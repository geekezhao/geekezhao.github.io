{"meta":{"title":"Geeke's Blog","subtitle":"","description":"","author":"Geek ZHAO","url":"https://zqzhao.cn","root":"/"},"pages":[{"title":"categories","date":"2020-04-05T08:31:30.000Z","updated":"2020-04-05T08:32:35.155Z","comments":false,"path":"categories/index.html","permalink":"https://zqzhao.cn/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-04-18T06:10:25.000Z","updated":"2020-04-18T06:16:45.773Z","comments":false,"path":"tags/index.html","permalink":"https://zqzhao.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Organization And Management Studies","slug":"Seminar-OrganizationAndManagementStudies","date":"2021-09-14T05:17:36.000Z","updated":"2021-09-14T08:50:02.149Z","comments":true,"path":"2021/09/14/Seminar-OrganizationAndManagementStudies/","link":"","permalink":"https://zqzhao.cn/2021/09/14/Seminar-OrganizationAndManagementStudies/","excerpt":"","text":"Gang ZHENG zg@zju.edu.cnLin WANG 3160105195@zju.edu.cn OrganizationNoteszmh.pdf What is the organization?What’s the features?How to define?What’s the difference and similarity between administration and management? What’s the perspective of your studies? A specific perspective. Course IntroductionThis is a theory-oriented course. Students should stand in the feet of authors’ and think in the way author thinks. 联系观察内容和理论 Where do interesting questions raise from?Theory compared with phenomenon = Most interesting question phenomenon+theory —&gt; theoretical framework —&gt; method Objectives: to provide a systematic and critical understanding of organizational and managerial theories to show how these theories can serve as useful research tools for the analysis of organizational situations and managerial activities Read/Comment/Present/Discuss/Reflect/Write TextBook: Morgan, G. 2006. Images of Organization(2nd), Sage. 《组织》 Outlines: Mechanical Model 9.28 Bureaucratic structure and personality, 1940 Time-and-motion regained, 1993 Contingency theory 10.12 A framework for the comparative analysis of organization Organizational structure, environment and performance: The role of strategic choice Population Ecology 10.26 the population ecology of organizations organizational process of resource partitioning Institutional theory 11.9 institutionalized organizations: formal structure as myth and Ceremony the iron cage revisited: institutional isomorphism and collective rationality in organizational fields Organizational Economics 11.23 The nature of the firm Comparative economic organization: The analysis of discrete structural alternatives Network and organization 12.7 economic action and social structure: The problem of embeddedness social structure and competition in interfirm networks: the paradox of embeddedness Managerial and organizational cognition 12.21 organizing and the process of sensemaking transaction and 《组织理论》理查德司格特《经典理论的开发历程》迈克尔希特《社会网络与组织》奇达夫 马丁《管理决策中的判断》2007 Organization VS InstitutionOrganization can be defined in different ways: Physical structure Social sturcture Technology (A process to make work done) Culture Part of an environment Organization can also be studied in terms of the central issues and recurring themes of organizing: decision making controlling changing conflicting power Organization Characteristics: Social entity or reality (related to people) A common goal or a series of goals Relatively clear-cut boundary Intended structure and coordination Definite functions What’s the difference between institution and organization? Rules. Basic questions about research on organization but institution: How do we know if an organization is successful? What are the components of an organization? (此处涉及element resource, nk model应该会在这里讨论) What determines the structure of an organization? What options for managers have for designing their organization and when should each be used How do you apply a knowledge of organizational and managerial theory to the resolution of current management problems? Management VS Administration Administration: to serve, and hence later, to manage Management: to control by hand / gain results Administration: following instructions and service, and focusing on process, procedures and propriety Management: The achievement of results, and personal responsibility by the manager for results being achieved How many PERSPECTIVES of OM? classical school’s perspective Sociological stream focused on the changing shapes and roles of formal organizations within society and broader influence of industrialization o the nature of work and its consequences for workers Scholars:Emile Durkheim, Karl Marx, Max Weber Classical Management Stream Scholars: Frederick Taylor, Henri Fayol, and Chester Barnard 一支源于社会学视角，另一支源于经典管理视角，经典学派集大成=Adam Smith modern perspective Bertalanffy: General Systems Theory symbolic-interpretive perspective Karl Weick: Enactment Theory (The social psychology of organizing, 1969) ET focuses on the subjective origin of organizational realities, which is different fro modern perspective. postmodernism perspective 我想回答的一些问题 什么研究视角（perspective）Static VS Dynamic (Organization vs Organizing) Theoretical think / theoretical framework从概念比较中得来，要在论文中用最精确的单词，用对单词意味着critical thinking","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Theorical_Basis","slug":"Theorical-Basis","permalink":"https://zqzhao.cn/tags/Theorical-Basis/"}]},{"title":"Service Science Lect 1","slug":"Seminar-ServiceScienceLect1","date":"2021-09-13T06:26:11.000Z","updated":"2021-09-14T05:24:14.109Z","comments":true,"path":"2021/09/13/Seminar-ServiceScienceLect1/","link":"","permalink":"https://zqzhao.cn/2021/09/13/Seminar-ServiceScienceLect1/","excerpt":"","text":"华中生 zshua@zju.edu.cn Content服务科学是做什么的？ Subject1:服务科学及研究思考 Subject2:服务参与者行为与服务关系 Subject3:服务资源组织与协调 Subject4:探索免解出服务 报告1：如何发现好的管理学研究问题 报告2：管理科学的研究与论文写作方法 专题1：基于互联网的科技咨询（怎么应付科技部） 专题2：基于互联网的养老服务 完全讲明白一篇文章问题-方法-结果想法好-论证严谨-结果有趣abs4以上 什么是服务是体验，是服务，experienced infoIBM创始，给出解决方案服务是主观的 服务接触 service contact 客户参与和服务的个性化程度 服务交付 service delivery 提供服务的实时性 服务交互 service encounter 服务提供者和客户互动 服务价值 service value 满足需求的程度及带给客户的价值 服务营销？有这个东西吗？ 服务是什么？ intangibility heterogeneity w inseparability 生产和消费过程无法分割 perishability 服务：具有无形特征却可以给人在一定时间段上带来某种利益或满足感的一系列交互行为及其过程。（不一定要有结果或实际效用，我理解是一种experienced goods） 现代服务以ICT为支撑，基于新的时空关而进行协同创造、创造价值的交互行为及其过程。 服务的三要素： 价值共创 SP与C共同参与制造过程与结果 不仅包括经济价值，还可能包括非经济的目标 经济价值测度方法也与工业经济有差别 服务关系 不仅包括SP与C之间的关系，往往不是二元关系 服务供给 有效的服务供给永远是短缺的 产业融合：产业交叉及其跨界发展服务并不只存在于服务业 现代服务业 基础服务 生产和市场服务 个人消费服务 公共服务 服务科学和运作科学？operation research? Operation management?algorithm management —》 平台算法的bias —》由政府监管的政策 （是否提供服务，涉及到服务，就可以放到服务科学里） 现代服务与传统服务的不同 新的空间概念 新的时间概念（打破时空限制） 新的服务关系 交互关系、关系结构与变化（主题、层次、范围、演化等） 新的价值内涵与价值创造方式 价值内涵不同：行为动机、价值层次、测度方法 价值形成机制不同：成本结构、服务模式、商业模式不同 现代服务的新特征 服务系统化 系统指服务流程、服务供应链，更多的是服务生态系统。服务系统中顾客、信息主体、资源主体和环境等参与要素形成动态的关联 服务关系性 资源整合性 什么是服务科学？对所有具有服务本质并创造价值的人类行为与活动进行研究的科学，通过提炼服务主体与客户的行为特征和服务关系的科学本质，发现服务过程与服务系统效率的关键要素及其作用规律，探索服务价值的测度方法、创造模式与传递机制，目前是在服务实践中全面提升服务生产力、改善服务体验。 服务科学需要在测量感知的基础上，通过科学规律和科学本质的发现来改善服务系统与服务提供。 不仅仅针对服务业，而是对所有有服务关系本质活动过程的一种系统性和科学性的研究。","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Theorical_Basis","slug":"Theorical-Basis","permalink":"https://zqzhao.cn/tags/Theorical-Basis/"}]},{"title":"Paper Related to NK Model","slug":"Notes-nkmodel","date":"2021-08-20T08:25:11.000Z","updated":"2021-08-21T10:06:07.914Z","comments":true,"path":"2021/08/20/Notes-nkmodel/","link":"","permalink":"https://zqzhao.cn/2021/08/20/Notes-nkmodel/","excerpt":"","text":"List Year Journal Title Author Model Notes 1997 Management Science Adaptation on rugged landscapes Daniel A. Levinthal 综述 ——- 2017 Research Policy What drives innovation? Evidence from economic history Josef Taalbi long term historical studis/ Landscape fitness 2004 International Journal of Operations and Production Management Manufacturing strategy: Understanding the fitness landscape McCarthy, Ian P. 综述 2019 Journal of Management Effective Search in Rugged Performance Landscapes: A Review and Outlook Baumann, Oliver, Schmidt, Jens, Stieglitz, Nils 综述 2017 Research Policy NK model as a representation of innovative search Martin Ganco, Martin researh paper PapersTemplateName, Year​ Topic​ Data Literature Finding​ Notes​ ​ What drives innovation?Taalbi, 2017​ Topicon how and to what extent innovation activity is the response to changes in the social or economic environmentDatamicro-based database on Swedish product innovations, 1970–2007Literature Innovation can be driven by both positive and negative powers. Positive: private return from innovation. Negative: necessity and demand. Accordingly, not only does any innovator face a more or less complex combinatorial problem, but the evolution of technology must be thought of as the evolution of a complex system. To this end this framework builds on the nowadays standard NK-model, originally introduced to describe adaptive genetic evolution on fitness landscapes (Kauffman and Levin, 1987; Kauffman, 1993), but subsequently applied to e.g. economics of innovation to describe how search strategies – local search or distant search, exploitation or exploration – are afflicted by the complexity of the space of combinations (cf March, 1991; Levinthal, 1997; Frenken, 2000). Recent research has remarked that the NK-model is an apt tool for understanding how complexity problematic shapes search strategies of firms, but that notions such as problemistic search and negative feedback have not been properly included (Gavetti et al., 2012; Billinger et al., 2013). The current endeavors examine a way to link the NK-model to the notion of innovation as a creative response to changes in economic data. Finding s puzzle and z puzzle: s puzzle: to find out how to attain certain characteristics in a product by combining available input modules z puzzle: to identify those characteristics of a product that have high value, or payoffs. $\\pi$ is not related to a specific characteristic but a combination of characteristics Both internal and external factors leave effect on payoffs. external: e.g. prices or demand internal: the process of technological change If we think of the production chain as a tree, the technological distance is thus the number of roots that have to be modified to discover a new technology. The four different search strategies may be connected to varying levels of complexity and un- certainty about payoffs and the space of input combinations. 事实上这是对innovation的动力来源的讨论，主要是利润充沛的蓝海场景和受到内外部局限的红海场景的讨论(innovation pushes) (1) institutionalized: abundant characteristics and strong direction of technological change; (2) hindered by market uncertainty or considerable complexity. problemistic opportunity -&gt; failure inducement or negative performance feedback marketing opportunity -&gt; changes in consumer preferences and general demand factors provide pivotal incentives for innovation by raising expected returns from innovation technological opportunity -&gt; decreasing the technological distance to some known set of high payoff characteristics or focus the search to a subset of the space of input combinations. Innovations driven by problems and technological opportunities are associated with higher market and firm novelty of the innovations, indicating a possible relation with explorative search strategies and disruptive innovation processes. Overall, innovations in high-tech and medium high-tech industries were more likely to be driven by problems or opportunities. Conversely, problem-solving in- novations are more common in medium high-tech industries. The results also convey that innovations driven by problems and technological opportunities are connected to frequencies of 16-32 years of duration. These innovations were clustered some time after the downswing phase of the Kuznets cycle, around 1980 and 1998. This does not suggest a causal relationship from GDP growth to innovation activity, but informs of, if anything, a generic interplay between long-run economic growth and innovation activity. ​ Notes 创新点在于 【长时期】的【历史数据研究】instead of case study -&gt; 自己搜集标注的数据 nkmodel的一些更新：problemistic search and negative feedback 由于影响的因素特别复杂，而且innovation是一个联结的过程，每个invention可能只有一小点创新，因此视为complex system，使用landscape model 推导过程里涉及新的分布Irwin-Hall Distribution 注：这里需要重新对照参数推导 文章主要讨论创新原动力，计量模型没有用到nkmodel，nkmodel在这里用于解释complexity系统以及因变量的不同情况。* ：本文不以nkmodel作为主要方法，看起来只是包装一下。 Adaptation on rugged landscapesDaniel A. Levinthal, 1997. Manufacturing strategy: Understanding the fitness landscapeMcCarthy, Ian P., 2004. Effective Search in Rugged Performance LandscapesBaumann, Oliver, Schmidt, Jens, Stieglitz, Nils, 2019.​nkmodel.pdf​","categories":[],"tags":[{"name":"Notes","slug":"Notes","permalink":"https://zqzhao.cn/tags/Notes/"}]},{"title":"Performance Studies","slug":"Notes-Performance-Studies","date":"2021-08-17T10:42:32.000Z","updated":"2021-08-20T08:06:00.959Z","comments":true,"path":"2021/08/17/Notes-Performance-Studies/","link":"","permalink":"https://zqzhao.cn/2021/08/17/Notes-Performance-Studies/","excerpt":"","text":"What is Performance?Whatever you are doing now, whoever you are at this moment, whatever you did when you began your day, you were and are performing. Performing is an ongoing, never-ending activity or set of activities. What “to perform” means in the arts, business, sports, education, sex, industry, the military, and so on, varies. What ties all these meanings and diverse domains into one bundle is the idea of doing something effectively, convincingly, and repeatedly. To perform is to get something done (be effective), to impress others with what’s been done (be convincing), and to do it again (to follow a score or script). To study performances means to pay attention to both the highly conscious managed constructions of the arts, rituals, and sports and to the almost unconscious embodied constructions of daily life. Of course, when you are in flow, cruising along on autopilot, you are not aware of what you are doing — you might not know that you are performing. In that case, imagine that someone else is observing you. Even if you are not performing for yourself, you may be performing for others. Many great photographs have been candid shots snapped with the subjects unaware of the photographer. In fact, we slip in and out of awareness of our own actions and the actions of others. This sliding scale is a thermometer of performance. The more aware we are of what we, or others, are doing, the more those actions can be called “performances.” Thus a particular molecule of action may or may not be a performance depending on one’s awareness of the action. With awareness comes the ability to adjust your own actions and how you interpret the actions of others. Or, if you are a choreographer, theatre director, or party-planner, how to manage or adjust the actions of others. Again and again, you are performing as you watch other people perform, while others perform as they watch you perform. A comprehensive illustration of the broad spectrum of performance is what I call “the fan and the web.” Fan Ritualization Art-Making Process Play Performance in everyday life Eruption and resolution of crisis Shamanism Rites and ceremonies Web prehistoric shamanism historic shamanism origins of theatre origins of European theatre experimental performance dialogic and body oriented psychotherapies ethological studies of ritual and play performances in everyday life play and crisis behaviour Nine Kinds of Performance In everyday life In the arts In sports and other popular entertainments In medicine, business, law, and other professions, and in ordinary jobs In politics In technology (Online community) In sex In ritual In play Seven Functions of Performance To entertain To create beauty To mark or change identity To make or foster community To heal To teach or persuade To deal with the sacred and demonic Thinking about the example of a shaman performance. IS/AS PerformanceAccording to performance studies, anything and everything — the actions of humans, animals, or nature (a sunset, a thunderstorm) — can be analyzed “as” performance. What “is” performance depends on cultural context. A specific event “is” performance in one context, but not performance in another. Any event can be studied “as” performance. Specific activities within every culture are designated “is” performance. What “is” a performance can only be determined through cultural and historical analysis. What “is” performance is defined by context, convention, usage, and tradition. At any given time and place, what “is” performance is limited. Not everything “is” performance. On the other hand, any activity can be studied “as performance.” To make an “as performance” analysis one asks performance questions: How is an event staged? Where does it take place? What special gestures, clothes, and objects are used? What roles are played — and are these roles permanent or temporary? These questions are not asked in a vacuum, but in terms of specific historical and cultural circumstances. The Basic Parameter of PerformanceHere are three people: Goffman, Erving. 1959./anthropologist Victor Turner’s theories of social drama, liminal-liminoid, and communitas/philosopher J.L. Austin’s concept of the performative Restoration of BehaviorRestored behavior is behavior that has been enacted previously. In fact, all behavior is restored, performed for the second to nth time. All behaviors are reconstructions or reconfigurations of already behaved actions. That is, all behavior is part of an already begun and never-ending process of rehearsals and recombinations. The present is made from bits of the personal or collective past selected and modified — consciously or unconsciously — to accomplish some near or distant future project. The restoration of behavior process is a rehearsal process where today’s behavior is made from bits of yesterday’s behavior shaped according to the emerging performance-to-be. Even what is apparently imaginary — total fantasy — is made from bits of actualities distorted and/or reshaped by mental processes. Restoration of behavior can be understood as a kind of Darwinian-genetic “natural selection” of social rather than biological events, items, bits, and processes. Make Believe/Make BeliefPerformances can be “make believe,” such as Elia Kazan’s 1949 production of Arthur Miller’s Death of a Salesman or Pina Bausch’s 1978 dance theatre work, Café Müller or James Taylor’s 2015 album Before This World. Performances can also be “make belief,” roles people assert are their real selves. This kind of make belief role is what Goffman writes about in The Presentation of Self in Everyday Life. A make believe role is based on a make belief role. For example, the 1960 movie Inherit the Wind is based on the actual trial in 1925 of John Thomas Scopes who was accused, and convicted, of teaching Darwin’s theory of evolution to a Tennessee high school class. This famous “monkey trial” was intentionally staged to test whether or not “modern science” ought to be taught in public schools. But the make believe/make belief process can run the other way too. In lesson 8, we will see how the make believe of theatre is transformed into the make belief of ritual in the Ramlila of Ramnagar, India. Many make believe roles are transformed into make belief by means of committed performance. What is Performance Studies?Performance Studies (PS) is an emerging academic discipline, increasingly accepted within the academic world, that intersects and overlaps the social sciences, cultural and media studies, and the study of the arts. Performance Studies international (PSi), founded in 1997, is a global association of performance studies scholars and artists. Up through 2016, PSi has met in China, New Zealand, Croatia, Germany, Singapore, Canada, Holland, Denmark, the UK, Australia, and the US. PSi’s projects and programs are intentionally even more diversified culturally and geographically. For more on PSi go to: http://www.psi-web.org. Several journals feature Performance Studies including: TDR The Journal of Performance Studies, Performance Research, Global Performance Studies, PAJ: Performing Arts Journal, Performance Matters, and Liminalities (both online only). Many other journals.","categories":[],"tags":[{"name":"Notes","slug":"Notes","permalink":"https://zqzhao.cn/tags/Notes/"}]},{"title":"Notes-Preregistration","slug":"Notes-Preregistration","date":"2021-01-03T08:24:28.000Z","updated":"2021-01-03T08:26:09.904Z","comments":true,"path":"2021/01/03/Notes-Preregistration/","link":"","permalink":"https://zqzhao.cn/2021/01/03/Notes-Preregistration/","excerpt":"","text":"What is preregistration?) Benefits of preregistration","categories":[],"tags":[{"name":"Notes","slug":"Notes","permalink":"https://zqzhao.cn/tags/Notes/"}]},{"title":"Notes in Experiments (True/Field/Nature)","slug":"Notes-Experiments","date":"2021-01-03T06:49:41.000Z","updated":"2021-01-03T07:17:27.731Z","comments":true,"path":"2021/01/03/Notes-Experiments/","link":"","permalink":"https://zqzhao.cn/2021/01/03/Notes-Experiments/","excerpt":"","text":"What is the difference between True(Lab)/Field/Nature Experiment? Variables TrueExperiment FieldExperiment NatureExperiment IV Manipulated by researcher, as well as other extraneous variables Manipulated by researcher / Extraneous variables can not be manipulated Generated by nature/ All variables cannot be manipulated DV Observed in Lab Observed in natural environment Observed in natural environment General Introduction 1 General Introduction 2 Strength and Weakness What is Field Experiments? A paper in NATURE What is the difference between Exogenous and Endogenous Variables?In an economic model, an exogenous variable is one whose value is determined outside the model and is imposed on the model, and an exogenous change is a change in an exogenous variable. In contrast, an endogenous variable is a variable whose value is determined by the model. An endogenous change is a change in an endogenous variable in response to an exogenous change that is imposed upon the model. The term endogeneity in econometrics has a related but distinct meaning. An endogenous random variable is correlated with the error term in the econometric model, while an exogenous variable is not. Wiki","categories":[],"tags":[{"name":"Notes","slug":"Notes","permalink":"https://zqzhao.cn/tags/Notes/"}]},{"title":"Difference in Bayes and Frequency","slug":"Notes-Bayes-and-Frequency","date":"2020-10-18T06:50:41.000Z","updated":"2020-10-18T06:54:34.825Z","comments":true,"path":"2020/10/18/Notes-Bayes-and-Frequency/","link":"","permalink":"https://zqzhao.cn/2020/10/18/Notes-Bayes-and-Frequency/","excerpt":"","text":"The difference between Bayes and Frequency are mainly based on the order of observation. Frequency mathematicians want to record the fact faithfully while Bayes mathematicians want to update the known knowledge with new observation.","categories":[],"tags":[{"name":"Notes","slug":"Notes","permalink":"https://zqzhao.cn/tags/Notes/"}]},{"title":"FE and RE and HLM","slug":"AMR-HLM","date":"2020-09-01T03:18:57.000Z","updated":"2020-09-01T03:24:00.254Z","comments":true,"path":"2020/09/01/AMR-HLM/","link":"","permalink":"https://zqzhao.cn/2020/09/01/AMR-HLM/","excerpt":"","text":"Fixed Effect vs. Random Effect只求甚解：固定效应与随机效应 真实世界的复杂现象 = 确定的统计模型 + 不确定的随机误差 写在前面： 原本只是为了了解HLM，但在HLM的介绍中介绍了随机效应和固定效应，为了厘清这两个概念找了相关资料，竟然意外中已经完成了对HLM的初步了解。但由于固定效应和随机效应是相对于某一种模型更为抽象、基本的概念，所以选用这一组概念作为入手点观察这一类统计方法。 What is the Essence of Regression ?下面的四幅图直观地展示了回归模型的“固定”与“随机”。同样都是一条回归方程（有几乎相同的截距和斜率，即模型的“固定部分”），但数据的实质却截然不同——①中的X和Y是两个正态分布的变量，其回归模型的“随机部分”基本都来自于随机误差，因此模型是适当的；②中的X和Y实则是非线性关系，因此用一般的线性回归做拟合是错误的，应加入X的二次项做多项式回归；③中的一个数据点成为了异常值（outlier），同样会影响回归模型的准确性，可以剔除该点，或者做稳健回归；④进一步告诉我们，哪怕是一个小小的异常数据点，也足以产生错误的、有误导性的结果。②~④的共性在于，残差并不满足正态分布，或者存在异方差（heteroscedasticity），所以它们得到的回归模型（固定部分）都是不妥当的。 一般而言，回归模型的“随机部分”需要尽可能服从正态分布，这样才能保证“固定部分”的参数估计是无偏的、一致的、有效的。 “回归”的思想其实渗透着“舍得”的理念：我们通过舍弃那些“随机部分”的误差（residual variance），获得了我们想要的“固定部分”的参数（regression coefficients）。 What is HLM ? t检验是ANOVA的一个特例（自变量只有两水平）ANOVA是回归分析的一个特例（自变量为分类变量）回归分析的实质是一般线性模型GLM（其推广则是广义线性模型）GLM是HLM的一个特例（只有Level 1）元分析可以视为只有组间模型的HLM（只有Level 2） 回归分析是几乎所有统计模型的基础，而回归分析的最一般形式则可以归为多层线性模型HLM。多层线性模型HLM : 总方差 = 组内方差（Level 1）+ 组间方差（Level 2） 以下举例：“智力水平（IQ）能否影响学业成绩（GPA）”变量： 学生成绩，学生IQ，学校水平 在上面的例子中，学生是个体水平（Level 1）的分析单元，IQ和GPA都是在个体水平收集的变量，而学校是群体水平（Level 2）的分析单元，不过我们暂时并没有收集学校水平的任何自变量，只是把学校本身当做一个分组变量（clustering/grouping variable）。换句话说，上面这个例子也可用被称作“随机效应单因素协方差分析（ANCOVA with random effects）”。 注：上述模型在Level 1 层面仅考虑了学生个体差异；在Level 2 层面中考虑了学校差异，由于学校间的差异会影响截距，因此此时是随机截距，又因为GPA与IQ的关联是由学生在一开始决定的，此时又是固定斜率。 Q：HLM是否在应用之出已经明确了模型的随机部分和固定部分，仅仅通过HLM确定各个系数？我们还可以引入学校水平的自变量来对学校间的GPA均值差异进行解释，比如教师数量、教学经费……这些变量由于只在学校层面变化，对于每个学校内的每一个学生而言都只有一种可能的取值，因此必须放在Level 2的方程中作为群体水平自变量，而不能简单地处理为个体水平自变量——这也就是HLM的另一个存在的意义：可以同时纳入分析个体与群体水平的自变量。 注：Level 1 和 Level 2 存在分层结构的关系（类似概念可见分层抽样和分层聚类）。此时自变量进入模型必须按照作用对象划分到对应的模型中。 “多层线性模型”与“分层/逐步多元回归” 的关系，请注意： 多层线性模型HLM解决的是多层嵌套结构数据（落脚点是数据结构） 分层/逐步多元回归本身是普通的回归分析，解决的是不同自变量的重要性的优先程度（落脚点是变量重要性） HLM的自由度只求甚解：HLM的自由度是个重要的问题吗？ 一些参考资料 How to Decide ?","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Theorical_Basis","slug":"Theorical-Basis","permalink":"https://zqzhao.cn/tags/Theorical-Basis/"}]},{"title":"Article Template of MIS - Discussion","slug":"module-result","date":"2020-08-16T10:41:14.000Z","updated":"2020-08-16T10:42:25.186Z","comments":true,"path":"2020/08/16/module-result/","link":"","permalink":"https://zqzhao.cn/2020/08/16/module-result/","excerpt":"","text":"","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Article_Template_MIS","slug":"Article-Template-MIS","permalink":"https://zqzhao.cn/tags/Article-Template-MIS/"}]},{"title":"Article Template of MIS - Discussion","slug":"module-discussion","date":"2020-08-08T14:02:33.000Z","updated":"2020-08-10T08:20:14.203Z","comments":true,"path":"2020/08/08/module-discussion/","link":"","permalink":"https://zqzhao.cn/2020/08/08/module-discussion/","excerpt":"","text":"In this part, I will formulate the template of discussion and future research part. Normally, this part includes implication for theory and implication for practice. DiscussionLimitation and Future ResearchImplication for TheoryImplication for PracticeConclusion","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Article_Template_MIS","slug":"Article-Template-MIS","permalink":"https://zqzhao.cn/tags/Article-Template-MIS/"}]},{"title":"Article Template of MIS - Origin","slug":"module-origin","date":"2020-08-08T11:51:53.000Z","updated":"2020-08-08T11:53:31.893Z","comments":true,"path":"2020/08/08/module-origin/","link":"","permalink":"https://zqzhao.cn/2020/08/08/module-origin/","excerpt":"","text":"模板中已经参考过的文献Introduction 文章 来源 点评 Branstetter 2019 ISR 这篇文章对过去文献的评述主要放在了对后续章节的展开中，也就是in the following sections这一部分中，不是特别典型；另外放了一些篇幅在对自己结果的简介上。 Bharadwaj 2000 MISQ 这篇文章的开头大篇幅放在自己理论上，比较少提到了前文研究和后续的行文。 Chae 2014 MISQ 这篇放了很大篇幅在过往文献的比较和综述上，后续需要关注literature的写法。","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Article_Template_MIS","slug":"Article-Template-MIS","permalink":"https://zqzhao.cn/tags/Article-Template-MIS/"}]},{"title":"Article Template of MIS - Introduction","slug":"module-intro","date":"2020-08-07T14:30:12.000Z","updated":"2020-08-08T12:32:15.598Z","comments":true,"path":"2020/08/07/module-intro/","link":"","permalink":"https://zqzhao.cn/2020/08/07/module-intro/","excerpt":"","text":"In this part, I will conduct a module of introduction in order to avail future researches. Based on the favor of different journals, I will list the template grouped by the journals. Mainly there are three journals which are MISQ, ISR and MS. However, there are also other articles with a graceful written style. 开头句ISR This paper documents a significant change in the nature and direction of invention in four “traditional” manufacturing industries. MSMISQ Understanding the economic impact of information tech- nology is a critical issue to information systems researchers, and there is a rich body of literature about IT value (Chan 2000; Dehning and Richardson 2002; Kohli and Devaraj 2003; Mahmood and Mann 2000; Melville et al. 2004; Wade and Hulland 2004). Despite the widely held belief that information technology (IT) is fundamental to a firm’s survival and growth, scholars are still struggling to specify the underlying mechanisms linking IT to financial performance. Others引入-对过往文献的评述（侧重不足）ISRMSMISQ This study focuses on the performance effects of IT, an issue that has provoked much debate over the last decade. Dubbed the “productivity paradox,” the controversy over the business value of computer investments continues to rage even in the face of more encouraging evidence about payoffs from IT (Brynjolfsson 1993; Brynjolfsson and Hitt 1993, 1996; Hitt and Brynjolfsson 1996) For example, in his most recent book, The Squandered Computer, Strassman (1997) argues that there is no discernible relationship between IT investments and any measure of firm profitability including return on assets, return on equity, and economic value added. Other empirical studies that have investigated the relationship have also yielded mixed results. These results have been extensively cited and summarized elsewhere (c.f. Brynjolfsson 1993; Hitt and Brynjolfsson 1996; Lucas 1993; Wilson 1993). The findings of past studies have however been questioned on methodological grounds such as (1) use of inappropriate measures of IT intensity, (2) failure to control for other factors that drive firm profits, and (3) problems related to sample selection and sample size (Dos Santos et al. 1993; Hitt and Brynjolfsson 1996; Lucas 1993; Mooney et al. 1995). With this backdrop, it is natural to ask if IT capabilities still hold the same value today as they did in the past. However, these studies were conducted with data from the early 1990s, and we wondered if their findings still hold true after over a decade of rapid and widespread change in IT and the way organizations use IT. Thus, we updated these studies with new data from the early 2000s. Replications and updates are an important aspect of scientific endeavor because they test the robustness of a theory and solidify tentative beliefs into accepted knowledge (Santhanam and Hartono 2003). However, replicative studies are generally underutilized by the research community (Berthon et al. 2002). We believe that examining and reexamining what has been scientifically studied and reported is particularly important to the research community. Others引入-重要现实意义ISR Engineers and industry experts in these sectors have provided anecdotal evidence of a software-biased shift in the trajectory of innovation, but this evidence has generally rested on a relatively small number of possibly unrepresentative firms and products. MSMISQ Despite the widely held belief that information technology (IT) is fundamental to a firm’s survival and growth, scholars are still struggling to specify the underlying mechanisms linking IT to financial performance. Anecdotal evidence and case studies indicate that effective and efficient use of IT is a key factor differentiating successful firms from their less successful counterparts. For example, IT capabilities were found to be an important differentiator of banks that were doing well in the mid-1980s, as compared to those that were less profitable (Nolan 1994). Widely publicized IT programs in firms such as American Airlines, Merrill-Lynch, and Frito-Lay have been associated with superior business performance. At the same time, there is also evidence that many firms, concerned about falling behind on the technology curve, engage in high IT investments without deriving any benefits from IT (Nolan 1994). Despite some skepticism about the direct effect of IT on firm performance (Carr 2003; Clemons 1986, 1991; Clemons and Row 1991; Powell and Dent-Micallef 1997), many IS researchers believe that superior IT capability can render a firm a significant competitive advantage over its competitors. However, as Nicolas Carr argued in his Harvard Business Review article in 2003, several significant develop- ments in the IT industry in the 2000s may have eroded the competitive edge resulting from being an IT leader with superior IT capability. Others对自己的全文做一个简单总结ISR Using much more comprehensive patent and patent citation data, we present new statistical evidence showing that this software-biased shift is persistent, systematic, and increasingly pervasive. We also point to other indicators suggesting that this shift extends far beyond the boundaries of our four target industries.这里是对自己的文章内容的总结，可以注意下一些名词的选择。 MSMISQ Thus, we embarked on a study that examined whether being an IT leader in the 2000s is still as significant a factor in determining business performance as it was in the 1990s. Also, if it is, how have the benefits of being an IT leader changed from the early 1990s to the 2000s? Others文章结构ISR This paper is structured as follows. Section 2 reviews research from the engineering and management literatures that points to a significant increase in the importance of software as an enabler of innovation in four “traditional” manufacturing sectors. We interpret these developments through the lens of the economic literature on general purpose technologies, and identify dimensions of technological change that link the observations of different industry experts to a common underlying cause. While suggestive, earlier research on this shift tends to be somewhat anecdotal, rely- ing heavily on the experience of a small number of firms and a highly selected sample of recent product development efforts. Section 3 presents new statistical evidence based on patent citation data that suggests the software-biased shift in the direction of technological change suggested by the engineering and managerial literatures is real, broad-based, and economically and statistically significant. Section 4 empirically examines the implications of this shift in software intensity for the innovation performance of firms in the four manufacturing sectors that are the focus of our study. Section 5 concludes with a summary of key results and avenues for future research. MSMISQ The purpose of this paper is to employ the resource-based view to develop the theoretical links and empirically examine the association between IT capability and business performance. Since the resource-based view explicitly recognizes the importance of intangibles such as customer orientation and organizational knowledge, it offers a significant opportunity to explore these theoretical complimentarities in examining the relationship between IT resources and firm performance. The remainder of this paper is organized as follows. The next section presents a brief outline of the resource-based theory of the firm followed by an examination of the links between IT resources and firm performance. This is followed by the empirical analysis, describing the data sources and the methodology used to address the research questions. Finally, the results and the implications of the study are presented and some concluding comments offered. In the following subsections, we summarize the early studies in terms of their methods and findings. Then, we report the process and the results of our study in which we updated the aforementioned studies that empirically confirmed the link between IT capability and business performance. Others我的看法在Introduction部分，首先，要强调自己的文章背景是重要的、过往研究中存在不足。其次，需要简单描述自己的文章的大概内容。最后，简介后续文章铺陈。","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Article_Template_MIS","slug":"Article-Template-MIS","permalink":"https://zqzhao.cn/tags/Article-Template-MIS/"}]},{"title":"Social Similarity","slug":"Seminar-social-similarity","date":"2020-07-09T10:58:02.000Z","updated":"2020-08-09T11:50:12.896Z","comments":true,"path":"2020/07/09/Seminar-social-similarity/","link":"","permalink":"https://zqzhao.cn/2020/07/09/Seminar-social-similarity/","excerpt":"","text":"本文考虑社交网络、社会关系间的相似性、距离度量，后续或有补充。 话语相似性 Top management team social interaction and conservative reporting decision: A language style matching approach. Decision Support Systems. LSM（Language Similarity Measure）用于衡量CFO和CEO的话语相似度。文章用meeting record作为数据来源，删掉部分行业以及资产不良的企业。 FWI_{k,i}, k=1, ..., 9. \\tag{1}LSM_{k,i,j} = 1-|FWI_{k,i} - FWI_{k,j}| / |FWI_{k,i} + FWI_{k,j}+0.0001|, k=1, ..., 9. \\tag{2}LSM_{i,j} = E[\\sum_{k=1}^9 LSM_{k,i,j}]\\tag{3}其中，公式（1）衡量第i个总裁在第k类词汇中的词汇强度（Function of Word Intensity），公式（2）衡量第i个和第j个总裁在第k类词汇上的LSM，公式（3）衡量第i个和第j个总裁之间的总话语相似性。 To be Continue…","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Theorical_Basis","slug":"Theorical-Basis","permalink":"https://zqzhao.cn/tags/Theorical-Basis/"}]},{"title":"What Theory Is Not","slug":"Seminar-WhatTheoryIsNot","date":"2020-05-09T11:40:42.000Z","updated":"2020-08-09T13:04:58.385Z","comments":true,"path":"2020/05/09/Seminar-WhatTheoryIsNot/","link":"","permalink":"https://zqzhao.cn/2020/05/09/Seminar-WhatTheoryIsNot/","excerpt":"","text":"What Theory Is Not ?What Theory Is Not ? Reading MaterialThe Nature Of Theory In IS What Theory Is, Theorizing Is Not","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Theorical_Basis","slug":"Theorical-Basis","permalink":"https://zqzhao.cn/tags/Theorical-Basis/"}]},{"title":"SVM","slug":"CSMATH-SVM","date":"2020-05-01T09:05:21.000Z","updated":"2020-08-10T11:12:52.888Z","comments":true,"path":"2020/05/01/CSMATH-SVM/","link":"","permalink":"https://zqzhao.cn/2020/05/01/CSMATH-SVM/","excerpt":"","text":"Reading Materials 下述代码中SVM的拉格朗日对偶推导参考 cnblog 拉格朗日对偶推导参考2 cnblog2 kernel推导参考1 kernel1 kernel推导参考2《支持向量机导论》 代码细节参考1 github 代码细节参考2 Jianshu Active Set原理实现参考M. Asghar Bhatti《Practical Optimization Methods With mathematical Applications》Chapter8.4 代码变量命名尽量与Bhatti书中对应 Notes12345678910111213# 先写一下带kernel的SVM的拉格朗日对偶形式# min_alpha 1&#x2F;2*sum_&#123;i&#x3D;1 to n&#125;sum_&#123;j&#x3D;1 to n&#125;*alpha_i*alpha_j*y_i*y_j*phi(x.T)*phi(x)# s.t. alpha_i &gt;&#x3D; 0# sum_&#123;i&#x3D;1 to n&#125;*alpha_i*y_i &#x3D; 0# # # 二次规划基本形：# min_X 1&#x2F;2*X.T*H*X + c.T*X# s.t. AX &gt;&#x3D; b# # # 在上述优化问题中，对应到二次规划：# alpha是现在要求的二次规划基本形里的X，【y_i*y_j*phi(x.T)*phi(x)】整个是H 12345678910111213# 在Active Set Method中，根据Bhatti书中所述，主要有几个步骤：# 1. 确定起始点x0# 2. 确定迭代方向d_k（如果当前的是x_k，那么此时迭代方向是d_k，x_&#123;k+1&#125; &#x3D; x_k + a*d_k，其中a是迭代步长）# 3. 看d_k，也就是是否需要迭代，这一步的实质是看现在的x满足了多少constraint# 4. 如果还需要继续迭代，x_&#123;k+1&#125; &#x3D; x_k + a*d_k### 在ASM结束后，求到了ahpla，那放进去一个新的x如何判断class呢？# 由于w &#x3D; sum_&#123;i&#x3D;1 to n&#125;*alpha_i*y_i*phi(x)就可以确定w# 由于b &#x3D; &#123;1 - sum_&#123;j&#x3D;1 to n&#125;*alpha_j*y_i*y_j*k&lt;x_i, x_j&gt;&#125;&#x2F;y_j# 且由于引入kernel，并不需要知道phi(x)的值，也就是不用算出w，直接开算：# f(x) &#x3D; w.T*phi(x)+b &#x3D; sum_&#123;i&#x3D;1 to n&#125;*alphi_i*y_i*k&lt;x_i, x&gt;+b# 上式与0比较判别class Code123456789101112131415161718192021222324252627282930313233343536373839404142import numpy as npimport pandas as pdimport randomimport sklearnimport matplotlib.pyplot as plt# Generate 20 dots for each groupn &#x3D; 20group1_center &#x3D; [8, 10] # 20 dotsgroup2_center1 &#x3D; [1, 1] # 10 dotsgroup2_center2 &#x3D; [16, 19] # 10 dotsx1 &#x3D; []x2 &#x3D; []y1 &#x3D; [1 for i in range(0,n)]y2 &#x3D; [-1 for i in range(0,n)]for i in range(0, n): ele1 &#x3D; group1_center[0] + np.random.randn() ele2 &#x3D; group1_center[1] + np.random.randn() x1.append([ele1, ele2])for i in range(0, int(n&#x2F;2)): ele1 &#x3D; group2_center1[0] + np.random.randn() ele2 &#x3D; group2_center1[1] + np.random.randn() x2.append([ele1, ele2])for i in range(0, int(n&#x2F;2)): ele1 &#x3D; group2_center2[0] + np.random.randn() ele2 &#x3D; group2_center2[1] + np.random.randn() x2.append([ele1, ele2])x1 &#x3D; np.array(x1)x2 &#x3D; np.array(x2)plt.scatter(x1[:,0], x1[:,1], c&#x3D;&#39;r&#39;) # class &#x3D; 1plt.scatter(x2[:,0], x2[:,1], c&#x3D;&#39;b&#39;) # class &#x3D; -1plt.show()x &#x3D; np.vstack((x1, x2))y &#x3D; np.hstack((y1, y2))# print(x)# print(y) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171def IsZero(data): if data &gt; 1e-5 or dataa &lt; -1e-5: return False return Truedef IsZeroVec(Vec): for i in range(len(Vec)): if not(IsZero(Vec[i])): return False return Truedef Guassian_k(x, y, sigma &#x3D; 7.0): return np.exp(-np.linalg.norm(x-y)&#x2F; sigma)def Poly_k(x, y, c &#x3D; 2.0, a &#x3D; 1, d &#x3D; 2): return (a*x.T.dot(y) + c)**d# solve Equality Constrained Quadratic Programming # f(x) &#x3D; 1&#x2F;2*d.T*Q*d+r.T*d s.t. A*d &#x3D; b 注意此处是b，8.4.5原文是0def ECQP(Q, g, A, b): rowA, colA &#x3D; A.shape left &#x3D; np.vstack((Q, A)) right &#x3D; np.vstack((A.T, np.zeros((rowA, rowA)))) # 合成8.4.5中第二步等式左侧第一个矩阵 x &#x3D; np.linalg.solve(np.hstack((left, right)), np.vstack((-g, b))) d &#x3D; x[:colA] v &#x3D; x[colA:] return d, v # d就是要求的迭代方向#active set method#CONSTRAINT: Gx &lt;&#x3D; h Ax &#x3D; bdef ASM(x0, hessian, g, G, h, A &#x3D; [[0]], b &#x3D; 0): #Step 1: find active set indices #Ax &#x3D; b may be empty zeroIdx &#x3D; [] if A.shape[0] &#x3D;&#x3D; len(x0): rowA, colA &#x3D; A.shape else: rowA &#x3D; 0 rowG, colG &#x3D; G.shape sum &#x3D; np.dot(G, x0) tmp &#x3D; sum - h for i in range(rowG): if IsZero(tmp[i]): zeroIdx.append(i) iter &#x3D; 0 x &#x3D; x0 while True and iter &lt; 200: #Step 2 solve equality constraint optimization gNew &#x3D; hessian.dot(x)+g ANew &#x3D; np.zeros((rowA+len(zeroIdx), colG)) bNew &#x3D; np.zeros((rowA+len(zeroIdx), 1)) for i in range(rowA): for j in range(colG): ANew[i][j] &#x3D; A[i][j] count &#x3D; 0 for i in zeroIdx: for j in range(colG): ANew[rowA+count][j] &#x3D; G[i][j] count +&#x3D; 1 d, lamb &#x3D; ECQP(hessian, gNew, ANew, bNew) is_zero_vector &#x3D; True if np.linalg.norm(d) &gt; 1e-5: is_zero_vector &#x3D; False if is_zero_vector: #Step 3 if d is a zero vector isOpt &#x3D; True idxMin &#x3D; np.argmin(lamb) lambMin &#x3D; lamb[idxMin] if lambMin &lt; 0: isOpt &#x3D; False if isOpt: output &#x3D; np.zeros((rowG, 1)) shift &#x3D; 0 for i in zeroIdx: output[i][0] &#x3D; lamb[shift] shift +&#x3D; 1 return x, output break else: zeroIdx.remove(idxMin) iter +&#x3D; 1 else: #Step 4 if not alpha &#x3D; 1. idxMin &#x3D; -1 for i in range(rowG): if zeroIdx.count(i) &#x3D;&#x3D; 0: k &#x3D; (h[i][0]-G[i].T.dot(x))&#x2F;(G[i].T.dot(d)) if k &lt;&#x3D; alpha and G[i].dot(d) &gt; 0: idxMin &#x3D; i alpha &#x3D; k x &#x3D; x+alpha*d if idxMin !&#x3D; -1: zeroIdx.append(idxMin) iter +&#x3D; 1 return x, lambdef SVM(x, Y, kernel&#x3D;1): num &#x3D; 40 dimension &#x3D; 2 # number of samples and dimension of samples print(&quot;number of samples &#x3D; &quot;, num, &quot;, dimension of samples &#x3D; &quot;, dimension) kerMat &#x3D; np.zeros((num, num)) hessian &#x3D; np.zeros((num, num)) A &#x3D; np.zeros((1, num)) for i in range(num): A[0][i] &#x3D; Y[i] for j in range(num): if kernel &#x3D;&#x3D; 1: kerMat[i][j] &#x3D; Guassian_k(x[i], x[j]) else: kerMat[i][j] &#x3D; Poly_k(x[i], x[j]) hessian[i][j] &#x3D; kerMat[i][j] * Y[i] * Y[j] g &#x3D; np.ones((num, 1)) * -1 # g^k &#x3D; Q*X^k+c b &#x3D; np.zeros((1, 1)) # 8.4.5中的零矩阵 Q &#x3D; np.diag(np.ones(num) * -1) # 也就是上文中标准形的H，在8.4中用Q指代 h &#x3D; np.zeros((num, 1)) count &#x3D; 0 for i in range(num): if (Y[i] &#x3D;&#x3D; 1): count +&#x3D; 1 x0 &#x3D; np.ones((num, 1)) for i in range(num): if Y[i] &#x3D;&#x3D; 1: #x0[i][0] &#x3D; 1.&#x2F;count x0[i][0] &#x3D; num - count else: #x0[i][0] &#x3D; 1.&#x2F;(num-count) x0[i][0] &#x3D; count solution, lamb &#x3D; ASM(x0, hessian, g, Q, h, A, b) # 求解alpha a &#x3D; np.ravel(solution) # find ECQP multipliers larger than zero, Support vectors have non zero lagrange multipliers sv &#x3D; a &gt; 1e-5 ind &#x3D; np.arange(len(a))[sv] # print(ind) alpha &#x3D; a[sv] suppData &#x3D; x[sv] suppLab &#x3D; Y[sv] print(&quot;Altogether &quot;+ str(num) +&quot; points with &quot;+ (str(len(alpha))) +&quot; support vectors&quot;) # b &#x3D; &#123;1 - sum_&#123;j&#x3D;1 to n&#125;*alpha_j*y_i*y_j*k&lt;x_i, x_j&gt;&#125;&#x2F;y_j intercept &#x3D; 0 for i in range(len(alpha)): intercept +&#x3D; suppLab[i] intercept -&#x3D; np.sum(alpha * suppLab * kerMat[ind[i], sv]) intercept &#x2F;&#x3D; len(alpha) return alpha, suppData, suppLab, interceptdef project(x, alpha, suppData, suppLab, intercept, kernel &#x3D; 1): y_predict &#x3D; np.zeros(len(x)) for i in range(len(x)): s &#x3D; 0 for a, data, y in zip(alpha, suppData, suppLab): if kernel &#x3D;&#x3D; 1: s +&#x3D; a * y * Guassian_k(x[i], data) else: s +&#x3D; a * y * Poly_k(x[i], data) y_predict[i] &#x3D; s return (y_predict + intercept)def predict(x, alpha, suppData, suppLab, intercept, kernel): return np.sign(project(x, alpha, suppData, suppLab, intercept, kernel)) 12345678910111213141516171819202122232425262728293031323334353637# kernel &#x3D; 1 # Gaussian kernelkernel &#x3D; 0 # Polynomial kernel # Here we can change the kernel functionif kernel &#x3D;&#x3D; 1: print(&quot;Temporarily using Gaussian Kernel...\\n&quot;)else: print(&quot;Temporarily using Polynomial Kernel...\\n&quot;)alpha, suppData, suppLab, intercept &#x3D; SVM(x, y, kernel)y_predict &#x3D; predict(x, alpha, suppData, suppLab, intercept, kernel) # 计算所属class# predicted class&#x3D;1class1 &#x3D; []class2 &#x3D; []for i in range(0, len(y_predict)): if y_predict[i] &gt; 0: class1.append(x[i])# predicted class&#x3D;-1 else: class2.append(x[i])x1 &#x3D; np.array(x1)x2 &#x3D; np.array(x2)plt.scatter(x1[:,0], x1[:,1], c&#x3D;&#39;r&#39;) # class &#x3D; 1plt.scatter(x2[:,0], x2[:,1], c&#x3D;&#39;b&#39;) # class &#x3D; -1plt.title(&quot;Original DataSet&quot;)plt.show()class1 &#x3D; np.array(class1)class2 &#x3D; np.array(class2)plt.scatter(class1[:,0], class1[:,1], c&#x3D;&#39;black&#39;) # class &#x3D; 1plt.scatter(class2[:,0], class2[:,1], c&#x3D;&#39;green&#39;) # class &#x3D; -1plt.title(&quot;After SVM&quot;)plt.show() Result Using Polynomial Kernel Using Gaussian Kernel","categories":[],"tags":[{"name":"CS_Math","slug":"CS-Math","permalink":"https://zqzhao.cn/tags/CS-Math/"}]},{"title":"Content Analysis Methods","slug":"AMR-content-analysis","date":"2020-04-29T08:26:57.000Z","updated":"2020-04-29T08:53:45.587Z","comments":true,"path":"2020/04/29/AMR-content-analysis/","link":"","permalink":"https://zqzhao.cn/2020/04/29/AMR-content-analysis/","excerpt":"","text":"内容分析方法内容分析法是一个高度结构化的分析方法，其分析过程需要经过精密的设计，以满足分析需要。内容分析法将非定量的文本转化为定量的数据，并依据这些数据做出定量分析，得到关于事实的判断和推论。因此，它对组成文本内容的因素与机构的分析更为细致和程序化。 内容分析法的一般过程包括建立分析目标、确定分析总体、选择分析单位、设计分析维度体系、进行评判记录和分析推论六部分。而其中涉及的主要具体工作就是设计分析维度、文本分类、抽样与评判记录。 另一个版本的过程描述： 其操作步骤主要有：1.阐明研究问题或假设；2.界定研究总体 ；3.从总体中选择合适的样本 ；4.选择和定义分析单位 ；5.构建用以分析的内容类别 ；6.建立量化系统 ；7.培训编码人员并进行试点研究 ；8.根据已有的定义对内容进行编码 ；9.分析采集到的数据 ；10.解释研究结果，得出结论。 抽样工作包括两个方面的内容：一是界定总体，二是从总体中抽取有代表性的样本。内容分析法常用的三种抽样方式为：来源取样、日期抽样与分析单位取样。 分析维度通常在进行具体评判记录前就已经事前确定，在设计分析维度时应考虑如何对内容分析结果进行定量分析，即考虑到使结果适合数据处理的问题。 在进行分类时，需要确定分类标准完全、彻底地适合于所有选定的分析材料，使所有分析单位都可归入相应的类别，不能出现无处可归的现象。在分类中应当使用同一个分类标准，即只能从众多属性中选取一个作为分类依据。分类的层次应该明确，逐级展开，不能越级和出现层级混淆的现象。 评判记录是根据已确定的分析维度和分析单位对样本中的信息作分类记录，登记下每一个分析单位中分析维度是否存在及出现的频率。要做好评判记录工作，需要注意以下几个方面： 按照分析维度用量化方式记录分析对象的量化数据（如有、无、数字形式、百分比）。 采用事先设计好的易于统计分析的评判记录表记录。先把每一分析维度的情况逐一登记下来，然后再做出总计。 在根据类目出现频数进行判断记录时不要忽略基数。","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Theorical_Basis","slug":"Theorical-Basis","permalink":"https://zqzhao.cn/tags/Theorical-Basis/"}]},{"title":"Grounded Theory","slug":"AMR-grounded-theory","date":"2020-04-28T14:56:47.000Z","updated":"2020-04-29T07:32:25.755Z","comments":true,"path":"2020/04/28/AMR-grounded-theory/","link":"","permalink":"https://zqzhao.cn/2020/04/28/AMR-grounded-theory/","excerpt":"","text":"质性研究与定性研究 定性研究的理论基础主要是哲学，其研究传统是一种形而上、思辨的传统；而质的研究的理论基础主要是人种学、现象学、解释学、实证主义理论，具有跨学科、多学科的色彩。 定性研究的方法包括历史法、个案法、观察法、调查法、文献资料分析法、经验总结法等；而质的研究除了上述定性研究方法外，还包含实证研究方法。定性研究注重哲学思辨、逻辑推理，根据个人主观经验，然后用演绎的方法对自己的思考进行验证。质的研究则注重在互动过程中系统收集、分析原始资料的基础上展开讨论。 对于研究的结果，定性研究偏向结论性、抽象性和概括性；质的研究则更加强调研究的过程性、情境性和具体性。定性研究更多地是研究者个人观点的阐发和个人的建议，质的研究强调在原始资料基础上建构结论或理论。 扎根理论的流派区分 Glaser &amp; Strauss 经典扎根理论 1967 Glaser极力反对Strauss将扎根理论程序化，认为Strauss这样做是违背了扎根理论的基本精神——不先入为主的构想问题、提出概念、范畴或假设来强制选择资料和形成理论。在Glaser看来，扎根理论研究的问题不是研究者自己确定的研究问题，而是研究对象所面临的问题，研究者在深入田野工作之前是没有具体研究问题，所有的研究问题、概念及范畴都是随着研究的进展而自然涌现的。而Strauss的程序化版本实际上是在研究之前研究者就有了一个相对完整概念，所谓的“典范矩阵”与“主轴编码”不过是一个生硬促成、事先臆想的概念化描述，是将现有资料填充到预设框架中的过程。 在1992年出版《扎根理论的分析基础：自然呈现与生硬促成》一书中，针对Strauss和Corbin的程序化扎根理论进行批判与回应。 Strauss &amp; Corbin 程序化扎根理论 1990 1990《质性研究基础：扎根理论程序与技术》 在1967年原始版本的基础上，结合具体实践，引入了一些新的概念和方法，如，“维度化”、“主轴编码”和“典范模型”等 Charmaz 建构主义扎根理论 在吸收Glaser和Strauss思想后将建构主义理念与方法融入扎根理论中，并发表了一系列论文与著作，如《建构主义与客观主义扎根理论》、《建构扎根理论：质性研究实践指南》等，由此，也被认定为“建构主义扎根理论”代表。 在Charmaz看来，所有方法论都是人类了解世界的一种方式，人类对世界的理解是一种解释性的，所谓的“真理”与“理论”都具有临时性特征，理论不是被发现的，也不是独立于研究者而存在与数据中，任何理论提供的都是对被研究世界的一种解释性图象，而不是真实面貌。扎根理论也不例外，只是人类理解世界的一种方法论，人类认识世界、理解世界的过程，也是人类与外部世界互动与建构的过程。正因为建构主义思想的引入，使得扎根理论摆脱了实证主义约束，成为一种更具有前瞻性、细致性与反思性的质性研究方法。","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Theorical_Basis","slug":"Theorical-Basis","permalink":"https://zqzhao.cn/tags/Theorical-Basis/"}]},{"title":"Levenberg-Marquardt","slug":"CSMATH-Levenberg-Marquardt","date":"2020-04-25T08:24:31.000Z","updated":"2020-08-10T11:09:54.514Z","comments":true,"path":"2020/04/25/CSMATH-Levenberg-Marquardt/","link":"","permalink":"https://zqzhao.cn/2020/04/25/CSMATH-Levenberg-Marquardt/","excerpt":"","text":"GoalImplement the Levenberg-Marquardt algorithm Design your own test functions, two variable functions are highly recommended. Plot the iteration steps Reading MaterialLevmar Code1234567891011121314151617181920212223242526272829import numpy as npimport pandas as pdimport matplotlib.pyplot as plt# Based on http:&#x2F;&#x2F;users.ics.forth.gr&#x2F;~lourakis&#x2F;levmar&#x2F;levmar.pdf# Using f &#x3D; a*exp(b*x) as primary functionpara_real &#x3D; [1,2] # set primary parameters# set-upk &#x3D; 0k_max &#x3D; 100nu &#x3D; 2 para_quasi &#x3D; [4,5] # set a random parameter set# A &#x3D; J.T.dot(J)# F &#x3D; a*np.exp(b*x)# eps_p &#x3D; a*np.exp(b*x)-y # eps_p is cost function# g &#x3D; J.T.dot(F)tao &#x3D; 10**(-3)# miu &#x3D; tao*np.max(np.linalg.eig(A)[0]) # in course slides is 4.eps1 &#x3D; 10**(-15)eps2 &#x3D; 10**(-15) # 此处在论文中eps1是函数值的threshold, eps2是对变量值的thresholdeps3 &#x3D; 10**(-15) # 此处增加对cost的threshold# stop# stop &#x3D; np.linalg.norm(g, ord&#x3D;np.inf) &lt;&#x3D; eps1# a,b&#x3D;np.linalg.eig(x) ##特征值赋值给a，对应特征向量赋值给b # #特征值全都正，即为正定矩阵 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950def func_F(para, input_data): a &#x3D; [para[0]*np.exp(para[1]*x) for x in input_data] a &#x3D; np.array(a) return a #generating the input_data and output_data,whose shape both is (num_data,1)def Generate(para, data_num): input_data &#x3D; np.array(np.linspace(0,15,data_num)).reshape(data_num,1) # 产生包含噪声的数据 mid,sigma &#x3D; 0,5 output_data &#x3D; func_F(para,input_data) + np.random.normal(mid, sigma, data_num).reshape(data_num,1) return input_data, output_data#calculating the derive of pointed parameter,whose shape is (num_data,1)def Deriv(para_quasi, input_data, para_index):# print(para_index) para_quasi1 &#x3D; para_quasi.copy() para_quasi2 &#x3D; para_quasi.copy() para_quasi1[para_index] +&#x3D; 0.000001 para_quasi2[para_index] -&#x3D; 0.000001 data_est_output1 &#x3D; func_F(para_quasi1,input_data) data_est_output2 &#x3D; func_F(para_quasi2,input_data) a &#x3D; (data_est_output1 - data_est_output2) &#x2F; 0.000002 return (data_est_output1 - data_est_output2) &#x2F; 0.000002 #calculating jacobian matrix,whose shape is (num_data,num_params)def Jacobian(para_quasi, input_data): para_num &#x3D; np.shape(para_quasi)[0] data_num &#x3D; np.shape(input_data)[0] J &#x3D; np.zeros((data_num,para_num)) for i in range(0,para_num): J[:,i] &#x3D; list(Deriv(para_quasi,input_data,i)) return Jdef func_g(para_quasi, input_data, output_real): F &#x3D; func_F(para_quasi, input_data) J &#x3D; Jacobian(para_quasi, input_data) eps_p &#x3D; output_real - F g &#x3D; J.T.dot(eps_p) return g 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566data_num &#x3D; 100para_num &#x3D; 2para_real &#x3D; [1,2] # set primary parameterspara_quasi &#x3D; [4,5] # set a random parameter setinput_data, output_real &#x3D; Generate(para_real, data_num)k &#x3D; 0k_max &#x3D; 10000nu &#x3D; 2 J &#x3D; Jacobian(para_quasi, input_data)A &#x3D; J.T.dot(J)# F &#x3D; a*np.exp(b*x)# eps_p &#x3D; a*np.exp(b*x)-y # eps_p is cost functiong &#x3D; func_g(para_quasi, input_data, output_real)eps1 &#x3D; 10**(-12)tao &#x3D; 10**(-3)miu &#x3D; tao*np.max(np.linalg.eig(A)[0]) # in course slides is 4.stop &#x3D; np.linalg.norm(g, ord&#x3D;np.inf) &lt;&#x3D; eps1delta &#x3D; [] # 一个用来放cost的没用数组while (not stop) and (k &lt; k_max): k +&#x3D; 1 print(k) while(True): s &#x3D; np.linalg.inv(A + miu*np.eye(para_num)).dot(g) print(&#39; &#39;, np.linalg.norm(s)) if np.linalg.norm(s) &lt;&#x3D; eps2: stop &#x3D; True else: F &#x3D; func_F(para_quasi, input_data) eps_p &#x3D; output_real - F delta.append(sum([x**2 for x in (eps_p.T).tolist()[0]])) para_quasi_new &#x3D; [para_quasi[0] + s[0,0], para_quasi[1] + s[1,0]] print(&#39; &#39;, para_quasi_new) F_new &#x3D; func_F(para_quasi_new, input_data) eps_p_new &#x3D; output_real - F_new rou &#x3D; (np.linalg.norm(eps_p)**2 - np.linalg.norm(eps_p_new)**2) &#x2F; (s.T.dot(miu*s + g)) # print(&#39;rou &#x3D; &#39;, rou[0][0]) # 不知道为什么rou是[[x]]形式的 rou &#x3D; rou[0][0] if rou &gt; 0: para_quasi &#x3D; para_quasi_new J &#x3D; Jacobian(para_quasi, input_data) A &#x3D; J.T.dot(J) eps_p &#x3D; eps_p_new g &#x3D; func_g(para_quasi, input_data, output_real) stop &#x3D; np.linalg.norm(g, ord&#x3D;np.inf) &lt;&#x3D; eps1 or np.linalg.norm(eps_p)**2 &lt;&#x3D; eps3 miu &#x3D; miu*max(1&#x2F;3, 1-(2*rou-1)**3) nu &#x3D; 2 else: miu &#x3D; miu*nu nu *&#x3D; 2 print(&quot; [miu, nu] &#x3D; &quot;, miu,&#39; , &#39;, nu) if rou &gt; 0 or stop: breakdelta.append(sum([x**2 for x in (eps_p.T).tolist()[0]]))print(para_quasi)# print(para_real)# print(delta) 1234567891011121314151617plt.plot(range(0, len(delta)), delta)plt.xlabel(&quot;iteration times&quot;)plt.ylabel(&quot;eps_p squared sum&quot;)plt.title(&quot;eps_p squared sum (error)&quot;)plt.show()# plt.scatter(input_data, output_real, color&#x3D;&#39;b&#39;, s&#x3D;)plt.plot(range(0, 16), func_F(para_real, range(0, 16)), color&#x3D;&#39;g&#39;, )plt.scatter(input_data, func_F(para_quasi, input_data), color&#x3D;&#39;r&#39;)# plt.plot(range(0, 10), func_F(para_quasi, range(0, 10)), color&#x3D;&#39;purple&#39;)# 用估计的点和原函数看下拟合结果plt.xlabel(&quot;x&quot;)plt.ylabel(&quot;y&quot;)plt.title(&quot;estimation result&quot;)plt.show() Result","categories":[],"tags":[{"name":"CS_Math","slug":"CS-Math","permalink":"https://zqzhao.cn/tags/CS-Math/"}]},{"title":"Experiment","slug":"AMR-experiment","date":"2020-04-25T03:56:29.000Z","updated":"2020-08-09T09:21:48.200Z","comments":true,"path":"2020/04/25/AMR-experiment/","link":"","permalink":"https://zqzhao.cn/2020/04/25/AMR-experiment/","excerpt":"","text":"行为经济学（Behavioral Economics）是将心理学的研究成果引入经济分析的经济学新分支，而实验经济学（Experimental Economics）是行为经济学模型的主要实证手段。行为经济学的研究经过了三代学者的发展。20世纪80—90年代，第一代行为经济学家指出了传统经济理论无法解释的异常现象（如，禀赋效应、阿莱悖论、经济衰退中的工资刚性等）；而20世纪90年代至21世纪初，第二代行为经济学家针对上述心理现象建立一般性的理论模型，如，level-k学习模型、以负罪厌恶为基础的守约模型等；而最近几年第三代行为经济学的研究人员开始将第二代的研究成果运用到应用领域中去，而行为合约设计就是其中的热点。比如，劳动力市场的合约设计将在本文第四部分详细讨论。 sohu博客 （一）科学研究中的内部有效性和外部有效性 任何一种科学研究，都面临着内部有效性和外部有效性两方面的挑战。内部有效性（Internal Validity）是指，研究人员分析某一种特定因素所造成的效果时，一定不能把其他原因造成的效果错误地归结到被研究的对象上。比如，当我们分析一种药物对心血管疾病的疗效时，如果病情较重的人服用了药物而病情较轻的人未服药，那么病情的轻重程度会对分析结论造成干扰；如果参加某种劳动技能培训的人的智力水平高于未参加培训的人的智力水平，那么研究人员所观察到的“技能培训的效果”有可能来自智力水平的差别。而外部有效性（External Validity）是指，从有限样本中得出的研究结论，究竟在多大程度上能推广到总体中去。比如，某一种药在美国的临床实践中取得了效果，那么这种药能否在中国的临床中取得效果？如果理论经济学家所设计出来的市场机制通过经济实验取得了成功，那么这一机制在现实生活中的效果又会如何？ 首先需要指出的是，确保内部有效性是所有研究工作的起点。误读了经济现象背后的真实原因，无论其应用环境是否贴近现实，都必然会误导政策制定与制度安排。在内部有效性得到保证的基础上，研究人员再继续探讨研究结论的外部有效性，即研究结论的适用范围（比如，无论经济学理论研究还是经济学实证研究，都有针对经济学理论模型或实证数据分析的Robustness Check，即适用性检验）。其次需要指出的是，没有任何一种经济学研究方法能在内部有效性和外部有效性两方面同时做到完美，理论（Theories）、实验（Experiments）和观察性实证方法（Observational Empirical Methods）各有所长。经济学实验在经济学的实证研究方法中是内部有效性最强的研究手段，其代价是外部有效性受到一定限制。 （二）经济实验：通过“控制”实现内部有效性 经济实验的本质，就是通过研究人员对实验的“控制”实现内部有效性。经济实验中的控制手段包括：研究人员将来自同一群体（如某高校的本科生）的实验参加者随机分配到不同的实验条件中去、以消除不同实验条件下的参加者的系统性差异，从而不同实验条件下实验结果的差异只能归结于不同实验条件下实验设置的差别，而不能归结于不同实验条件下参加者的差异；在同一实验设置下参加者阅读相同的实验说明，以确保参加者接受相同的信息；实验说明中通常采用中性词语，以避免与研究问题无关的社会偏好对实验结果造成干扰……等。朱富强一文中所讨论的“双盲设计”（即实验参加者之间相互匿名，且参加者对研究人员也匿名），也是一种常见的实验控制手段。“双盲设计”能降低研究人员的观察效应、社会距离等因素对实验结果的干扰。 第一点需要澄清的是，研究人员通过实验设计对实验进行控制的目的，是为了实现内部有效性，而不是像朱富强一文所提到的为了迎合“主流经济学”、确保主流经济理论中的结论被实验验证。以Hoffman，McCabe，Shachat，Smith的研究工作为例（这一工作也在朱富强一文中提到了）：一名实验参加者是分配者，另一名实验参加者是接受者；由分配者将10美元在分配者与接受者之间分配，而接受者只能接受分配者的提案、没有讨价还价的余地。在传统经济学的自利前提下，理论预测分配者会将全部10美元归为己有。但实验结果表明，即便是在双盲设计下，作为分配者的参加者通常会留1到2美元给接受者。这个实验的证据表明利他偏好（Other-Regarding Preference）确实会在经济活动中发挥作用，按照朱富强一文的分类方法，这一实验应该是属于“反主流”的。恰恰是“双盲设计”等严格的实验控制手段，使得Hoffman等人的研究结论更加稳健：即便是在最容易出现自利行为的双盲设计下，研究人员都观察到了利他行为，从而我们很难把这种利他行为归结于研究人员的压力或诱导等其他原因。 第二点需要澄清的是，实验控制从未将实验参加者的社会性抽象掉，“最大限度地将受试者还原为孤立的原子个体，甚至是类似机器般的成本——收益反应者”。经济学理论的出发点，包括关于经济环境的结构性假设和关于经济活动参与主体的行为假设两类。经济实验通过控制，能在实验环境中最大程度再现经济学理论中的结构性假设（如初始禀赋的分布、成本的结构，等等），但实验设计中并不对实验参加者的行为进行假设（参加者是否能够充分有效处理全部信息、是否逆向归纳，等等）。因此，如果实验表明理论失效，能够相对容易地得知理论失效的原因（比如，可以进一步通过实验验证究竟是哪一条行为假设脱离实际情况）。而通过现实生活中的数据检验理论，其难点在于现实生活与经济学理论中的结构性假设存在距离，从而很难确定理论失效的具体原因。 （三）实地实验：对实验结论外部有效性的回应 近年来，学界对经济学实验的批评集中在实验结论的外部有效性上。比如，经济学的实验室实验通常征召本科生作为实验参加者，支付相对较低的报酬，而实验在较短的时间内完成。那么如果参加者群体发生变化（如有丰富经验的从业者）、报酬规模发生变化、实验环境是现实生活中的市场，实验结论是否也会发生变化？ 21世纪日益受到重视的实地实验（Field Experiment）是对这类质疑的有力回应。实地实验是介于实验室实验和完全基于现实市场所自然产生的数据的观察性实证方法之间的一种实证手段。实地实验与实验室实验相同的是，研究人员将实验参与者随机分配到不同实验条件中去，从而能有效避免样本选择或内生性造成的系统性偏差。但实地实验在现实生活中的市场里进行，从而研究人员对实验的控制不如实验室实验完美（如研究人员很难在现实生活中控制价值、成本、信息等因素）。实证方法中，从内部有效性来说，实验室实验最强，实地实验次之，观察性实证方法最弱；从外部有效性来说，顺序正好颠倒：观察性实证方法最强，实地实验次之，实验室实验最弱。","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Theorical_Basis","slug":"Theorical-Basis","permalink":"https://zqzhao.cn/tags/Theorical-Basis/"}]},{"title":"Examination & Check","slug":"AMR-examination","date":"2020-04-18T10:57:34.000Z","updated":"2020-08-09T09:21:18.422Z","comments":true,"path":"2020/04/18/AMR-examination/","link":"","permalink":"https://zqzhao.cn/2020/04/18/AMR-examination/","excerpt":"","text":"What’s the difference between Post-Hoc Examination, Validity Examination, and Robustness Check? Post-Hoc ExaminationAfter review, the examination asked by the reviewers.Usually, post-hoc examination can mend the obvious flaws in your research. Sometimes, the robustness check can be the representative part of the research.See below. Sun, H., Wright, R. T., &amp; Thatcher, J. (2019). Revisiting the impact of system use on task performance: an exploitative-explorative system use framework. Journal of the Association for Information Systems, 20(4), 3. In this paper, Study 2 is post-hoc examination. Due to the requirement from reviewers, the authors conduct the second study, which is a much more complete and solid one than the former. Validity ExaminationWhen we talk about the validity examination, the first question is whether the scale has a proper conceptual framework. Then, we look into the validity of the scale. Robustness CheckMainly, the robustness check is divided into three categories. NEED FURTHER CHECK. Change the Variables ❓ Change the Model ✔️ Change the Data ✔️","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Theorical_Basis","slug":"Theorical-Basis","permalink":"https://zqzhao.cn/tags/Theorical-Basis/"}]},{"title":"NK-model","slug":"Seminar-nk-model","date":"2020-04-17T12:47:35.000Z","updated":"2020-08-09T09:24:21.983Z","comments":true,"path":"2020/04/17/Seminar-nk-model/","link":"","permalink":"https://zqzhao.cn/2020/04/17/Seminar-nk-model/","excerpt":"","text":"McCarthy, I. P., &amp; Tan, Y. K. (2000). Manufacturing competitiveness and fitness landscape theory. Journal of Materials Processing Technology, 107(1-3), 347-352. Esteve Almirall, Ramon Casadesus-Masanell. (2010). Open Versus Closed Innovation: A Model of Discovery and Divergence. Academy of Management Review, Vol. 35, No. 1, 27–47. Sina Blog: 研究工具 - NK MODEL 本文参考了上述材料以及人大经管论坛，现简要陈述NK MODEL如下。非常凑巧的是，这篇博客中的引文是AMR的这篇，正好是本周管理系统模块的选读论文。因此作为NK MODEL的入门文章，应当以此举例。 Link between NK-Model and FLTNK Model脱胎于Fitness Landscape Theory。 What is Fitness Landscape Theory? Fitness Landscape Theory类似于生态学中生态位的概念 对于某一物种而言，不同资源组合会形成适应度不同的环境 在诸多环境中，有几种bundle会特别适合这一物种，称为生态位（此处可以参考经济学中“预算束”的概念） 以资源建立空间坐标系（若有k个资源，即有k维空间），适应度在这一空间内应当形成类似于GMM图像的分布，即Fitness Landscape NK模型研究适用于处理系统内部要素的相互作用关系对系统的整体适应性的问题。由于系统存在复杂性，实证研究无法直接研究各要素间的相互关系以及各要素对系统整体的影响，此时NK模型提供一个间接、简洁、有效的手段对系统进行仿真。 NK模型的理解可以遵循基因型与表型的对应理解。（Kauffman）对应到上述Fitness Landscape Theory，基因型（genotype）的不同组合在此处对应着Fitness Landscape Theory中对资源的不同组合，表型（phenotype）的不同组合在此处对应系统最终的状态。系统的进化，或者说最优解，其实就是生物进化中的最终形态（在自然选择中当前总是保持最适）。NK MODEL本质上是一个进化算法。 基因之间存在交互作用，改变一个基因型并不意味着改变了单一表型而是对整体产生了影响，甚至影响的正面负面也会受到其他基因的调控。这种条件之间的Trade-off即NK模型的研究中心。 NK-Model NK-Model将复杂系统描述为一个由N个元素构成的系统，其中每个元素i都有各自的等位基因。例如$A_i=3$即为第i个元素有3个等位基因。现在我们为每个元素，从其等位基因集合中选出一个基因，则有Feature Vector$&lt; s_1, s_2, …, s_N &gt;$，那么这个Vector即通过限定特征对应了某一System。 在(Almirall, Casadesus-Masanell, 2010)中，将一个完整的System（在文中Syestem即某一Product）均分为2 Subsystem，所以有$&lt;\\alpha, \\beta&gt; = &lt; s_1, s_2, …, s_N &gt; = &lt; s_1, s_2, …, s_{N/2};s_{N/2 + 1}, …, s_N &gt;$。 至此已经解释了NK模型中“N”的含义，最后为“N”Part作结，我们引入系统的设计空间的概念。系统的设计空间（Design Space）即由N个feature组成的N维概率空间。空间的具体大小为$\\Pi_{i=1}^{N}A_i$，也就是组合数。 在(Almirall, Casadesus-Masanell, 2010)中，为了计算方便起见，每个Feature仅有2个等位基因，即设计空间大小为$2^N$。 现在我们要解释K的作用。K衡量的是元素间的interaction，即该系统中每个元素i都与k个其他元素进行交互，即系统复杂度。 在(Almirall, Casadesus-Masanell, 2010)中，对这一部分的描述原文摘录如下： There are $2^N$ possible product configurations. The contribution $c_i$ of each product feature $s_i$ to willingness to pay dependents on other K components. For each of $2^K$ possible combinations, a value is drawn from a uniform probability distribution on [0, 1]. The overall willingness to pay associated with $$ is the average over the N value contributions, WTP(s_1, s_2, ..., s_N) = \\dfrac{\\sum_{i=1}^{N}c_i(s_i; s_{i_1}, s_{i_2}, ..., s_{s_k})}{N}Where $s_{i_j}$, $j=\\{1, …, k\\}$ are the configurations of the K features with which $s_i$ interacts. We assume random assignment of dependencies($i_j$ are determined randomly in the model). 文章的细节还没看完有待补充，NK模型已经解释完毕。","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Theorical_Basis","slug":"Theorical-Basis","permalink":"https://zqzhao.cn/tags/Theorical-Basis/"}]},{"title":"Agent Based Model","slug":"Seminar-agent-based-model","date":"2020-04-09T11:11:06.000Z","updated":"2021-09-14T07:20:21.015Z","comments":true,"path":"2020/04/09/Seminar-agent-based-model/","link":"","permalink":"https://zqzhao.cn/2020/04/09/Seminar-agent-based-model/","excerpt":"","text":"Reading Materials: Major Material Nan 2017-Unifying the Role of IT in Hyperturbulence and Competitive Advantage Via a Multilevel Perspective of IS Strategy Reading Material An, 2012 Axtell, 1996 Bonabeau, 2002 García-Callejas Grimm, 2006 Grimm, 2016 Related papersAgent-based modeling on technological innovation as an evolutionary process 10.1016/j.ejor.2004.01.055 This paper describes a multi-agent model built to simulate the process of technological innovation, based on the widely accepted theory that technological innovation can be seen as an evolutionary process. The actors in the simulation include producers and a large number of consumers. Every producer will produce several types of products at each step. Each product is composed of several design parameters and several performance parameters (fitness components). Kauffman’s famous NK model is used to deal with the mapping from a design parameter space (DPS) to a performance parameter space (PPS). In addition to the constructional selection, which can be illustrated by the NK model, we added environmental selection into the simulation and explored technological innovation as the result of the interaction between these two kinds of selection. © 2004 Elsevier B.V. All rights reserved. An evolutionary framework for service innovation: Insights of complexity theory for service science 10.1016/j.ijpe.2011.10.015 There is an increasing need for a theory-based and industry-oriented framework for service innovation in both research and practice. However the study of service innovation has been somewhat limited. This paper applies two models of complexity theory (Kauffmans NK model in biology and organizational ambidexterity in organization science) for service innovation and proposes a novel perspective on service innovation as an evolutionary process, which is interactive, local, unpredictable, and emergent. The paper also proposes a typology of service innovation that includes eight different strategic orientations of service innovation; also included are illustrations from a knowledge-intensive service industry, particularly the IT-based consulting and service industry sector. Drawing from this complexity theory perspective, the paper discusses numerous implications for future conceptualization of service, multidimensionality of service innovation, and service innovation strategies. © 2011 Elsevier B.V. All Rights Reserved. NK model as a representation of innovative search 10.1016/j.respol.2017.08.009 The process of innovation is frequently modeled as a bounded, iterative, trial-and-error search over a complex landscape using an NK model. An important question, however, is whether such theoretical approximation is consistent with empirical data. Prior work tested specific insights of the NK model while yielding mixed evidence. I examine how the full set of predictions generated by the NK model map onto observed empirical patterns while relying on commonly used patent-based measures of complexity. While the fit between the predictions and data is not perfect, I find that the ability of the NK model to capture innovative processes is better than previously thought. While doing so, I draw attention to potential boundary conditions for both the applicability of the model and usefulness of the measures. The study sheds new light on an important discussion within the field of innovation and technology management and helps to bridge the gap between the NK model and its empirical implementation. E-marketing services and e-marketing performance: the roles of innovation, knowledge complexity and environmental turbulence in influencing the relationship 10.1080/0267257X.2015.1102758 The business-to-business electronic marketplace (e-marketplace) is becoming critical for small- and medium-sized enterprises (SMEs). However, which e-marketing services determine a firm’s e-marketing performance and how innovation, knowledge complexity and environmental turbulence influence the relationship between e-marketing services and e-marketing performance are under-researched topics in the field. We first empirically tested 176 SMEs from China to evaluate which e-marketing services are significantly related to e-marketing performance and how these services collectively influence the performance. Then, we used an NK model to examine how innovation, knowledge complexity and environmental turbulence mediate/moderate the relationship. The results show that five e-marketing services (e-CRM, e-SCM, e-competitiveness, IS/IT integration and information transparency) can greatly influence e-marketing performance; innovation positively mediates the relationship between e-marketing services and performance; and knowledge complexity and environmental turbulence positively moderate the relationship.","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Theorical_Basis","slug":"Theorical-Basis","permalink":"https://zqzhao.cn/tags/Theorical-Basis/"}]},{"title":"MISQ Research Curation on IS Use","slug":"Seminar-Burton-summary","date":"2020-04-05T08:28:07.000Z","updated":"2020-04-17T12:48:09.012Z","comments":true,"path":"2020/04/05/Seminar-Burton-summary/","link":"","permalink":"https://zqzhao.cn/2020/04/05/Seminar-Burton-summary/","excerpt":"","text":"Burton-Jones, A., Stein, M., Mishra, A. “IS Use,” in MIS Quarterly Research Curations, Ashley Bush and Arun Rai, Eds., http://misq.org/research-curations, December 1, 2017.MIS Quarterly Articles on IS Use Files here. This article is primarily an overview of the research content and the research methods used in IS use related article. Now, I’ll briefly summarize the article and give my comments. Focus of the Research CurationThis part introduce how they retrieve the previous article and determine the rim of dataset, actually “Paper Set” here. The standards is full of manipulation. The main procedure is shown as follow: Segment all the article based on the publish year: 1977-1999, 2000- Determine the search term also based on the publish year Exclude articles focused PURELY on users’ intentions, attitudes, behaviors etc. Exclude articles focused on misuse, abuse and addiction. The author also mention that they include or exclude an article based on their “collective judgement”. Progression of Research in MISQThis part summarize the revolutionary change and evolutionary change in IS use. One steady topic is the importance and the complexity of the IS use. This theme gradually develops since 1977 and still thrive nowadays. However, the sophistication in term measurement and theoretical basis allow researchers to discuss an old terminology in new context. (The article refer to which as the theoretical and empirical research.) “They can account for it with theories and methods that are sensitive to longitudinal, multilevel, and multifactorial contexts rather than reducing the reality of IS use into cross-sectional, single-level, and single-theory thinking.” About 2000, a novel branch of IS acceptance appears, which is due to the broken burble economy of Internet. I think it also devotes to the separation of the publish period. Thematic Advances in KnowledgeFour major thematic advances are mentioned here. Application, refinement, and integrations of various social psychological explanations of It acceptance. Development of theories to account for the dynamics of use. Richer measurement and methodological approaches Continuing expansion of the broader network of constructs. My CommentsWhen looking into the appendix, we find out that in early age of IT use, most of researchers use conceptual framework or qualitative methods while in later period they turn to quantitative methods. My question is : Could the quantitative methods help to clarify or refine the concepts? If so, how? Quantitative methods rely on theoretical basis to consolidate its validity, how can they help to refine the concept? Will the concept or the definition of IT use augment in future? If so, we still need to focus on qualitative methods. Mixed methods research gains its popularity in recent years. What is the exact definition mixed methods research? A SEM combines both qualitative data and quantitative data? Or a three-stage research including qualitative case helps refining the framework and a quantitative method validate the hypothesis?","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"MIS_thinking","slug":"MIS-thinking","permalink":"https://zqzhao.cn/tags/MIS-thinking/"}]},{"title":"Formative Construct and Reflective Construct","slug":"Seminar-construct","date":"2020-04-05T03:41:10.000Z","updated":"2020-08-09T09:24:07.443Z","comments":true,"path":"2020/04/05/Seminar-construct/","link":"","permalink":"https://zqzhao.cn/2020/04/05/Seminar-construct/","excerpt":"","text":"Reading Materials: MISQ 1MacKenzie.pdf 2REVISITING_BIAS 3CRITICAL_IMPORTANCE 4NEGATIVE_CONSEQUENCES 5PLS-SEM Detmar Straub Speech notes","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Theorical_Basis","slug":"Theorical-Basis","permalink":"https://zqzhao.cn/tags/Theorical-Basis/"}]},{"title":"GMM","slug":"CSMATH-GMM","date":"2020-03-31T04:02:31.000Z","updated":"2020-08-10T09:05:33.025Z","comments":true,"path":"2020/03/31/CSMATH-GMM/","link":"","permalink":"https://zqzhao.cn/2020/03/31/CSMATH-GMM/","excerpt":"","text":"一些参考资料# 如何实现GMM的概率密度函数 def p(x, mu, sigma): n = len(x) div = (2 * np.pi) ** (n / 2) * (abs(np.linalg.det(sigma)) ** 0.5) expOn = -0.5 * ( np.dot( (x - mu).T, np.dot(np.linalg.inv(sigma), (x - mu)) ) ) return np.exp(expOn) / div 什么是GMM 区别一维单高斯、多维单高斯、混合多高斯 区别一维单高斯、多维单高斯、混合多高斯1 区别一维单高斯、多维单高斯、混合多高斯2 区别一维单高斯、多维单高斯、混合多高斯3 协方差的直观理解 矩阵的负二分之一怎么计算1 矩阵的负二分之一怎么计算2第二个人写的矩阵乘法用dot比较合规 |A|其实是行列式运算 Code 注意区分一维单高斯模型、多维单高斯模型和混合高斯模型 其差别在于单高斯模型SGM总是只有一个峰，不管是在几维空间内总是只有一个峰值 混合高斯模型是多个单高斯模型的概率叠加（这里的SGM不一定是一维内的，也可以是多维的） 一维单高斯模型即正态分布； 多维单高斯模型是在各个维度上分别应用一维单高斯模型，然后通过协方差矩阵刻画维度间相关关系（正相关、负相关、不相关） （下文中将在各个维度中应用标准正态，但事实上或许可以是不标准的正态分布，有待后续尝试） 混合高斯模型相当于samples落在了多个单高斯模型中 （以一个1000Samples，p=[0.4 0.6]的双峰GMM为例，相当于在第一个模型中有400个Samples，而另一个包括600Samples） 1234567import numpy as npimport mathimport random import scipy.stats as stimport matplotlib.pyplot as plt 123456789101112131415161718192021222324252627282930313233343536# 以下试图生成一组符合多维单高斯模型的数据点（此处为2D Gaussian）# 每个维度做SGM 然后x &#x3D; Sigma^0.5*z + mux &#x3D; np.random.uniform(size&#x3D;1000) # Random sequence used for x axisy &#x3D; np.random.uniform(size&#x3D;1000)axis &#x3D; [] # zfor i in range(0, len(x)): x1 &#x3D; st.norm.ppf(x[i], loc&#x3D;0, scale&#x3D;1) # 均值为 loc，标准差为 scale 的正态分布在 each 处的累计分布概率值 y1 &#x3D; st.norm.ppf(y[i], loc&#x3D;0, scale&#x3D;1) axis.append([x1,y1]) axis &#x3D; np.array(axis).T # 这里生成成对的z坐标，单独的z_x和z_y符合标准正态# 以下求sigma的1&#x2F;2次方A &#x3D; np.array([1, 4, 3, 16]).reshape(2,2)v, Q &#x3D; np.linalg.eigh(A) # v 为特征值, Q 为特征向量V &#x3D; np.diag(v**(0.5))Sigma &#x3D; Q.dot(V).dot(np.linalg.inv(Q)) # 得到协方差矩阵的1&#x2F;2次方后，可以对z坐标进行偏置# 协方差矩Sigma阵刻画的是数据点在正交轴的拉伸# 均值mu类似于质心，刻画的是数据点的中心位置漂移 x &#x3D; Sigma.dot(axis).T # x &#x3D; Sigma^0.5*z + mu 这一步做的是数据点的拉伸# 以下生成mu，这里用了很蠢的生成方法，选取的质心是(4,7)m &#x3D; [4 for i in range(0,1000)]for i in range(0,1000): m.append(7)center &#x3D; np.array(m).reshape(2,1000).Tx &#x3D; x + center # x &#x3D; Sigma^0.5*z + mu 这一步做的是质心漂移plt.figure()plt.scatter(x&#x3D;[each[0] for each in x], y&#x3D;[each[1] for each in x])plt.show() 12345678910111213141516171819202122232425262728293031# 以下试图生成一组符合多维单高斯模型的数据点（此处为2D Gaussian）# 每个维度中的默认单高斯模型为标准正态分布def SGM(n, sigma, mu, d&#x3D;2): x &#x3D; np.random.uniform(size&#x3D;n) # Random sequence used for x axis y &#x3D; np.random.uniform(size&#x3D;n) axis &#x3D; [] # z for i in range(0, n): x1 &#x3D; st.norm.ppf(x[i], loc&#x3D;0, scale&#x3D;1) # 均值为 loc，标准差为 scale 的正态分布在 each 处的累计分布概率值 y1 &#x3D; st.norm.ppf(y[i], loc&#x3D;0, scale&#x3D;1) axis.append([x1,y1]) axis &#x3D; np.array(axis).T # 这里生成成对的z坐标，单独的z_x和z_y符合标准正态 # 以下求sigma的1&#x2F;2次方 A &#x3D; np.array(sigma).reshape(d,d) # 注意区分此处的sigma和下文中的Sigma，变量命名还需要注意 v, Q &#x3D; np.linalg.eigh(A) # v 为特征值, Q 为特征向量 V &#x3D; np.diag(v**(0.5)) Sigma &#x3D; Q.dot(V).dot(np.linalg.inv(Q)) x &#x3D; Sigma.dot(axis).T # x &#x3D; Sigma^0.5*z + mu 这一步做的是数据点的拉伸 m &#x3D; [mu[0] for i in range(0,n)] for i in range(0,n): m.append(mu[1]) center &#x3D; np.array(m).reshape(d,n).T x &#x3D; x + center # x &#x3D; Sigma^0.5*z + mu 这一步做的是质心漂移 return x 123456789# 以下试图生成一组符合多2D Mixture of Gaussian (MOG) distribution的数据点# 每个维度中的默认单高斯模型为标准正态分布x1 &#x3D; SGM(n&#x3D;50, sigma&#x3D;[1, 6, 2, 12], mu&#x3D;[5,10], d&#x3D;2)x2 &#x3D; SGM(n&#x3D;100, sigma&#x3D;[9, 4, 2, 1], mu&#x3D;[8,4], d&#x3D;2)plt.figure()plt.scatter(x&#x3D;[each[0] for each in x1], y&#x3D;[each[1] for each in x1], c&#x3D;&#39;blue&#39;)plt.scatter(x&#x3D;[each[0] for each in x2], y&#x3D;[each[1] for each in x2], c&#x3D;&#39;red&#39;)plt.show() 12# 以下合并两个点集total_set &#x3D; np.vstack((x1, x2)) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 以下试图计算每个cluster内的点并打上标记，并试图应用一种pycharm风格的函数注释def cal(cluster, temp_centroid, radius, eps, node, total_set, empty): &quot;&quot;&quot; used for calculate distance between nodes and centroid cluster: the number of cluster temp_centroid: temportary centroid location radius: radius eps: threshold to end the process node: used to illustrate to which cluster the node belongs and the times of calculation in process total_set: locations of nodes empty: 用于标记未使用的点，事实上通过字典查找可以实现，偷个懒浪费内存了，甚至懒得改写成英文 return: node, empty, cent_x, cent_y # cent_? is the final location of temporary cluster &quot;&quot;&quot; print(temp_centroid) cent_x &#x3D; temp_centroid[0] cent_y &#x3D; temp_centroid[1] node_temp &#x3D; [0 for i in range(0, len(total_set))] while True: shift &#x3D; [0, 0] print([cent_x, cent_y]) for i in range(0, len(total_set)): x &#x3D; total_set[i][0] y &#x3D; total_set[i][1] distance2 &#x3D; (x - cent_x)**2 + (y - cent_y)**2 distance &#x3D; math.sqrt(distance2) if distance &lt;&#x3D; radius: # if node in cluster node_temp[i] +&#x3D; 1 try: # 其实本cluster出现并不代表节点是第一次被分类，但我懒得写了，trycatch大法好 empty.remove(i) # delete node already in some cluster except Exception as e: pass shift[0] +&#x3D; x - cent_x shift[1] +&#x3D; y - cent_y # add shift vector mode &#x3D; shift[0]**2 + shift[1]**2 print(&#39;mode&#x3D;&#39;,mode) if mode &lt;&#x3D; eps: break else: cent_x +&#x3D; shift[0]&#x2F;len(total_set) cent_y +&#x3D; shift[1]&#x2F;len(total_set) node.append(node_temp) return node, empty, cent_x, cent_y 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364# Mean Shiftn_of_node &#x3D; len(total_set) # number of nodesprint(1)# 以下为centroid和node初始化centroid &#x3D; [] node &#x3D; [] # 后续通过list形式追加cluster标记，每一个cluster有一行# 以下为node标记做初始化empty &#x3D; [int(i) for i in range(0, n_of_node)] # 用于标记未使用的点temp &#x3D; random.choice(empty) # 每次在未标记点选一个作为当前质心起始点temp_centroid &#x3D; total_set[temp]cluster &#x3D; 0radius &#x3D; 4eps &#x3D; 0.01# 以下得到cluster和node的pairwhile True: node, empty, cent_x, cent_y &#x3D; cal(cluster, temp_centroid, radius, eps, node, total_set, empty) centroid.append([cent_x, cent_y]) print(&#39;cluster&#x3D;&#39;, cluster, &#39; ,cent_num &#x3D;&#39;, len(centroid)) print(node[-1]) for i in range(0, len(centroid)-1): # 考虑合并 distance &#x3D; (centroid[i][0]-centroid[-1][0])**2 + (centroid[i][1]-centroid[-1][1])**2 if math.sqrt(distance) &lt;&#x3D; radius: for j in range(0, len(total_set)): node[i][j] +&#x3D; node[-1][j] node &#x3D; node[:-1] x1 &#x3D; centroid[i][0] x2 &#x3D; centroid[-1][0] y1 &#x3D; centroid[i][1] y2 &#x3D; centroid[-1][1] n1 &#x3D; 0 n2 &#x3D; 0 for k in range(0, len(total_set)): if node[i][k] !&#x3D; 0: n1 +&#x3D; 1 if node[-1][k] !&#x3D; 0: n2 +&#x3D; 1 new_centroid &#x3D; [(n1*x1+n2*x2)&#x2F;(n1+n2), (n1*y1+n2*y2)&#x2F;(n1+n2)] centroid[i] &#x3D; new_centroid centroid &#x3D; centroid[:-1] break if empty &#x3D;&#x3D; []: break else: # update default value cluster +&#x3D; 1 temp &#x3D; random.choice(empty) # 每次在未标记点选一个作为当前质心起始点 temp_centroid &#x3D; total_set[temp]print(node)print(&#39;end&#39;)print(&#39;cluster&#x3D;&#39;, cluster)# 这里有两种合并cluster的做法 # 第一种在每次生成新的cluster以后进行合并，本次作业选择第一种# 第二种在全部结束后观察质心间关系，寻找无向图的component 123456789101112131415161718192021222324252627# 以下尝试构建cluster与点集对应关系result &#x3D; []print(node)for i in range(0, len(total_set)): temp &#x3D; -1 max_v &#x3D; -1 for j in range(0, len(node)): if node[j][i] &gt;&#x3D; max_v: max_v &#x3D; node[j][i] temp &#x3D; j result.append(temp)print(centroid)x_axis &#x3D; [[] for i in range(0, len(centroid))]y_axis &#x3D; [[] for i in range(0, len(centroid))]for i in range(0, len(total_set)): x_axis[result[i]].append(total_set[i][0]) y_axis[result[i]].append(total_set[i][1])plt.figure()for i in range(0, len(centroid)): plt.scatter(x&#x3D;x_axis[i], y&#x3D;y_axis[i])plt.show()","categories":[],"tags":[{"name":"CS_Math","slug":"CS-Math","permalink":"https://zqzhao.cn/tags/CS-Math/"}]},{"title":"SVD","slug":"CSMATH-SVD","date":"2020-03-18T10:05:32.000Z","updated":"2020-08-10T09:04:47.353Z","comments":true,"path":"2020/03/18/CSMATH-SVD/","link":"","permalink":"https://zqzhao.cn/2020/03/18/CSMATH-SVD/","excerpt":"","text":"参考资料和笔记SVD（奇异值分解）Python实现 以及我的个人笔记EVD_and_SVD.pdf Code Dataset使用手写数字识别 以下仅保留数学部分实现 123456789101112131415161718192021# 提取data &#x3D;&gt; 130个3, &quot;32*32&quot; &#x3D;&gt; &quot;16*16&quot;# 这里没有做pixel合并raw_data &#x3D; digitals[3][:130]data &#x3D; []for each in raw_data: # 32*32 &#x3D;&gt; 16*16 line &#x3D; [] for i in range(0, 32, 2): for j in range(0, 32, 2):# pixel &#x3D; eval(each[i][j])# pixel +&#x3D; eval(each[i+1][j])# pixel +&#x3D; eval(each[i][j+1])# pixel +&#x3D; eval(each[i+1][j+1]) # 4个pixel合成一个，类似CNN without overlap line.append(each[i][j]) a &#x3D; np.array(line) data.append(a)# print(a.shape)matrix &#x3D; np.array(data, dtype&#x3D;np.float) # 已经完成转置 X(N,p) &#x3D; X(130, 256) 12345# 对matrix做一步均值化处理matrix_mean &#x3D; np.mean(matrix, axis&#x3D;0)matrix &#x3D; matrix - matrix_mean 1234567891011121314151617181920212223242526272829303132333435# 把取前k个奇异值的操作写成函数，算一下MSE# 此处要注意，奇异值里有一个小于0的值（为什么呢？）# 所以在这一步先进行了前k个的筛选再开方，避免了这一问题def sig(k, matrix): # What if 只取前k个奇异值？ # k &#x3D; 4 # 求奇异值矩阵和左右奇异矩阵 # A &#x3D; U(mxm)E(mxn)V^T(nxn ) || AA^T &#x3D; UEE^TU^T sigma, u &#x3D; np.linalg.eigh(matrix.dot(matrix.T)) # 得到E和U sigma_sort_index &#x3D; np.argsort(sigma)[::-1] # 得到降序排列特征值对应index sigma_sort &#x3D; np.sort(sigma)[::-1] # 得到降序排列特征值 sigma_sort_sqrt &#x3D; np.sqrt(sigma_sort[:k]) # 奇异值 &#x3D; sqrt(T*T) u_sort &#x3D; u[:, sigma_sort_index][:, :k] # 得到降序排列特征值对应特征向量 # 在取了前k个奇异值之后，对应特征向量仅保留前4项，由于u原本为列向量所以列上仅保留前4项 # A &#x3D; UE&#39;(mxm)V&#39;(mxn)^T &#x3D;&gt; V&#39;^T &#x3D; (UE&#39;)^(-1)A &#x3D; (E&#39;)^(-1)U^TA sigma_part &#x3D; np.diag(sigma_sort_sqrt) # 对角化# print(sigma_part.shape) # 这里得到的sigma_part仅为130维，相当于mxm的对角阵，但原式中为mxn # 此处为一个降维操作 # 由于上式中sigma！&#x3D;原式sigma，所以此时v并不为A^TA的特征向量 # 而是要通过U和sigma_part确定 v_part_T &#x3D; np.linalg.inv(sigma_part).dot(u_sort.T).dot(matrix) return sigma_part, u_sort, v_part_T# print(v_part_T.shape)# print(u_sort.shape)# print(sigma_part.shape)","categories":[],"tags":[{"name":"CS_Math","slug":"CS-Math","permalink":"https://zqzhao.cn/tags/CS-Math/"}]},{"title":"Theory Related Collection","slug":"Seminar-TheoryRelatedCollection","date":"2019-09-20T11:58:11.000Z","updated":"2020-08-09T12:59:46.632Z","comments":true,"path":"2019/09/20/Seminar-TheoryRelatedCollection/","link":"","permalink":"https://zqzhao.cn/2019/09/20/Seminar-TheoryRelatedCollection/","excerpt":"","text":"1999 Rigor and RelevanceRevisited Response to Benbasat and Zmud.pdf 1999, MISQ, Empirical Research inInformation Systems On the Relevance of Practice in Thinking of IS.pdf 2003, Defining InterestingResearch Problems.pdf 2003, The identity crisis withinthe IS discipline.pdf","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Theorical_Basis","slug":"Theorical-Basis","permalink":"https://zqzhao.cn/tags/Theorical-Basis/"}]},{"title":"News Clustering by Title","slug":"CSDN-news-clustering","date":"2018-03-13T04:13:06.000Z","updated":"2020-08-09T09:22:36.769Z","comments":true,"path":"2018/03/13/CSDN-news-clustering/","link":"","permalink":"https://zqzhao.cn/2018/03/13/CSDN-news-clustering/","excerpt":"","text":"0. Thinking0.1 Word List SelectionCustom word list and divid into two layers by category, summed as final eigenvalues, if there are multiple eigenvalues in the same layer then averaged(although this leads to inaccurate classification, eigenvalues tend to be closer). First.txt Used to categorize the main categories, including philosophy, awards and conference activities, research, promotion Each category starts with a whole hundred and the remaining spaces are replaced by “/n” Using the dictionary sequence number *1000000 as an eigenvalue Second.txt Used to classify sub-categories, including faculties, national regions, international regions, international organizations Each category starts with a whole hundred and the remaining spaces are replaced by “/n” Using the dictionary serial number *1000 as an eigenvalue 0.2 Adjustment in K-meansWhen selecting equal spacing selection or random selection, the final result will lead to unevenness in some classes, so select the starting centroid according to a given list, the list has 10 elements, the selected k-value is less than or equal to 10, then selected in the list; the selected k-value is greater than 10, more than 10 parts of the overall medium spacing selection. 1list &#x3D; [50000000, 150000000, 250000000, 350000000, 450000000, 50000, 150000, 250000, 350000, 450000] 0.3 Text Processing Use regular matching to remove punctuation after source text is entered The dictionary is re-ordered according to python’s built-in sort function, because we also need to find a feature word belongs to the original feature word class in reverse, so select the new dictionary, including both the feature word and the original serial number (dictionary’s subscript serial number expresses the current new serial number, the new serial number is easy to find half) 1. Input1.1 CrawlerFirst we crawled 3000+ news headlines on the home page of Zhejiang University. 12345678910111213141516171819202122232425262728293031# -*- coding: utf-8 -*-__author__ &#x3D; &#39;Zhao&#39;from bs4 import BeautifulSoupimport requestssName &#x3D; &quot;new.txt&quot;f &#x3D; open(sName, &#39;w+&#39;)for i in range(1,188): url &#x3D; &quot;http:&#x2F;&#x2F;www.zju.edu.cn&#x2F;xw&#x2F;list&quot; + str(i) + &quot;.htm&quot; headers &#x3D; &#123; &#39;User-Agent&#39;:&quot;Mozilla&#x2F;5.0 (Macintosh; Intel Mac OS X 10_12_5) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;59.0.3071.115 Safari&#x2F;537.36&quot;, &#125; r &#x3D; requests.get(url, headers&#x3D;headers) r.encoding&#x3D;&#39;utf-8&#39; demo &#x3D; r.text soup &#x3D; BeautifulSoup(demo,&#39;html.parser&#39;) # print(&quot;**********************&quot;) for result in soup.find_all(&quot;ul&quot;, &quot;news&quot;): m&#x3D;result.get_text() # print(m) f.write(m) print(url)f.close() 1.2 RegularizationThen regularize to get the title list - this step is relatively simple, just call the re module and leave the code alone here. (Actually, I realized I didn’t save this code…) 1.3 Word ListWhen creating the word list, I chose to double match, that is, first assign a value to each title according to the main keyword, which is larger, and then delete the value according to the secondary keyword. Since the end is abstracted to digital clustering, this works relatively well. (Of course, the results weren’t actually that great.) 2. ClusteringHere I’ve been lazily using the previous participle algorithm… That algorithm is not very accurate. Of course, it has no effect on the small jobs… 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517# -*- coding: utf-8 -*-__author__ &#x3D; &#39;Zhao&#39;# 浙江大学新闻网的list进行相似度计算，并且进行k-means聚类import operatorimport reimport mathfrom decimal import getcontext# import comp_char from cnsortpath &#x3D; &#39;lib&#x2F;&#39;fp &#x3D; open(path + &#39;First.txt&#39;, encoding&#x3D;&#39;utf-8&#39;)ori &#x3D; fp.readlines()# ori is the list with out any operationcopy &#x3D; []new_list &#x3D; []for x in ori: x &#x3D; re.sub(r&#39;\\n&#39;, &#39;&#39;, x) copy.append(x) new_list.append(x)# in this part we change the format in a into standard format and save as copyfp.close()# we close the file, then we can run the list totally in this programcopy.sort()id &#x3D; 0dictionary &#x3D; []for element in copy: if element !&#x3D; &#39;&#39;: dictionary.append([]) dictionary[id].append(element) for ele in new_list: if ele &#x3D;&#x3D; element and len(dictionary[id]) &lt; 2: dictionary[id].append(new_list.index(ele)) id +&#x3D; 1# using new list to substitute original dictionary which contains lots of &#39;&#39; (it&#39;s hard to visualize.)id &#x3D; 0for element in dictionary: print(id, &quot; &quot;, element, end&#x3D;&quot; &#x2F; &quot;) print(&quot; &quot;, copy[id]) id +&#x3D; 1print(&quot;----------&quot;)path &#x3D; &#39;scrapy&#x2F;&#39;f &#x3D; open(path + &#39;ori_news.txt&#39;)ori &#x3D; f.readlines()# ori is the list with out any operationtext &#x3D; []for x in ori: x &#x3D; re.sub(r&#39;\\n&#39;, &#39;&#39;, x) text.append(x)# in this part we change the format in a into standard format and save as copyfp.close()# we close the file, then we can run the list totally in this program# ------------- upper is reading part including wordlist and text -------------index &#x3D; []for x in ori: index.append([])# ------------- upper is append a vacant list prepared to insert index -------------for str_input in text: str_input &#x3D; re.sub(r&#39;,&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;，&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;\\.&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;。&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;——&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;……&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;！&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;!&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;\\?&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;？&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;;&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;；&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39; &#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;&#x2F;&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;、&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;&quot;&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;\\&#39;&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;&lt;&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;&gt;&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;《&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;》&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;\\(&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;\\)&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;（&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;）&#39;, &quot;&quot;, str_input) # change all the punctuation as blank, however, we may split falsely. # Words get around, the step can also split at wrong place, so, I do not fix this mistake.# ------------- upper is transforming part -------------temp_text &#x3D; -1for str_input in text: temp_text +&#x3D; 1 str_head &#x3D; 0 str_tail &#x3D; len(str_input) ptr &#x3D; 5 temp &#x3D; 0 # 当前处理字段起始位置 # result &#x3D; [] # ch_index &#x3D; [] exact_num &#x3D; 0 # we sort dictionary(the copy) in this program and each word has two characteristic number # using as index to look back on original dictionary while temp &lt; str_tail - 1: flag &#x3D; 0 ptr &#x3D; 5 while flag !&#x3D; 1: in_put &#x3D; str_input[temp:temp + ptr] # 当前处理字段 tail &#x3D; len(dictionary) - 1 head &#x3D; 0 half &#x3D; int((tail + head) &#x2F; 2) while tail !&#x3D; half and head !&#x3D; half: if operator.lt(dictionary[half][0], in_put): # 如果字符组的一半比input小 head &#x3D; half half &#x3D; int((tail + head) &#x2F; 2) elif operator.gt(dictionary[half][0], in_put): # 如果字符组的一半比input大 tail &#x3D; half half &#x3D; int((tail + head) &#x2F; 2) elif operator.eq(dictionary[half][0], in_put): flag &#x3D; 1 temp +&#x3D; len(in_put) if tail !&#x3D; 11 and in_put !&#x3D; &quot;&quot;: try: exact_num &#x3D; dictionary[half][1] except: print(half) # print(&quot;exact_num &#x3D; &quot;,exact_num) index[temp_text].append(exact_num * 1000000) # index[temp_text].append(half) # 这个语句仅用于调试之后的Part A部分 break if ptr &#x3D;&#x3D; 0 and temp &lt;&#x3D; len(str_input) - 1: # print(str_input[temp], end&#x3D;&#39;&#x2F;&#39;) # result.append(str_input[temp]) # ch_index.append(-1) temp +&#x3D; 1 flag &#x3D; 1 if flag &#x3D;&#x3D; 0: ptr -&#x3D; 1 # ------ Part A 仅用于调试变量 具体用于探测特征变量 ------ # print(text[temp_text]) # for element in index[temp_text]: # print(element,end&#x3D;&quot; &quot;) # # print(dictionary[element]) # print(&quot;&quot;) # # print(index[temp_text]) # print(&quot;------------------------------&quot;) # ------ Part A END ------ if len(index[temp_text]) &gt; 1: sum &#x3D; 0 for element in index[temp_text]: sum +&#x3D; element average &#x3D; sum &#x2F; len(index[temp_text]) index[temp_text] &#x3D; [] index[temp_text].append(int(average)) # ------ Part B 仅用于调试变量 具体用于探测特征变量 ------ # print(text[temp_text]) # print(index[temp_text]) # print(&quot;-------------&quot;) # ------ Part B END ------# ------------ Upper is first array for the title (the main class) ------------path &#x3D; &#39;lib&#x2F;&#39;fp &#x3D; open(path + &#39;Second.txt&#39;, encoding&#x3D;&#39;utf-8&#39;)ori &#x3D; fp.readlines()# ori is the list with out any operationcopy &#x3D; []new_list &#x3D; []for x in ori: x &#x3D; re.sub(r&#39;\\n&#39;, &#39;&#39;, x) copy.append(x) new_list.append(x)# in this part we change the format in a into standard format and save as copyfp.close()# we close the file, then we can run the list totally in this programcopy.sort()id &#x3D; 0dictionary &#x3D; []for element in copy: if element !&#x3D; &#39;&#39;: dictionary.append([]) dictionary[id].append(element) for ele in new_list: if ele &#x3D;&#x3D; element and len(dictionary[id]) &lt; 2: dictionary[id].append(new_list.index(ele)) id +&#x3D; 1# using new list to substitute original dictionary which contains lots of &#39;&#39; (it&#39;s hard to visualize.)id &#x3D; 0for element in dictionary: print(id, &quot; &quot;, element, end&#x3D;&quot; &#x2F; &quot;) print(&quot; &quot;, copy[id]) id +&#x3D; 1print(&quot;----------&quot;)# ------------- upper is reading part including the second wordlist -------------temp_text &#x3D; -1for str_input in text: temp_text +&#x3D; 1 # str_head &#x3D; 0 str_tail &#x3D; len(str_input) ptr &#x3D; 5 temp &#x3D; 0 # 当前处理字段起始位置 while temp &lt; str_tail - 1: flag &#x3D; 0 ptr &#x3D; 5 while flag !&#x3D; 1: in_put &#x3D; str_input[temp:temp + ptr] # 当前处理字段 tail &#x3D; len(dictionary) - 1 head &#x3D; 0 half &#x3D; int((tail + head) &#x2F; 2) while tail !&#x3D; half and head !&#x3D; half: if operator.lt(dictionary[half][0], in_put): # 如果字符组的一半比input小 head &#x3D; half half &#x3D; int((tail + head) &#x2F; 2) elif operator.gt(dictionary[half][0], in_put): # 如果字符组的一半比input大 tail &#x3D; half half &#x3D; int((tail + head) &#x2F; 2) elif operator.eq(dictionary[half][0], in_put): flag &#x3D; 1 temp +&#x3D; len(in_put) if tail !&#x3D; 11 and in_put !&#x3D; &quot;&quot;: try: exact_num &#x3D; dictionary[half][1] except: print(half) index[temp_text].append(exact_num * 1000) # index[temp_text].append(half) # 这个语句仅用于调试之后的Part A部分 break if ptr &#x3D;&#x3D; 0 and temp &lt;&#x3D; len(str_input) - 1: temp +&#x3D; 1 flag &#x3D; 1 if flag &#x3D;&#x3D; 0: ptr -&#x3D; 1 # ------ Part A 仅用于调试变量 具体用于探测特征变量 ------ # print(text[temp_text]) # for element in index[temp_text]: # print(element,end&#x3D;&quot; &quot;) # # print(dictionary[element]) # print(&quot;&quot;) # # print(index[temp_text]) # print(&quot;------------------------------&quot;) # ------ Part A END ------ if len(index[temp_text]) &gt; 1: sum &#x3D; 0 for i in range(1, len(index[temp_text])): sum +&#x3D; index[temp_text][i] average &#x3D; sum &#x2F; len(index[temp_text]) average +&#x3D; index[temp_text][0] index[temp_text] &#x3D; [] index[temp_text].append(int(average)) # ------ Part B 仅用于调试变量 具体用于探测特征变量 ------ # print(text[temp_text]) # print(index[temp_text]) # print(&quot;-------------&quot;) # ------ Part B END ------# ------------ Upper is second array for the title (the second class) ------------for element in index: if element &#x3D;&#x3D; []: element.append(0)# ------------ 如果仍然没有结果 那么用0替代这个分组 --------------list &#x3D; [50000000, 150000000, 250000000, 350000000, 450000000, 50000, 150000, 250000, 350000, 450000]# ------------ Start Clustering -------------getcontext().prec &#x3D; 4k &#x3D; int(input(&quot;please input k:\\n&quot;))new_ori_set &#x3D; [float(item[0]) for item in index]centroid &#x3D; []if k &lt;&#x3D; 10: for i in range(0,k-1): centroid.append(list[i])else: for element in list: centroid.append(element) step &#x3D; (len(new_ori_set) - 0) &#x2F; (k-10) # print(new_ori_set) temp &#x3D; 0 while temp &lt; len(new_ori_set): centroid.append(new_ori_set[math.trunc(temp)]) temp +&#x3D; stepprint(&quot;original centroids: &quot;, centroid, &quot;\\n&quot;)class_i &#x3D; [[] for i in range(len(centroid))]class_text &#x3D; [[] for i in range(len(centroid))]# class_i is the null class for k centroidflag &#x3D; 1number &#x3D; 0times &#x3D; 0# sign if k never change or this program runs more than 100 timeswhile flag &#x3D;&#x3D; 1 and times &lt; 100: number +&#x3D; 1 flag &#x3D; 0 times +&#x3D; 1 class_i &#x3D; [[] for i in range(len(centroid))] class_text &#x3D; [[] for i in range(len(centroid))] # class_i is the null class for k centroid for i in range(0, len(new_ori_set)): distance &#x3D; float(&quot;inf&quot;) centroid_in_choose &#x3D; 0 for j in range(0, len(centroid)): if abs(new_ori_set[i] - centroid[j]) &lt; distance: distance &#x3D; abs(new_ori_set[i] - centroid[j]) centroid_in_choose &#x3D; j class_i[centroid_in_choose].append(new_ori_set[i]) class_text[centroid_in_choose].append(i) # sort all the elements into proper class # ------------ 每次 Clustering 之后的结果输出 ------------ # print(&quot;after %sth cluster: &quot; % number, &quot;\\n&quot;) # print(&quot;centroid class&quot;) # for i in range(0, len(class_i)): # print(centroid[i], &#39; &#39;, class_i[i]) # # print(&quot;---------&quot;) # ------------ 每次 Clustering 之后的结果输出 END ------------ for i in range(0, len(class_i)): sum &#x3D; 0 for j in range(0, len(class_i[i])): sum +&#x3D; class_i[i][j] if sum !&#x3D; 0: new_centroid &#x3D; round(sum &#x2F; len(class_i[i]), 3) else: continue if new_centroid !&#x3D; centroid[i]: # print(&quot;change centroid &quot;, centroid[i], &quot;as &quot;, end&#x3D;&quot;&quot;) centroid[i] &#x3D; new_centroid # print(centroid[i]) flag &#x3D; 1 # print(&quot;---------&quot;) # change the wrong centroid# ------------ Clustering 最终结果输出 -----------# print(&quot;THE CONCLUSION IS：&quot;)# print(&quot;centroid class&quot;)# for i in range(0, len(class_i)):# print(centroid[i], &#39; &#39;, [text[element] for element in class_text[i]])# ------------ Clustering 最终结果输出 END -----------# -------------- * UPPER IS CLUSTERING, CLUSTERING IS END.* --------------# ------------ 输出到txt -------------try: path &#x3D; &#39;out&#x2F;&#39; f &#x3D; open(path + &quot;result.txt&quot;, &quot;w+&quot;) f.write(&quot;cat\\ttitle\\n&quot;) for i in range(0, len(class_i)): for element in class_text[i]: f.write(str(i) + &quot;\\t&quot; + text[element] + &quot;\\n&quot;) f.close() print(&quot;Print out %d classes successfully.&quot;%k)except: print(&quot;Print out to txt ERROR.&quot;)# ------------ 输出到txt END -------------","categories":[{"name":"Tech","slug":"Tech","permalink":"https://zqzhao.cn/categories/Tech/"}],"tags":[{"name":"Clustering","slug":"Clustering","permalink":"https://zqzhao.cn/tags/Clustering/"}]},{"title":"Chinese Characters Clustering","slug":"CSDN-simple-chs-clustering","date":"2018-01-25T08:47:26.000Z","updated":"2020-04-05T02:57:13.105Z","comments":true,"path":"2018/01/25/CSDN-simple-chs-clustering/","link":"","permalink":"https://zqzhao.cn/2018/01/25/CSDN-simple-chs-clustering/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304# -*- coding: utf-8 -*-__author__ &#x3D; &#39;Zhao&#39;import reimport operatorblank &#x3D; [chr(183)]tabs &#x3D; [&#39;&#39;]def tree(lst): l &#x3D; len(lst) if l &#x3D;&#x3D; 0: print(&#39;─&#39; * 3) else: for i, j in enumerate(lst): if i !&#x3D; 0: print(tabs[0], end&#x3D;&#39;&#39;) if l &#x3D;&#x3D; 1: s &#x3D; &#39;─&#39; * 3 elif i &#x3D;&#x3D; 0: s &#x3D; &#39;┬&#39; + &#39;─&#39; * 2 elif i + 1 &#x3D;&#x3D; l: s &#x3D; &#39;└&#39; + &#39;─&#39; * 2 else: s &#x3D; &#39;├&#39; + &#39;─&#39; * 2 print(s, end&#x3D;&#39;&#39;) if isinstance(j, list) or isinstance(j, tuple): if i + 1 &#x3D;&#x3D; l: tabs[0] +&#x3D; blank[0] * 3 else: tabs[0] +&#x3D; &#39;│&#39; + blank[0] * 2 tree(j) else: print(&quot; &quot;, j) tabs[0] &#x3D; tabs[0][:-3]def judge_element_delete(list_input, centroid, group, match_num): for list_element in list_input: if isinstance(list_element, list): for element in list_element: if element &#x3D;&#x3D; match_num: del centroid[list_input.index(list_element)] del group[list_input.index(list_element)] else: if list_element &#x3D;&#x3D; match_num: del centroid[list_input.index(list_element)] del group[list_input.index(list_element)]# --------------- in this part we save the list as list ---------------path &#x3D; &#39;&#x2F;Users&#x2F;apple&#x2F;desktop&#x2F;&#39;fp &#x3D; open(path + &#39;list.txt&#39;)ori &#x3D; fp.readlines()# ori is the list with out any operationcopy &#x3D; []for x in ori: x &#x3D; re.sub(r&#39;\\n&#39;, &#39;&#39;, x) copy.append(x)# in this part we change the format in a into standard format and save as copyfp.close()# we close the file, then we can run the list totally in this programcopy.sort()# --------------- this part end ---------------# in this part we know the average length in this list is 2, thus we set step as 5.# In that case, we can contain at least one word.# totally, there are 56064 words in this list and only 56 is longer than 5.# In that case, 5 can be a reasonable step for this program.# sum &#x3D; 0# num &#x3D; 0# for x in copy:# sum +&#x3D; len(x)# num +&#x3D; 1# average &#x3D; (int)(sum&#x2F;num)# print(average, &#39; &#39;, num);# max_lenth &#x3D; 0# for x in copy:# if max_lenth &lt; len(x):# max_lenth &#x3D; len(x)## print(max_lenth)# number &#x3D; 0# for x in copy:# if len(x) &gt; 5:# number +&#x3D; 1## print(number)# --------------- the upper is the calculation in the preparation ---------------str_input &#x3D; input(&quot;请输入一个段落：\\n&quot;)str_input &#x3D; re.sub(r&#39;,&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39;，&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39;\\.&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39;。&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39;——&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39;……&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39;！&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39;!&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39;\\?&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39;？&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39;;&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39;；&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39; &#39;, &quot;&quot;, str_input)# change all the punctuation as blank, however, we may split falsely.# Words get around, the step can also split at wrong place, so, I do not fix this mistake.str_head &#x3D; 0str_tail &#x3D; len(str_input)ptr &#x3D; 5temp &#x3D; 0step &#x3D; 5result &#x3D; []ch_index &#x3D; []while temp &lt; str_tail-1: flag &#x3D; 0 ptr &#x3D; 5 while flag !&#x3D; 1: in_put &#x3D; str_input[temp:temp + ptr] tail &#x3D; len(copy) head &#x3D; 0 half &#x3D; int((tail + head) &#x2F; 2) while tail !&#x3D; half and head !&#x3D; half: if operator.lt(copy[half], in_put): # 如果字符组的一半比input小 head &#x3D; half half &#x3D; int((tail + head) &#x2F; 2) elif operator.gt(copy[half], in_put): # 如果字符组的一半比input大 tail &#x3D; half half &#x3D; int((tail + head) &#x2F; 2) else: # print(in_put, end&#x3D;&#39;&#x2F;&#39;) result.append(in_put) ch_index.append(half) flag &#x3D; 1 temp +&#x3D; len(in_put) break if ptr &#x3D;&#x3D; 0 and temp &lt;&#x3D; len(str_input)-1: # print(str_input[temp], end&#x3D;&#39;&#x2F;&#39;) result.append(str_input[temp]) ch_index.append(-1) temp +&#x3D; 1 flag &#x3D; 1 if flag &#x3D;&#x3D; 0: ptr -&#x3D; 1group &#x3D; resultcentroid &#x3D; ch_index# group &#x3D; input(&quot;Please input some numbers spit as blank:\\n&quot;).split(&quot; &quot;)# group_num &#x3D; len(group)# for element in group:# centroid.append(int(element))precision &#x3D; 0for element in group: precision &#x3D; len(element) if len(element) &gt; precision else precisiongroup_num &#x3D; len(group)while group_num !&#x3D; 2: # print(&quot;the numbers of groups now is &quot;, group_num, &quot;\\n&quot;) matrix &#x3D; [[] for i in range(group_num)] for i in range(group_num): for j in range(group_num): distance &#x3D; abs(int(centroid[i]) - int(centroid[j])) matrix[i].append(distance) # --------------- matrix --------------- # print(&quot;distance matrix :&quot;) # for i in range(group_num): # print(matrix[i]) # matrix contains the distance between every two elements # print(&quot;------------&quot;) max_in_matrix &#x3D; 0 for i in range(group_num): for j in range(group_num): max_in_matrix &#x3D; max_in_matrix if max_in_matrix &gt; matrix[i][j] else matrix[i][j] # print(max_in_matrix) # if max_in_matrix &#x3D;&#x3D; 0: # break for i in range(group_num): for j in range(group_num): matrix[i][j] &#x2F;&#x3D; max_in_matrix matrix[i][j] &#x3D; round(1 - matrix[i][j], precision) if round(1 - matrix[i][j], precision) !&#x3D; 1 else 0 # print(&quot;standard matrix :&quot;) # for i in range(group_num): # print(matrix[i]) # print(&quot;------------&quot;) # standard the matrix similarity &#x3D; 0 for i in range(group_num): for j in range(group_num): similarity &#x3D; similarity if similarity &gt; matrix[i][j] else matrix[i][j] # print(&quot;max similarity in the matrix: &quot;, max_in_matrix, &quot;\\n&quot;) # --------------- matrix --------------- # find the max similarity in this matrix temp_class &#x3D; [] index &#x3D; [] flag &#x3D; 0 for i in range(group_num): for j in range(group_num): if matrix[i][j] &#x3D;&#x3D; similarity: index.append(i) index.append(j) flag &#x3D; 1 temp_class.append(group[i]) temp_class.append(group[j]) if flag &#x3D;&#x3D; 1: break if flag &#x3D;&#x3D; 1: break # find the first center index of new group group_num &#x3D; len(group) for i in range(group_num): if matrix[index[0]][i] &#x3D;&#x3D; similarity and i !&#x3D; index[1]: temp_class.append(group[i]) index.append(i) for i in range(group_num): if matrix[index[1]][i] &#x3D;&#x3D; similarity and i !&#x3D; index[0]: temp_class.append(group[i]) index.append(i) new_centroid &#x3D; 0 for element in index: new_centroid +&#x3D; centroid[element] new_centroid &#x2F;&#x3D; len(index) for element in index: group[element] &#x3D; &#39;substitute&#39; centroid[element] &#x3D; &#39;substitute&#39; lenth &#x3D; len(group) temp_flag &#x3D; 0 while temp_flag !&#x3D; 1: temp_flag &#x3D; 1 for i in range(0, lenth): if group[i] &#x3D;&#x3D; &#39;substitute&#39;: del group[i] lenth &#x3D; len(group) temp_flag &#x3D; 0 break lenth &#x3D; len(centroid) temp_flag &#x3D; 0 while temp_flag !&#x3D; 1: temp_flag &#x3D; 1 for i in range(0, lenth): if centroid[i] &#x3D;&#x3D; &#39;substitute&#39;: del centroid[i] lenth &#x3D; len(centroid) temp_flag &#x3D; 0 break group.append(temp_class) centroid.append(new_centroid) group_num &#x3D; len(group)print(group)tree(group)","categories":[{"name":"Tech","slug":"Tech","permalink":"https://zqzhao.cn/categories/Tech/"}],"tags":[{"name":"Clustering","slug":"Clustering","permalink":"https://zqzhao.cn/tags/Clustering/"}]},{"title":"Python 3.5 Set-Up","slug":"CSDN-python-setting","date":"2017-11-16T08:13:09.000Z","updated":"2020-04-05T04:10:19.867Z","comments":true,"path":"2017/11/16/CSDN-python-setting/","link":"","permalink":"https://zqzhao.cn/2017/11/16/CSDN-python-setting/","excerpt":"","text":"install Homebrew1&#x2F;usr&#x2F;bin&#x2F;ruby -e &quot;$(curl -fsSL https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Homebrew&#x2F;install&#x2F;master&#x2F;install)&quot; Jump if already installed. It’s necessary to update your homebrew to the latest version. 2020-04-05 Update: If you get blocked, try to fix the problem by this. Use Homebrew install Python3 &amp; pip3 (pip is a package management tool for Python), automatically latest version, you may choose another version. 1$ brew install python3 We use pip3 because we want to use Python 3.x.x. If you need pip simply, try1$ sudo easy_install pip install pip need administrator role Check the version 1234$python --version$python3 --version$pip --version$pip3 --version Install [PyCharm](https://www.jetbrains.com/pycharm/). I recommend community edition. If you want the professional edition, there is a Free JetBrains Products License Server. Install additional packages: For example, bs4 (BeautifulSoup 4): PyCharm offer you an inner package management tool: Preferences —&gt; Project —&gt; Project Interpreter Click “+” to install packages you need. Usually there are some errors, follow its introduction and try again. At most cases, error occurs when you revoke the administrator role. So… sudoplease Another way is to install in the terminal: $ pip3 install bs4 if any problems, follow the introduction and try again. Usually you need to upgrade your “pip” “homebrew” “python” or other relative package.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://zqzhao.cn/categories/Tech/"}],"tags":[]},{"title":"Hierarchical Clustering","slug":"CSDN-hierarchical-clustering","date":"2017-11-14T10:28:27.000Z","updated":"2020-04-18T05:55:07.958Z","comments":true,"path":"2017/11/14/CSDN-hierarchical-clustering/","link":"","permalink":"https://zqzhao.cn/2017/11/14/CSDN-hierarchical-clustering/","excerpt":"","text":"周志华《机器学习》中的层次聚类算法太简单了，这个算法里考虑到了多个子类聚成同一个父类的情况。但是时间精力有限，没有办法实现完美的树状输出，Bonus中我会改进。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151# -*- coding: utf-8 -*-__author__ &#x3D; &#39;Zhao&#39;import mathimport numpy as npdef judge_element_append(list_input): if isinstance(list_input, list): for element in list_input: temp_class.append(element) else: temp_class.append(list_input)def judge_element_delete(list_input, aim_list, match_num): for list_element in list_input: if isinstance(list_element, list): for element in list_element: if element &#x3D;&#x3D; match_num: del aim_list[list_input.index(list_element)] else: if list_element &#x3D;&#x3D; match_num: del aim_list[list_input.index(list_element)]group &#x3D; []group &#x3D; input(&quot;Please input some numbers spit as blank:\\n&quot;).split(&quot; &quot;)group_num &#x3D; len(group)centroid &#x3D; []for i in range(group_num): centroid.append(group[i])print(&quot;centroid is &quot;, centroid, &quot;\\n&quot;)times &#x3D; 0# auto-incrementwhile group_num !&#x3D; 1: group_num &#x3D; len(group) print(&quot;the numbers of groups now is &quot;, group_num, &quot;\\n&quot;) matrix &#x3D; [[] for i in range(group_num)] for i in range(group_num): for j in range(group_num): distance &#x3D; abs(int(centroid[i]) - int(centroid[j])) matrix[i].append(distance) print(&quot;distance matrix :&quot;) for i in range(group_num): print(matrix[i]) # matrix contains the distance between every two elements print(&quot;------------&quot;) max_in_matrix &#x3D; 0 for i in range(group_num): for j in range(group_num): max_in_matrix &#x3D; max_in_matrix if max_in_matrix &gt; matrix[i][j] else matrix[i][j] # print(max_in_matrix) for i in range(group_num): for j in range(group_num): matrix[i][j] &#x2F;&#x3D; max_in_matrix matrix[i][j] &#x3D; round(1 - matrix[i][j], 3) if round(1 - matrix[i][j], 3) !&#x3D; 1 else 0 print(&quot;standard matrix :&quot;) for i in range(group_num): print(matrix[i]) print(&quot;------------&quot;) # standard the matrix max_in_matrix &#x3D; 0 for i in range(group_num): for j in range(group_num): max_in_matrix &#x3D; max_in_matrix if max_in_matrix &gt; matrix[i][j] else matrix[i][j] print(&quot;max similarity in the matrix: &quot;, max_in_matrix, &quot;\\n&quot;) # find the max similarity in this matrix if max_in_matrix &#x3D;&#x3D; 0: temp_class &#x3D; [] for i in range(group_num): judge_element_append(group[i]) # print(&quot;last temp_group &#x3D; &quot;, temp_class) for i in range(len(temp_class)): judge_element_delete(group, centroid, temp_class[i]) judge_element_delete(group, group, temp_class[i]) group.append(temp_class) print(&quot;[CONCLUSION]: &quot;, group) break temp_class &#x3D; [] index1 &#x3D; 0 index2 &#x3D; 0 flag &#x3D; 0 for i in range(group_num): for j in range(group_num): if matrix[i][j] &#x3D;&#x3D; max_in_matrix: index1 &#x3D; i index2 &#x3D; j flag &#x3D; 1 judge_element_append(group[i]) judge_element_append(group[j]) if flag &#x3D;&#x3D; 1: break # find the first center index of new group group_num &#x3D; len(group) # print(group_num) for i in range(group_num): if matrix[index1][i] &#x3D;&#x3D; max_in_matrix and i !&#x3D; index2: judge_element_append(group[i]) # group_num &#x3D; len(group) for i in range(group_num): if matrix[index2][i] &#x3D;&#x3D; max_in_matrix and i !&#x3D; index1: judge_element_append(group[i]) times +&#x3D; 1 print(&quot;after %dth clustering: &quot; % times) # print(&quot;temp_group &#x3D; &quot;, temp_class) for i in range(len(temp_class)): judge_element_delete(group, centroid, temp_class[i]) judge_element_delete(group, group, temp_class[i]) group.append(temp_class) print(&quot;the new group is &quot;, group) sum &#x3D; 0 for i in range(len(temp_class)): sum +&#x3D; int(temp_class[i]) centroid.append(sum &#x2F; len(temp_class)) print(&quot;the new centroid is &quot;, centroid, &quot;\\n&quot;) print(&quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;EHD OF ONE CLUSTERING&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\\n&quot;)","categories":[{"name":"Tech","slug":"Tech","permalink":"https://zqzhao.cn/categories/Tech/"}],"tags":[{"name":"Clustering","slug":"Clustering","permalink":"https://zqzhao.cn/tags/Clustering/"}]},{"title":"Naive K-Means","slug":"CSDN-k-means","date":"2017-11-02T10:54:03.000Z","updated":"2020-04-18T05:46:11.337Z","comments":true,"path":"2017/11/02/CSDN-k-means/","link":"","permalink":"https://zqzhao.cn/2017/11/02/CSDN-k-means/","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576# -*- coding: utf-8 -*-__author__ &#x3D; &#39;Zhao&#39;import mathfrom decimal import getcontextgetcontext().prec &#x3D; 4origin_set &#x3D; []origin_set &#x3D; input(&quot;please input a set which is consist of numbers:\\n&quot;).split(&quot; &quot;)k &#x3D; int(input(&quot;please input k:\\n&quot;))origin_set &#x3D; [float(item) for item in origin_set]step &#x3D; (len(origin_set) - 0) &#x2F; kcentroid &#x3D; []temp &#x3D; 0while temp &lt; len(origin_set): centroid.append(origin_set[math.trunc(temp)]) temp &#x3D; temp + stepprint(&quot;original centroids: &quot;, centroid, &quot;\\n&quot;)class_i &#x3D; [[] for i in range(len(centroid))]# class_i is the null class for k centroidflag &#x3D; 1number &#x3D; 0# sign if k never changewhile flag &#x3D;&#x3D; 1: number +&#x3D; 1 flag &#x3D; 0 class_i &#x3D; [[] for i in range(len(centroid))] # class_i is the null class for k centroid for i in range(0, len(origin_set)): distance &#x3D; float(&quot;inf&quot;) centroid_in_choose &#x3D; 0 for j in range(0, len(centroid)): if abs(origin_set[i] - centroid[j]) &lt; distance: distance &#x3D; abs(origin_set[i] - centroid[j]) centroid_in_choose &#x3D; j class_i[centroid_in_choose].append(origin_set[i]) # sort all the elements into proper class print(&quot;after %sth cluster: &quot; % number, &quot;\\n&quot;) print(&quot;centroid class&quot;) for i in range(0, len(class_i)): print(centroid[i], &#39; &#39;, class_i[i]) print(&quot;---------&quot;) for i in range(0, len(class_i)): sum &#x3D; 0 for j in range(0, len(class_i[i])): sum +&#x3D; class_i[i][j] if sum !&#x3D; 0: new_centroid &#x3D; round(sum &#x2F; len(class_i[i]), 3) else: continue if new_centroid !&#x3D; centroid[i]: print(&quot;change centroid &quot;, centroid[i], &quot;as &quot;, end&#x3D;&quot;&quot;) centroid[i] &#x3D; new_centroid print(centroid[i]) flag &#x3D; 1 print(&quot;---------&quot;) # change the wrong centroidprint(&quot;THE CONCLUSION IS：&quot;)print(&quot;centroid class&quot;)for i in range(0, len(class_i)): print(centroid[i], &#39; &#39;, [int(element) for element in class_i[i]])","categories":[{"name":"Tech","slug":"Tech","permalink":"https://zqzhao.cn/categories/Tech/"}],"tags":[{"name":"Clustering","slug":"Clustering","permalink":"https://zqzhao.cn/tags/Clustering/"}]},{"title":"3 Hours Review of OOP","slug":"CSDN-3hoursOOP","date":"2017-02-04T04:33:38.000Z","updated":"2020-04-18T06:18:02.201Z","comments":true,"path":"2017/02/04/CSDN-3hoursOOP/","link":"","permalink":"https://zqzhao.cn/2017/02/04/CSDN-3hoursOOP/","excerpt":"","text":"基于《Thinking in C++》 1. 静态成员变量 静态成员变量用static修饰，它只属于类而不是对象，因此所有这个类的对象享用同一个静态变量值。 静态成员变量必须要在类外初始化 type class::name = value; 初始化的时候不用带static但需要有类型，protected，privated，public都可以被这样初始化 静态成员变量的调用 //通过类类访问 static 成员变量 Student::m_total = 10; //通过对象来访问 static 成员变量 Student stu(&quot;小明&quot;, 15, 92.5f); stu.m_total = 20; //通过对象指针来访问 static 成员变量 Student *pstu = new Student(&quot;李华&quot;, 16, 96); pstu -&gt; m_total = 20; static 成员变量不占用对象的内存，而是在所有对象之外开辟内存，即使不创建对象也可以访问。 一个类中可以有一个或多个静态成员变量，所有的对象都共享这些静态成员变量，都可以引用它。 static 成员变量和普通 static 变量一样，都在内存分区中的全局数据区分配内存，到程序结束时才释放。这就意味着，static 成员变量不随对象的创建而分配内存，也不随对象的销毁而释放内存。而普通成员变量在对象创建时分配内存，在对象销毁时释放内存。 静态成员变量初始化时可以赋初值，也可以不赋值。如果不赋值，那么会被默认初始化为 0。全局数据区的变量都有默认的初始值 0，而动态数据区（堆区、栈区）变量的默认值是不确定的，一般认为是垃圾值。 静态成员变量既可以通过对象名访问，也可以通过类名访问，但要遵循 private、protected 和 public 关键字的访问权限限制。当通过对象名访问时，对于不同的对象，访问的是同一份内存。 静态成员变量可以成为派生类和基类共同使用的数值，也可以成为成员函数的可选参数。 静态成员变量可以是所属类的类型，普通数据成员只能成为该类的指针或引用。 2. 静态成员函数 静态成员函数的地址可以用普通函数指针调用 class A{ public: static fun(){}; int fun1(){}; } int (*pf1)()=&amp;base::fun; int (base::*pf2)()=&amp;case::fun1; 静态成员函数不可以调用类的非静态成员，因为这个静态成员函数并不带有this指针。 静态成员函数不可以同时声明为 virtual const volatile函数。 静态成员函数不需要对象名即可调用。 非静态成员函数可以自由调用静态成员函数和静态成员变量。 3. 引用和地址 引用类似于某个变量的别名，完全享用同一片地址。 引用必须在定义的时候初始化。 引用对象已经初始化不能重新引用另外的变量。 4. 拷贝构造函数 CExample(const CExample&amp; C) 就是我们自定义的拷贝构造函数。可见，拷贝构造函数是一种特殊的构造函数，函数的名称必须和类名称一致，它必须的一个参数是本类型的一个引用变量。 调用时机 类作为一个参数整体传入一个函数的时候，需要调用这个类的拷贝构造函数，进行形参和实参的复制 类作为一个结果返回的时候，先产生一个临时变量，调用拷贝构造函数将返回值拷贝到临时变量，析构返回的变量，再析构临时变量 需要通过另一个变量初始化的时候 class mode{...} mode A(10); mode B = A; 拷贝构造函数分为浅拷贝和深拷贝。 默认拷贝构造函数是浅拷贝的一种 默认拷贝构造函数无法处理静态成员变量只是简单复制 需要自己写浅拷贝构造函数进行静态成员变量的复制 如果被拷贝对象中包含指针，进行逐位拷贝后新旧两个指针将指向同一个空间，并且将被重复释放 深拷贝用于需要动态创建新空间时 Rect(const Rect&amp; r) { width = r.width; height = r.height; p = new int; // 为新对象重新动态分配空间 *p = *(r.p); } 可以创建一个private的拷贝构造函数声明来解决默认值拷贝。？？？ 5. const 修饰指针变量时： 只有一个const，如果const位于*左侧，表示指针所指数据是常量，不能通过解引用修改该数据；指针本身是变量，可以指向其他的内存单元。 只有一个const，如果const位于*右侧，表示指针本身是常量，不能指向其他内存地址；指针所指的数据可以通过解引用修改。 两个const，*左右各一个，表示指针和指针所指数据都不能修改。 修饰函数参数时: 不能改变该参数的值。 修饰函数时： 该函数不能改变调用的参数值，同样地，该函数也不能调用任何非const函数。 修饰返回值时： 指针返回时：只能赋值给同样用const修饰的左值 值传递时：const并没有什么意义 6. 对象初始化和析构 空初始化：即无参数无括号形式 如int i，new int,new int[10].当在所有函数之外时，初始化为0；当在某一函数中时，没初始化。 值初始化：即无参数有括号形式，且括号只能在类型名后，而不能在变量名之后，即只能创无名对象，对象被值初始化为0. 如：int() //创建了一个无名对象，其被值初始化为0.一般将该无名对象初始化化或赋值给某有名对象，或直接作为无名对象使用 显式初始化：即有参数有括号形式，且当为有名对象时括号在对象名之后，为无名对象时括号在类类型名之后。 如：int i（5）； new int(5); 以下四种必须使用初始化列表： 初始化一个引用成员变量 初始化一个const变量 当我们在初始化一个子类对象的时候，而这个子类对象的父类有一个显示的带有参数的构造函数 当调用一个类类型成员的构造函数，而它拥有一组参数的时候 析构函数通常使用默认析构函数，但是在之前进行空间改变（指针移位等）的时候一定要自己写析构函数。 析构数组或类组： class A { A(){m_a=new int[10];} ~A(){delete [] m_a;} int * m_a; } 强制类型转换支持但并不推荐，推荐使用以下较温和的方法： pd = static_cast&lt;double*&gt;(pv); 初始化列表不管怎么写，初始化的顺序也只是按照原类内声明的顺序进行。 7. 重载函数和默认参数 重载函数的调用匹配 精确匹配：参数匹配而不做转换，或者只是做微不足道的转换，如数组名到指针、函数名到指向函数的指针、T到const T； 提升匹配：即整数提升（如bool 到 int、char到int、short 到int），float到double 使用标准转换匹配：如int 到double、double到int、double到long double、Derived*到Base*、T*到void*、int到unsigned int； 使用用户自定义匹配； 使用省略号匹配：类似printf中省略号参数 同一作用域中有相同函数名但是有不同参数列表的可见函数构成重载关系。 内层作用域的函数会隐藏外层的同名函数，同样的派生类的成员函数会隐藏基类的同名函数。 如果要在函数内部调用重名的全局变量则要以“:: va”这样的形式调用。 在编译器中，编译器看到的函数名为“类型+名称+从左往右的参数列表”，但事实上在调用重载函数时，仅仅有返回类型不同是不能成立的，因为编译器无法判断你调用的是哪个函数，具有二义性。 8. 运算符重载 两种重载方式的比较： 一般情况下，单目运算符最好重载为类的成员函数；双目运算符则最好重载为类的友元函数。以下一些双目运算符不能重载为类的友元函数：=、()、[]、-&gt;。 类型转换函数只能定义为一个类的成员函数而不能定义为类的友元函数。 C++提供4个类型转换函数：reinterpret_cast（在编译期间实现转换）、const_cast（在编译期间实现转换）、stactic_cast（在编译期间实现转换）、dynamic_cast（在运行期间实现转换，并可以返回转换成功与否的标志）。 若一个运算符的操作需要修改对象的状态，选择重载为成员函数较好。 若运算符所需的操作数（尤其是第一个操作数）希望有隐式类型转换，则只能选用友元函数。当运算符函数是一个成员函数时，最左边的操作数（或者只有最左边的操作数）必须是运算符类的一个类对象（或者是对该类对象的引用）。如果左边的操作数必须是一个不同类的对象，或者是一个内部 类型的对象，该运算符函数必须作为一个友元函数来实现。 当需要重载运算符具有可交换性时，选择重载为友元函数。 注意事项： 除了类属关系运算符”.“、成员指针运算符”.*“、作用域运算符”::“、sizeof运算符和三目运算符”?:“以外，C++中的所有运算符都可以重载。 重载运算符限制在C++语言中已有的运算符范围内的允许重载的运算符之中，不能创建新的运算符。运算符重载实质上是函数重载，因此编译程序对运算符重载的选择，遵循函数重载的选择原则。 重载之后的运算符不能改变运算符的优先级和结合性，也不能改变运算符操作数的个数及语法结构。 运算符重载不能改变该运算符用于内部类型对象的含义。它只能和用户自定义类型的对象一起使用，或者用于用户自定义类型的对象和内部类型的对象混合使用时。 运算符重载是针对新类型数据的实际需要对原有运算符进行的适当的改造，重载的功能应当与原有功能相类似，避免没有目的地使用重载运算符。 9. 继承和组合 kind of关系下用继承，part of关系下用组合。 继承 class Human { … }; class Man : public Human { … }; class Boy : public Man { … }; 组合 class Eye { public: void Look(void); }; class Nose { public: void Smell(void); }; class Mouth { public: void Eat(void); }; class Ear { public： void Listen(void); }; class Head { public: void Look(void) { m_eye.Look(); } void Smell(void) { m_nose.Smell(); } void Eat(void) { m_mouth.Eat(); } void Listen(void) { m_ear.Listen(); } private: Eye m_eye; Nose m_nose; Mouth m_mouth; Ear m_ear; }; 继承的关系不同对这个派生类并无影响，而是对该派生类的派生类产生影响。例如private Base（10），则对于该派生类的派生类来说，Base不可见。 10. inline &amp; extern 关键字inline 必须与函数定义体放在一起才能使函数成为内联，仅将inline 放在函数声明前面不起任何作用。 定义在类声明之中的成员函数将自动地成为内联函数。 宏替换是单纯地代码替换，inline函数真正具有函数的特征。 extern 表示该声明已经定义在别的文件中了。 11. virtual函数与纯虚函数 虚函数：类Base中加了Virtual关键字的函数就是虚拟函数（例如函数print），于是在Base的派生类Derived中就可以通过重写虚拟函数来实现对基类虚拟函数的覆盖。当基类Base的指针point指向派生类Derived的对象时，对point的print函数的调用实际上是调用了Derived的print函数而不是Base的print函数。 我们只需在把基类的成员函数设为virtual，其派生类的相应的函数也会自动变为虚函数。也就是说，virtual函数被继承后可以自动动态绑定当前对象。 纯虚函数：只声明，无定义，包含纯虚函数的类称为抽象类，无实际作用，只作为基类。 class &lt;类名&gt; { virtual &lt;类型&gt;&lt;函数名&gt;(&lt;参数表&gt;)=0; … }; 重载和覆盖的区别 重载的几个函数必须在同一个类中；覆盖的函数必须在有继承关系的不同的类中 覆盖的几个函数必须函数名、参数、返回值都相同；重载的函数必须函数名相同，参数不同。 覆盖的函数前必须加关键字Virtual；重载和Virtual没有任何瓜葛，加不加都不影响重载的运作。 关于C++的隐藏规则： 如果派生类的函数与基类的函数同名，但是参数不同。此时，不论有无virtual关键字，基类的函数将被隐藏（注意别与重载混淆）。 如果派生类的函数与基类的函数同名，并且参数也相同，但是基类函数没有virtual关键字。此时，基类的函数被隐藏（注意别与覆盖混淆）。 重写 重载 重定义 重写(override):父类与子类之间的多态性。子类重新定义父类中有相同名称和参数的虚函数。 1) 被重写的函数不能是 static 的。必须是 virtual 的 ( 即函数在最原始的基类中被声明为 virtual ) 。 2) 重写函数必须有相同的类型，名称和参数列表 (即相同的函数原型) 3) 重写函数的访问修饰符可以不同。尽管 virtual 是 private 的，派生类中重写改写为 public,protected 也是可以的 重载 (overload):指函数名相同，但是它的参数表列个数或顺序，类型不同。但是不能靠返回类型来判断。 重定义 (redefining):子类重新定义父类中有相同名称的非虚函数 ( 参数列表可以不同 ) 。 重写与重载的区别 (override) PK (overload) 方法的重写是子类和父类之间的关系，是垂直关系；方法的重载是同一个类中方法之间的关 系，是水平关系。 重写要求参数列表相同；重载要求参数列表不同。 重写关系中，调用那个方法体，是根据对象的类型（对象对应存储空间类型）来决定；重载关系，是根据调用时的实参表与形参表来选择方法体的。 12. binding 对象的静态类型：对象在声明时采用的类型。是在编译期确定的。 对象的动态类型：目前所指对象的类型。是在运行期决定的。对象的动态类型可以更改，但是静态类型无法更改。 D* pD = new D(); //pD的静态类型是它声明的类型D*，动态类型也是D* B* pB = pD; //pB的静态类型是它声明的类型B*，动态类型是pB所指向的对象pD的类型D* C* pC = new C(); pB = pC; //pB的动态类型是可以更改的，现在它的动态类型是C* 静态绑定：绑定的是对象的静态类型，某特性（比如函数）依赖于对象的静态类型，发生在编译期。 动态绑定：绑定的是对象的动态类型，某特性（比如函数）依赖于对象的动态类型，发生在运行期。 只有虚函数是动态绑定，其余函数都是静态绑定。动态绑定的函数调用的函数体看实际上的对象类型，静态绑定的函数调用的函数体看声明的对象类型。 虚函数是动态绑定的，但是为了执行效率，缺省参数是静态绑定的。 13. upcasting、downcasting与类指针 将基类引用转换为派生类引用称为upcasting，因为在继承图上式上升的。 对于一个使用了虚函数的基类来说： Base b = d;//直接赋值（产生切割） b.Test(); Base&amp; b2 = d;//使用引用赋值（不产生切割） b2.Test(); Base* b3 = &amp;d;//使用指针赋值（不产生切割） b3-&gt;Test(); //覆盖方法和子类数据丢失的现象生成切割(slice) 14. 模板 模板的一般形式： Template &lt;class或者也可以用typename T&gt; 返回类型 函数名（形参表） {//函数定义体 } //template是一个声明模板的关键字，表示声明一个模板关键字class不能省略，如果类型形参多余一个 ，每个形参前都要加class &lt;类型 形参表&gt;可以包含基本数据类型可以包含类类型. template &lt;class T&gt; inline T square(T x) { T result; result = x * x; return result; }; 15. 异常探查http://www.cnblogs.com/ggjucheng/archive/2011/12/18/2292089.html 16. explicitTest1 t1=12;//隐式调用其构造函数,成功 Test2 t2=12;//编译错误,不能隐式调用其构造函数 Test2 t2(12);//显式调用成功 explicit可以避免隐式调用构造函数。 17. 友元函数class A{ friend int print(); //友元函数不可被继承 } int print(){}; //可以定义在类内或者类外 int main{ A obj; print(); //可以直接调用友元函数 }","categories":[],"tags":[{"name":"OOP","slug":"OOP","permalink":"https://zqzhao.cn/tags/OOP/"}]}],"categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"},{"name":"Tech","slug":"Tech","permalink":"https://zqzhao.cn/categories/Tech/"}],"tags":[{"name":"Theorical_Basis","slug":"Theorical-Basis","permalink":"https://zqzhao.cn/tags/Theorical-Basis/"},{"name":"Notes","slug":"Notes","permalink":"https://zqzhao.cn/tags/Notes/"},{"name":"Article_Template_MIS","slug":"Article-Template-MIS","permalink":"https://zqzhao.cn/tags/Article-Template-MIS/"},{"name":"CS_Math","slug":"CS-Math","permalink":"https://zqzhao.cn/tags/CS-Math/"},{"name":"MIS_thinking","slug":"MIS-thinking","permalink":"https://zqzhao.cn/tags/MIS-thinking/"},{"name":"Clustering","slug":"Clustering","permalink":"https://zqzhao.cn/tags/Clustering/"},{"name":"OOP","slug":"OOP","permalink":"https://zqzhao.cn/tags/OOP/"}]}