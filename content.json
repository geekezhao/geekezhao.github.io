{"meta":{"title":"Geeke's Blog","subtitle":"","description":"","author":"Geek ZHAO","url":"https://zqzhao.cn","root":"/"},"pages":[{"title":"categories","date":"2020-04-05T08:31:30.000Z","updated":"2020-04-05T08:32:35.155Z","comments":false,"path":"categories/index.html","permalink":"https://zqzhao.cn/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-04-18T06:10:25.000Z","updated":"2020-04-18T06:16:45.773Z","comments":false,"path":"tags/index.html","permalink":"https://zqzhao.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Article Template of MIS - Origin","slug":"module-origin","date":"2020-08-08T11:51:53.000Z","updated":"2020-08-08T11:53:31.893Z","comments":true,"path":"2020/08/08/module-origin/","link":"","permalink":"https://zqzhao.cn/2020/08/08/module-origin/","excerpt":"","text":"模板中已经参考过的文献Introduction 文章 来源 点评 Branstetter 2019 ISR 这篇文章对过去文献的评述主要放在了对后续章节的展开中，也就是in the following sections这一部分中，不是特别典型；另外放了一些篇幅在对自己结果的简介上。 Bharadwaj 2000 MISQ 这篇文章的开头大篇幅放在自己理论上，比较少提到了前文研究和后续的行文。 Chae 2014 MISQ 这篇放了很大篇幅在过往文献的比较和综述上，后续需要关注literature的写法。","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Article_Template_MIS","slug":"Article-Template-MIS","permalink":"https://zqzhao.cn/tags/Article-Template-MIS/"}]},{"title":"Article Template of MIS - Introduction","slug":"module-intro","date":"2020-08-07T14:30:12.000Z","updated":"2020-08-08T12:32:15.598Z","comments":true,"path":"2020/08/07/module-intro/","link":"","permalink":"https://zqzhao.cn/2020/08/07/module-intro/","excerpt":"","text":"In this part, I will conduct a module of introduction in order to avail future researches. Based on the favor of different journals, I will list the template grouped by the journals. Mainly there are three journals which are MISQ, ISR and MS. However, there are also other articles with a graceful written style. 开头句ISR This paper documents a significant change in the nature and direction of invention in four “traditional” manufacturing industries. MSMISQ Understanding the economic impact of information tech- nology is a critical issue to information systems researchers, and there is a rich body of literature about IT value (Chan 2000; Dehning and Richardson 2002; Kohli and Devaraj 2003; Mahmood and Mann 2000; Melville et al. 2004; Wade and Hulland 2004). Despite the widely held belief that information technology (IT) is fundamental to a firm’s survival and growth, scholars are still struggling to specify the underlying mechanisms linking IT to financial performance. Others引入-对过往文献的评述（侧重不足）ISRMSMISQ This study focuses on the performance effects of IT, an issue that has provoked much debate over the last decade. Dubbed the “productivity paradox,” the controversy over the business value of computer investments continues to rage even in the face of more encouraging evidence about payoffs from IT (Brynjolfsson 1993; Brynjolfsson and Hitt 1993, 1996; Hitt and Brynjolfsson 1996) For example, in his most recent book, The Squandered Computer, Strassman (1997) argues that there is no discernible relationship between IT investments and any measure of firm profitability including return on assets, return on equity, and economic value added. Other empirical studies that have investigated the relationship have also yielded mixed results. These results have been extensively cited and summarized elsewhere (c.f. Brynjolfsson 1993; Hitt and Brynjolfsson 1996; Lucas 1993; Wilson 1993). The findings of past studies have however been questioned on methodological grounds such as (1) use of inappropriate measures of IT intensity, (2) failure to control for other factors that drive firm profits, and (3) problems related to sample selection and sample size (Dos Santos et al. 1993; Hitt and Brynjolfsson 1996; Lucas 1993; Mooney et al. 1995). With this backdrop, it is natural to ask if IT capabilities still hold the same value today as they did in the past. However, these studies were conducted with data from the early 1990s, and we wondered if their findings still hold true after over a decade of rapid and widespread change in IT and the way organizations use IT. Thus, we updated these studies with new data from the early 2000s. Replications and updates are an important aspect of scientific endeavor because they test the robustness of a theory and solidify tentative beliefs into accepted knowledge (Santhanam and Hartono 2003). However, replicative studies are generally underutilized by the research community (Berthon et al. 2002). We believe that examining and reexamining what has been scientifically studied and reported is particularly important to the research community. Others引入-重要现实意义ISR Engineers and industry experts in these sectors have provided anecdotal evidence of a software-biased shift in the trajectory of innovation, but this evidence has generally rested on a relatively small number of possibly unrepresentative firms and products. MSMISQ Despite the widely held belief that information technology (IT) is fundamental to a firm’s survival and growth, scholars are still struggling to specify the underlying mechanisms linking IT to financial performance. Anecdotal evidence and case studies indicate that effective and efficient use of IT is a key factor differentiating successful firms from their less successful counterparts. For example, IT capabilities were found to be an important differentiator of banks that were doing well in the mid-1980s, as compared to those that were less profitable (Nolan 1994). Widely publicized IT programs in firms such as American Airlines, Merrill-Lynch, and Frito-Lay have been associated with superior business performance. At the same time, there is also evidence that many firms, concerned about falling behind on the technology curve, engage in high IT investments without deriving any benefits from IT (Nolan 1994). Despite some skepticism about the direct effect of IT on firm performance (Carr 2003; Clemons 1986, 1991; Clemons and Row 1991; Powell and Dent-Micallef 1997), many IS researchers believe that superior IT capability can render a firm a significant competitive advantage over its competitors. However, as Nicolas Carr argued in his Harvard Business Review article in 2003, several significant develop- ments in the IT industry in the 2000s may have eroded the competitive edge resulting from being an IT leader with superior IT capability. Others对自己的全文做一个简单总结ISR Using much more comprehensive patent and patent citation data, we present new statistical evidence showing that this software-biased shift is persistent, systematic, and increasingly pervasive. We also point to other indicators suggesting that this shift extends far beyond the boundaries of our four target industries.这里是对自己的文章内容的总结，可以注意下一些名词的选择。 MSMISQ Thus, we embarked on a study that examined whether being an IT leader in the 2000s is still as significant a factor in determining business performance as it was in the 1990s. Also, if it is, how have the benefits of being an IT leader changed from the early 1990s to the 2000s? Others文章结构ISR This paper is structured as follows. Section 2 reviews research from the engineering and management literatures that points to a significant increase in the importance of software as an enabler of innovation in four “traditional” manufacturing sectors. We interpret these developments through the lens of the economic literature on general purpose technologies, and identify dimensions of technological change that link the observations of different industry experts to a common underlying cause. While suggestive, earlier research on this shift tends to be somewhat anecdotal, rely- ing heavily on the experience of a small number of firms and a highly selected sample of recent product development efforts. Section 3 presents new statistical evidence based on patent citation data that suggests the software-biased shift in the direction of technological change suggested by the engineering and managerial literatures is real, broad-based, and economically and statistically significant. Section 4 empirically examines the implications of this shift in software intensity for the innovation performance of firms in the four manufacturing sectors that are the focus of our study. Section 5 concludes with a summary of key results and avenues for future research. MSMISQ The purpose of this paper is to employ the resource-based view to develop the theoretical links and empirically examine the association between IT capability and business performance. Since the resource-based view explicitly recognizes the importance of intangibles such as customer orientation and organizational knowledge, it offers a significant opportunity to explore these theoretical complimentarities in examining the relationship between IT resources and firm performance. The remainder of this paper is organized as follows. The next section presents a brief outline of the resource-based theory of the firm followed by an examination of the links between IT resources and firm performance. This is followed by the empirical analysis, describing the data sources and the methodology used to address the research questions. Finally, the results and the implications of the study are presented and some concluding comments offered. In the following subsections, we summarize the early studies in terms of their methods and findings. Then, we report the process and the results of our study in which we updated the aforementioned studies that empirically confirmed the link between IT capability and business performance. Others我的看法在Introduction部分，首先，要强调自己的文章背景是重要的、过往研究中存在不足。其次，需要简单描述自己的文章的大概内容。最后，简介后续文章铺陈。","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Article_Template_MIS","slug":"Article-Template-MIS","permalink":"https://zqzhao.cn/tags/Article-Template-MIS/"}]},{"title":"Social Similarity","slug":"social-similarity","date":"2020-07-09T10:58:02.000Z","updated":"2020-07-09T16:13:02.416Z","comments":true,"path":"2020/07/09/social-similarity/","link":"","permalink":"https://zqzhao.cn/2020/07/09/social-similarity/","excerpt":"","text":"本文考虑社交网络、社会关系间的相似性、距离度量，后续或有补充。 话语相似性 Top management team social interaction and conservative reporting decision: A language style matching approach. Decision Support Systems. LSM（Language Similarity Measure）用于衡量CFO和CEO的话语相似度。文章用meeting record作为数据来源，删掉部分行业以及资产不良的企业。 FWI_{k,i}, k=1, ..., 9. \\tag{1}LSM_{k,i,j} = 1-|FWI_{k,i} - FWI_{k,j}| / |FWI_{k,i} + FWI_{k,j}+0.0001|, k=1, ..., 9. \\tag{2}LSM_{i,j} = E[\\sum_{k=1}^9 LSM_{k,i,j}]\\tag{3}其中，公式（1）衡量第i个总裁在第k类词汇中的词汇强度（Function of Word Intensity），公式（2）衡量第i个和第j个总裁在第k类词汇上的LSM，公式（3）衡量第i个和第j个总裁之间的总话语相似性。 未完待续。。。","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Theorical_Basis","slug":"Theorical-Basis","permalink":"https://zqzhao.cn/tags/Theorical-Basis/"}]},{"title":"Content Analysis Methods","slug":"content-analysis","date":"2020-04-29T08:26:57.000Z","updated":"2020-04-29T08:53:45.587Z","comments":true,"path":"2020/04/29/content-analysis/","link":"","permalink":"https://zqzhao.cn/2020/04/29/content-analysis/","excerpt":"","text":"内容分析方法内容分析法是一个高度结构化的分析方法，其分析过程需要经过精密的设计，以满足分析需要。内容分析法将非定量的文本转化为定量的数据，并依据这些数据做出定量分析，得到关于事实的判断和推论。因此，它对组成文本内容的因素与机构的分析更为细致和程序化。 内容分析法的一般过程包括建立分析目标、确定分析总体、选择分析单位、设计分析维度体系、进行评判记录和分析推论六部分。而其中涉及的主要具体工作就是设计分析维度、文本分类、抽样与评判记录。 另一个版本的过程描述： 其操作步骤主要有：1.阐明研究问题或假设；2.界定研究总体 ；3.从总体中选择合适的样本 ；4.选择和定义分析单位 ；5.构建用以分析的内容类别 ；6.建立量化系统 ；7.培训编码人员并进行试点研究 ；8.根据已有的定义对内容进行编码 ；9.分析采集到的数据 ；10.解释研究结果，得出结论。 抽样工作包括两个方面的内容：一是界定总体，二是从总体中抽取有代表性的样本。内容分析法常用的三种抽样方式为：来源取样、日期抽样与分析单位取样。 分析维度通常在进行具体评判记录前就已经事前确定，在设计分析维度时应考虑如何对内容分析结果进行定量分析，即考虑到使结果适合数据处理的问题。 在进行分类时，需要确定分类标准完全、彻底地适合于所有选定的分析材料，使所有分析单位都可归入相应的类别，不能出现无处可归的现象。在分类中应当使用同一个分类标准，即只能从众多属性中选取一个作为分类依据。分类的层次应该明确，逐级展开，不能越级和出现层级混淆的现象。 评判记录是根据已确定的分析维度和分析单位对样本中的信息作分类记录，登记下每一个分析单位中分析维度是否存在及出现的频率。要做好评判记录工作，需要注意以下几个方面： 按照分析维度用量化方式记录分析对象的量化数据（如有、无、数字形式、百分比）。 采用事先设计好的易于统计分析的评判记录表记录。先把每一分析维度的情况逐一登记下来，然后再做出总计。 在根据类目出现频数进行判断记录时不要忽略基数。","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Theorical_Basis","slug":"Theorical-Basis","permalink":"https://zqzhao.cn/tags/Theorical-Basis/"}]},{"title":"Grounded Theory","slug":"grounded-theory","date":"2020-04-28T14:56:47.000Z","updated":"2020-04-29T07:32:25.755Z","comments":true,"path":"2020/04/28/grounded-theory/","link":"","permalink":"https://zqzhao.cn/2020/04/28/grounded-theory/","excerpt":"","text":"质性研究与定性研究 定性研究的理论基础主要是哲学，其研究传统是一种形而上、思辨的传统；而质的研究的理论基础主要是人种学、现象学、解释学、实证主义理论，具有跨学科、多学科的色彩。 定性研究的方法包括历史法、个案法、观察法、调查法、文献资料分析法、经验总结法等；而质的研究除了上述定性研究方法外，还包含实证研究方法。定性研究注重哲学思辨、逻辑推理，根据个人主观经验，然后用演绎的方法对自己的思考进行验证。质的研究则注重在互动过程中系统收集、分析原始资料的基础上展开讨论。 对于研究的结果，定性研究偏向结论性、抽象性和概括性；质的研究则更加强调研究的过程性、情境性和具体性。定性研究更多地是研究者个人观点的阐发和个人的建议，质的研究强调在原始资料基础上建构结论或理论。 扎根理论的流派区分 Glaser &amp; Strauss 经典扎根理论 1967 Glaser极力反对Strauss将扎根理论程序化，认为Strauss这样做是违背了扎根理论的基本精神——不先入为主的构想问题、提出概念、范畴或假设来强制选择资料和形成理论。在Glaser看来，扎根理论研究的问题不是研究者自己确定的研究问题，而是研究对象所面临的问题，研究者在深入田野工作之前是没有具体研究问题，所有的研究问题、概念及范畴都是随着研究的进展而自然涌现的。而Strauss的程序化版本实际上是在研究之前研究者就有了一个相对完整概念，所谓的“典范矩阵”与“主轴编码”不过是一个生硬促成、事先臆想的概念化描述，是将现有资料填充到预设框架中的过程。 在1992年出版《扎根理论的分析基础：自然呈现与生硬促成》一书中，针对Strauss和Corbin的程序化扎根理论进行批判与回应。 Strauss &amp; Corbin 程序化扎根理论 1990 1990《质性研究基础：扎根理论程序与技术》 在1967年原始版本的基础上，结合具体实践，引入了一些新的概念和方法，如，“维度化”、“主轴编码”和“典范模型”等 Charmaz 建构主义扎根理论 在吸收Glaser和Strauss思想后将建构主义理念与方法融入扎根理论中，并发表了一系列论文与著作，如《建构主义与客观主义扎根理论》、《建构扎根理论：质性研究实践指南》等，由此，也被认定为“建构主义扎根理论”代表。 在Charmaz看来，所有方法论都是人类了解世界的一种方式，人类对世界的理解是一种解释性的，所谓的“真理”与“理论”都具有临时性特征，理论不是被发现的，也不是独立于研究者而存在与数据中，任何理论提供的都是对被研究世界的一种解释性图象，而不是真实面貌。扎根理论也不例外，只是人类理解世界的一种方法论，人类认识世界、理解世界的过程，也是人类与外部世界互动与建构的过程。正因为建构主义思想的引入，使得扎根理论摆脱了实证主义约束，成为一种更具有前瞻性、细致性与反思性的质性研究方法。","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Theorical_Basis","slug":"Theorical-Basis","permalink":"https://zqzhao.cn/tags/Theorical-Basis/"}]},{"title":"experiment","slug":"experiment","date":"2020-04-25T03:56:29.000Z","updated":"2020-04-25T03:59:54.680Z","comments":true,"path":"2020/04/25/experiment/","link":"","permalink":"https://zqzhao.cn/2020/04/25/experiment/","excerpt":"","text":"行为经济学（Behavioral Economics）是将心理学的研究成果引入经济分析的经济学新分支，而实验经济学（Experimental Economics）是行为经济学模型的主要实证手段。行为经济学的研究经过了三代学者的发展。20世纪80—90年代，第一代行为经济学家指出了传统经济理论无法解释的异常现象（如，禀赋效应、阿莱悖论、经济衰退中的工资刚性等）；而20世纪90年代至21世纪初，第二代行为经济学家针对上述心理现象建立一般性的理论模型，如，level-k学习模型、以负罪厌恶为基础的守约模型等；而最近几年第三代行为经济学的研究人员开始将第二代的研究成果运用到应用领域中去，而行为合约设计就是其中的热点。比如，劳动力市场的合约设计将在本文第四部分详细讨论。 sohu博客 （一）科学研究中的内部有效性和外部有效性 任何一种科学研究，都面临着内部有效性和外部有效性两方面的挑战。内部有效性（Internal Validity）是指，研究人员分析某一种特定因素所造成的效果时，一定不能把其他原因造成的效果错误地归结到被研究的对象上。比如，当我们分析一种药物对心血管疾病的疗效时，如果病情较重的人服用了药物而病情较轻的人未服药，那么病情的轻重程度会对分析结论造成干扰；如果参加某种劳动技能培训的人的智力水平高于未参加培训的人的智力水平，那么研究人员所观察到的“技能培训的效果”有可能来自智力水平的差别。而外部有效性（External Validity）是指，从有限样本中得出的研究结论，究竟在多大程度上能推广到总体中去。比如，某一种药在美国的临床实践中取得了效果，那么这种药能否在中国的临床中取得效果？如果理论经济学家所设计出来的市场机制通过经济实验取得了成功，那么这一机制在现实生活中的效果又会如何？ 首先需要指出的是，确保内部有效性是所有研究工作的起点。误读了经济现象背后的真实原因，无论其应用环境是否贴近现实，都必然会误导政策制定与制度安排。在内部有效性得到保证的基础上，研究人员再继续探讨研究结论的外部有效性，即研究结论的适用范围（比如，无论经济学理论研究还是经济学实证研究，都有针对经济学理论模型或实证数据分析的Robustness Check，即适用性检验）。其次需要指出的是，没有任何一种经济学研究方法能在内部有效性和外部有效性两方面同时做到完美，理论（Theories）、实验（Experiments）和观察性实证方法（Observational Empirical Methods）各有所长。经济学实验在经济学的实证研究方法中是内部有效性最强的研究手段，其代价是外部有效性受到一定限制。 （二）经济实验：通过“控制”实现内部有效性 经济实验的本质，就是通过研究人员对实验的“控制”实现内部有效性。经济实验中的控制手段包括：研究人员将来自同一群体（如某高校的本科生）的实验参加者随机分配到不同的实验条件中去、以消除不同实验条件下的参加者的系统性差异，从而不同实验条件下实验结果的差异只能归结于不同实验条件下实验设置的差别，而不能归结于不同实验条件下参加者的差异；在同一实验设置下参加者阅读相同的实验说明，以确保参加者接受相同的信息；实验说明中通常采用中性词语，以避免与研究问题无关的社会偏好对实验结果造成干扰……等。朱富强一文中所讨论的“双盲设计”（即实验参加者之间相互匿名，且参加者对研究人员也匿名），也是一种常见的实验控制手段。“双盲设计”能降低研究人员的观察效应、社会距离等因素对实验结果的干扰。 第一点需要澄清的是，研究人员通过实验设计对实验进行控制的目的，是为了实现内部有效性，而不是像朱富强一文所提到的为了迎合“主流经济学”、确保主流经济理论中的结论被实验验证。以Hoffman，McCabe，Shachat，Smith的研究工作为例（这一工作也在朱富强一文中提到了）：一名实验参加者是分配者，另一名实验参加者是接受者；由分配者将10美元在分配者与接受者之间分配，而接受者只能接受分配者的提案、没有讨价还价的余地。在传统经济学的自利前提下，理论预测分配者会将全部10美元归为己有。但实验结果表明，即便是在双盲设计下，作为分配者的参加者通常会留1到2美元给接受者。这个实验的证据表明利他偏好（Other-Regarding Preference）确实会在经济活动中发挥作用，按照朱富强一文的分类方法，这一实验应该是属于“反主流”的。恰恰是“双盲设计”等严格的实验控制手段，使得Hoffman等人的研究结论更加稳健：即便是在最容易出现自利行为的双盲设计下，研究人员都观察到了利他行为，从而我们很难把这种利他行为归结于研究人员的压力或诱导等其他原因。 第二点需要澄清的是，实验控制从未将实验参加者的社会性抽象掉，“最大限度地将受试者还原为孤立的原子个体，甚至是类似机器般的成本——收益反应者”。经济学理论的出发点，包括关于经济环境的结构性假设和关于经济活动参与主体的行为假设两类。经济实验通过控制，能在实验环境中最大程度再现经济学理论中的结构性假设（如初始禀赋的分布、成本的结构，等等），但实验设计中并不对实验参加者的行为进行假设（参加者是否能够充分有效处理全部信息、是否逆向归纳，等等）。因此，如果实验表明理论失效，能够相对容易地得知理论失效的原因（比如，可以进一步通过实验验证究竟是哪一条行为假设脱离实际情况）。而通过现实生活中的数据检验理论，其难点在于现实生活与经济学理论中的结构性假设存在距离，从而很难确定理论失效的具体原因。 （三）实地实验：对实验结论外部有效性的回应 近年来，学界对经济学实验的批评集中在实验结论的外部有效性上。比如，经济学的实验室实验通常征召本科生作为实验参加者，支付相对较低的报酬，而实验在较短的时间内完成。那么如果参加者群体发生变化（如有丰富经验的从业者）、报酬规模发生变化、实验环境是现实生活中的市场，实验结论是否也会发生变化？ 21世纪日益受到重视的实地实验（Field Experiment）是对这类质疑的有力回应。实地实验是介于实验室实验和完全基于现实市场所自然产生的数据的观察性实证方法之间的一种实证手段。实地实验与实验室实验相同的是，研究人员将实验参与者随机分配到不同实验条件中去，从而能有效避免样本选择或内生性造成的系统性偏差。但实地实验在现实生活中的市场里进行，从而研究人员对实验的控制不如实验室实验完美（如研究人员很难在现实生活中控制价值、成本、信息等因素）。实证方法中，从内部有效性来说，实验室实验最强，实地实验次之，观察性实证方法最弱；从外部有效性来说，顺序正好颠倒：观察性实证方法最强，实地实验次之，实验室实验最弱。","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Theorical_Basis","slug":"Theorical-Basis","permalink":"https://zqzhao.cn/tags/Theorical-Basis/"}]},{"title":"Examination","slug":"examination","date":"2020-04-18T10:57:34.000Z","updated":"2020-04-25T03:57:39.157Z","comments":true,"path":"2020/04/18/examination/","link":"","permalink":"https://zqzhao.cn/2020/04/18/examination/","excerpt":"","text":"What’s the difference between Post-Hoc Examination, Validity Examination, and Robustness Examination? 后验检","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Theorical_Basis","slug":"Theorical-Basis","permalink":"https://zqzhao.cn/tags/Theorical-Basis/"}]},{"title":"NK-model","slug":"nk-model","date":"2020-04-17T12:47:35.000Z","updated":"2020-04-18T04:00:55.758Z","comments":true,"path":"2020/04/17/nk-model/","link":"","permalink":"https://zqzhao.cn/2020/04/17/nk-model/","excerpt":"","text":"McCarthy, I. P., &amp; Tan, Y. K. (2000). Manufacturing competitiveness and fitness landscape theory. Journal of Materials Processing Technology, 107(1-3), 347-352. Esteve Almirall, Ramon Casadesus-Masanell. (2010). Open Versus Closed Innovation: A Model of Discovery and Divergence. Academy of Management Review, Vol. 35, No. 1, 27–47. Sina Blog: 研究工具 - NK MODEL 本文参考了上述材料以及人大经管论坛，现简要陈述NK MODEL如下。非常凑巧的是，这篇博客中的引文是AMR的这篇，正好是本周管理系统模块的选读论文。因此作为NK MODEL的入门文章，应当以此举例。 Link between NK-Model and FLTNK Model脱胎于Fitness Landscape Theory。 What is Fitness Landscape Theory? Fitness Landscape Theory类似于生态学中生态位的概念 对于某一物种而言，不同资源组合会形成适应度不同的环境 在诸多环境中，有几种bundle会特别适合这一物种，称为生态位（此处可以参考经济学中“预算束”的概念） 以资源建立空间坐标系（若有k个资源，即有k维空间），适应度在这一空间内应当形成类似于GMM图像的分布，即Fitness Landscape NK模型研究适用于处理系统内部要素的相互作用关系对系统的整体适应性的问题。由于系统存在复杂性，实证研究无法直接研究各要素间的相互关系以及各要素对系统整体的影响，此时NK模型提供一个间接、简洁、有效的手段对系统进行仿真。 NK模型的理解可以遵循基因型与表型的对应理解。（Kauffman）对应到上述Fitness Landscape Theory，基因型（genotype）的不同组合在此处对应着Fitness Landscape Theory中对资源的不同组合，表型（phenotype）的不同组合在此处对应系统最终的状态。系统的进化，或者说最优解，其实就是生物进化中的最终形态（在自然选择中当前总是保持最适）。NK MODEL本质上是一个进化算法。 基因之间存在交互作用，改变一个基因型并不意味着改变了单一表型而是对整体产生了影响，甚至影响的正面负面也会受到其他基因的调控。这种条件之间的Trade-off即NK模型的研究中心。 NK-Model NK-Model将复杂系统描述为一个由N个元素构成的系统，其中每个元素i都有各自的等位基因。例如$A_i=3$即为第i个元素有3个等位基因。现在我们为每个元素，从其等位基因集合中选出一个基因，则有Feature Vector$&lt; s_1, s_2, …, s_N &gt;$，那么这个Vector即通过限定特征对应了某一System。 在(Almirall, Casadesus-Masanell, 2010)中，将一个完整的System（在文中Syestem即某一Product）均分为2 Subsystem，所以有$&lt;\\alpha, \\beta&gt; = &lt; s_1, s_2, …, s_N &gt; = &lt; s_1, s_2, …, s_{N/2};s_{N/2 + 1}, …, s_N &gt;$。 至此已经解释了NK模型中“N”的含义，最后为“N”Part作结，我们引入系统的设计空间的概念。系统的设计空间（Design Space）即由N个feature组成的N维概率空间。空间的具体大小为$\\Pi_{i=1}^{N}A_i$，也就是组合数。 在(Almirall, Casadesus-Masanell, 2010)中，为了计算方便起见，每个Feature仅有2个等位基因，即设计空间大小为$2^N$。 现在我们要解释K的作用。K衡量的是元素间的interaction，即该系统中每个元素i都与k个其他元素进行交互，即系统复杂度。 在(Almirall, Casadesus-Masanell, 2010)中，对这一部分的描述原文摘录如下： There are $2^N$ possible product configurations. The contribution $c_i$ of each product feature $s_i$ to willingness to pay dependents on other K components. For each of $2^K$ possible combinations, a value is drawn from a uniform probability distribution on [0, 1]. The overall willingness to pay associated with $$ is the average over the N value contributions, WTP(s_1, s_2, ..., s_N) = \\dfrac{\\sum_{i=1}^{N}c_i(s_i; s_{i_1}, s_{i_2}, ..., s_{s_k})}{N}Where $s_{i_j}$, $j=\\{1, …, k\\}$ are the configurations of the K features with which $s_i$ interacts. We assume random assignment of dependencies($i_j$ are determined randomly in the model). 文章的细节还没看完有待补充，NK模型已经解释完毕。","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Theorical_Basis","slug":"Theorical-Basis","permalink":"https://zqzhao.cn/tags/Theorical-Basis/"}]},{"title":"MISQ Research Curation on IS Use","slug":"Burton-summary","date":"2020-04-05T08:28:07.000Z","updated":"2020-04-17T12:48:09.012Z","comments":true,"path":"2020/04/05/Burton-summary/","link":"","permalink":"https://zqzhao.cn/2020/04/05/Burton-summary/","excerpt":"","text":"Burton-Jones, A., Stein, M., Mishra, A. “IS Use,” in MIS Quarterly Research Curations, Ashley Bush and Arun Rai, Eds., http://misq.org/research-curations, December 1, 2017.MIS Quarterly Articles on IS Use Files here. This article is primarily an overview of the research content and the research methods used in IS use related article. Now, I’ll briefly summarize the article and give my comments. Focus of the Research CurationThis part introduce how they retrieve the previous article and determine the rim of dataset, actually “Paper Set” here. The standards is full of manipulation. The main procedure is shown as follow: Segment all the article based on the publish year: 1977-1999, 2000- Determine the search term also based on the publish year Exclude articles focused PURELY on users’ intentions, attitudes, behaviors etc. Exclude articles focused on misuse, abuse and addiction. The author also mention that they include or exclude an article based on their “collective judgement”. Progression of Research in MISQThis part summarize the revolutionary change and evolutionary change in IS use. One steady topic is the importance and the complexity of the IS use. This theme gradually develops since 1977 and still thrive nowadays. However, the sophistication in term measurement and theoretical basis allow researchers to discuss an old terminology in new context. (The article refer to which as the theoretical and empirical research.) “They can account for it with theories and methods that are sensitive to longitudinal, multilevel, and multifactorial contexts rather than reducing the reality of IS use into cross-sectional, single-level, and single-theory thinking.” About 2000, a novel branch of IS acceptance appears, which is due to the broken burble economy of Internet. I think it also devotes to the separation of the publish period. Thematic Advances in KnowledgeFour major thematic advances are mentioned here. Application, refinement, and integrations of various social psychological explanations of It acceptance. Development of theories to account for the dynamics of use. Richer measurement and methodological approaches Continuing expansion of the broader network of constructs. My CommentsWhen looking into the appendix, we find out that in early age of IT use, most of researchers use conceptual framework or qualitative methods while in later period they turn to quantitative methods. My question is : Could the quantitative methods help to clarify or refine the concepts? If so, how? Quantitative methods rely on theoretical basis to consolidate its validity, how can they help to refine the concept? Will the concept or the definition of IT use augment in future? If so, we still need to focus on qualitative methods. Mixed methods research gains its popularity in recent years. What is the exact definition mixed methods research? A SEM combines both qualitative data and quantitative data? Or a three-stage research including qualitative case helps refining the framework and a quantitative method validate the hypothesis?","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"MIS_thinking","slug":"MIS-thinking","permalink":"https://zqzhao.cn/tags/MIS-thinking/"}]},{"title":"Formative Construct and Reflective Construct","slug":"construct","date":"2020-04-05T03:41:10.000Z","updated":"2020-04-17T12:48:03.670Z","comments":true,"path":"2020/04/05/construct/","link":"","permalink":"https://zqzhao.cn/2020/04/05/construct/","excerpt":"","text":"Reading Materials: MISQ 1MacKenzie.pdf 2REVISITING_BIAS 3CRITICAL_IMPORTANCE 4NEGATIVE_CONSEQUENCES 5PLS-SEM Detmar Straub Speech notes","categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"}],"tags":[{"name":"Theorical_Basis","slug":"Theorical-Basis","permalink":"https://zqzhao.cn/tags/Theorical-Basis/"}]},{"title":"GMM","slug":"GMM","date":"2020-03-31T04:02:31.000Z","updated":"2020-04-18T05:33:47.106Z","comments":true,"path":"2020/03/31/GMM/","link":"","permalink":"https://zqzhao.cn/2020/03/31/GMM/","excerpt":"","text":"一些参考资料# 如何实现GMM的概率密度函数 def p(x, mu, sigma): n = len(x) div = (2 * np.pi) ** (n / 2) * (abs(np.linalg.det(sigma)) ** 0.5) expOn = -0.5 * ( np.dot( (x - mu).T, np.dot(np.linalg.inv(sigma), (x - mu)) ) ) return np.exp(expOn) / div 什么是GMM 区别一维单高斯、多维单高斯、混合多高斯 区别一维单高斯、多维单高斯、混合多高斯1 区别一维单高斯、多维单高斯、混合多高斯2 区别一维单高斯、多维单高斯、混合多高斯3 协方差的直观理解 矩阵的负二分之一怎么计算1 矩阵的负二分之一怎么计算2第二个人写的矩阵乘法用dot比较合规 |A|其实是行列式运算 Code 注意区分一维单高斯模型、多维单高斯模型和混合高斯模型 其差别在于单高斯模型SGM总是只有一个峰，不管是在几维空间内总是只有一个峰值 混合高斯模型是多个单高斯模型的概率叠加（这里的SGM不一定是一维内的，也可以是多维的） 一维单高斯模型即正态分布； 多维单高斯模型是在各个维度上分别应用一维单高斯模型，然后通过协方差矩阵刻画维度间相关关系（正相关、负相关、不相关） （下文中将在各个维度中应用标准正态，但事实上或许可以是不标准的正态分布，有待后续尝试） 混合高斯模型相当于samples落在了多个单高斯模型中 （以一个1000Samples，p=[0.4 0.6]的双峰GMM为例，相当于在第一个模型中有400个Samples，而另一个包括600Samples） 1234567import numpy as npimport mathimport random import scipy.stats as stimport matplotlib.pyplot as plt 123456789101112131415161718192021222324252627282930313233343536# 以下试图生成一组符合多维单高斯模型的数据点（此处为2D Gaussian）# 每个维度做SGM 然后x &#x3D; Sigma^0.5*z + mux &#x3D; np.random.uniform(size&#x3D;1000) # Random sequence used for x axisy &#x3D; np.random.uniform(size&#x3D;1000)axis &#x3D; [] # zfor i in range(0, len(x)): x1 &#x3D; st.norm.ppf(x[i], loc&#x3D;0, scale&#x3D;1) # 均值为 loc，标准差为 scale 的正态分布在 each 处的累计分布概率值 y1 &#x3D; st.norm.ppf(y[i], loc&#x3D;0, scale&#x3D;1) axis.append([x1,y1]) axis &#x3D; np.array(axis).T # 这里生成成对的z坐标，单独的z_x和z_y符合标准正态# 以下求sigma的1&#x2F;2次方A &#x3D; np.array([1, 4, 3, 16]).reshape(2,2)v, Q &#x3D; np.linalg.eigh(A) # v 为特征值, Q 为特征向量V &#x3D; np.diag(v**(0.5))Sigma &#x3D; Q.dot(V).dot(np.linalg.inv(Q)) # 得到协方差矩阵的1&#x2F;2次方后，可以对z坐标进行偏置# 协方差矩Sigma阵刻画的是数据点在正交轴的拉伸# 均值mu类似于质心，刻画的是数据点的中心位置漂移 x &#x3D; Sigma.dot(axis).T # x &#x3D; Sigma^0.5*z + mu 这一步做的是数据点的拉伸# 以下生成mu，这里用了很蠢的生成方法，选取的质心是(4,7)m &#x3D; [4 for i in range(0,1000)]for i in range(0,1000): m.append(7)center &#x3D; np.array(m).reshape(2,1000).Tx &#x3D; x + center # x &#x3D; Sigma^0.5*z + mu 这一步做的是质心漂移plt.figure()plt.scatter(x&#x3D;[each[0] for each in x], y&#x3D;[each[1] for each in x])plt.show() 12345678910111213141516171819202122232425262728293031# 以下试图生成一组符合多维单高斯模型的数据点（此处为2D Gaussian）# 每个维度中的默认单高斯模型为标准正态分布def SGM(n, sigma, mu, d&#x3D;2): x &#x3D; np.random.uniform(size&#x3D;n) # Random sequence used for x axis y &#x3D; np.random.uniform(size&#x3D;n) axis &#x3D; [] # z for i in range(0, n): x1 &#x3D; st.norm.ppf(x[i], loc&#x3D;0, scale&#x3D;1) # 均值为 loc，标准差为 scale 的正态分布在 each 处的累计分布概率值 y1 &#x3D; st.norm.ppf(y[i], loc&#x3D;0, scale&#x3D;1) axis.append([x1,y1]) axis &#x3D; np.array(axis).T # 这里生成成对的z坐标，单独的z_x和z_y符合标准正态 # 以下求sigma的1&#x2F;2次方 A &#x3D; np.array(sigma).reshape(d,d) # 注意区分此处的sigma和下文中的Sigma，变量命名还需要注意 v, Q &#x3D; np.linalg.eigh(A) # v 为特征值, Q 为特征向量 V &#x3D; np.diag(v**(0.5)) Sigma &#x3D; Q.dot(V).dot(np.linalg.inv(Q)) x &#x3D; Sigma.dot(axis).T # x &#x3D; Sigma^0.5*z + mu 这一步做的是数据点的拉伸 m &#x3D; [mu[0] for i in range(0,n)] for i in range(0,n): m.append(mu[1]) center &#x3D; np.array(m).reshape(d,n).T x &#x3D; x + center # x &#x3D; Sigma^0.5*z + mu 这一步做的是质心漂移 return x 123456789# 以下试图生成一组符合多2D Mixture of Gaussian (MOG) distribution的数据点# 每个维度中的默认单高斯模型为标准正态分布x1 &#x3D; SGM(n&#x3D;50, sigma&#x3D;[1, 6, 2, 12], mu&#x3D;[5,10], d&#x3D;2)x2 &#x3D; SGM(n&#x3D;100, sigma&#x3D;[9, 4, 2, 1], mu&#x3D;[8,4], d&#x3D;2)plt.figure()plt.scatter(x&#x3D;[each[0] for each in x1], y&#x3D;[each[1] for each in x1], c&#x3D;&#39;blue&#39;)plt.scatter(x&#x3D;[each[0] for each in x2], y&#x3D;[each[1] for each in x2], c&#x3D;&#39;red&#39;)plt.show() 12# 以下合并两个点集total_set &#x3D; np.vstack((x1, x2)) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 以下试图计算每个cluster内的点并打上标记，并试图应用一种pycharm风格的函数注释def cal(cluster, temp_centroid, radius, eps, node, total_set, empty): &quot;&quot;&quot; used for calculate distance between nodes and centroid cluster: the number of cluster temp_centroid: temportary centroid location radius: radius eps: threshold to end the process node: used to illustrate to which cluster the node belongs and the times of calculation in process total_set: locations of nodes empty: 用于标记未使用的点，事实上通过字典查找可以实现，偷个懒浪费内存了，甚至懒得改写成英文 return: node, empty, cent_x, cent_y # cent_? is the final location of temporary cluster &quot;&quot;&quot; print(temp_centroid) cent_x &#x3D; temp_centroid[0] cent_y &#x3D; temp_centroid[1] node_temp &#x3D; [0 for i in range(0, len(total_set))] while True: shift &#x3D; [0, 0] print([cent_x, cent_y]) for i in range(0, len(total_set)): x &#x3D; total_set[i][0] y &#x3D; total_set[i][1] distance2 &#x3D; (x - cent_x)**2 + (y - cent_y)**2 distance &#x3D; math.sqrt(distance2) if distance &lt;&#x3D; radius: # if node in cluster node_temp[i] +&#x3D; 1 try: # 其实本cluster出现并不代表节点是第一次被分类，但我懒得写了，trycatch大法好 empty.remove(i) # delete node already in some cluster except Exception as e: pass shift[0] +&#x3D; x - cent_x shift[1] +&#x3D; y - cent_y # add shift vector mode &#x3D; shift[0]**2 + shift[1]**2 print(&#39;mode&#x3D;&#39;,mode) if mode &lt;&#x3D; eps: break else: cent_x +&#x3D; shift[0]&#x2F;len(total_set) cent_y +&#x3D; shift[1]&#x2F;len(total_set) node.append(node_temp) return node, empty, cent_x, cent_y 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364# Mean Shiftn_of_node &#x3D; len(total_set) # number of nodesprint(1)# 以下为centroid和node初始化centroid &#x3D; [] node &#x3D; [] # 后续通过list形式追加cluster标记，每一个cluster有一行# 以下为node标记做初始化empty &#x3D; [int(i) for i in range(0, n_of_node)] # 用于标记未使用的点temp &#x3D; random.choice(empty) # 每次在未标记点选一个作为当前质心起始点temp_centroid &#x3D; total_set[temp]cluster &#x3D; 0radius &#x3D; 4eps &#x3D; 0.01# 以下得到cluster和node的pairwhile True: node, empty, cent_x, cent_y &#x3D; cal(cluster, temp_centroid, radius, eps, node, total_set, empty) centroid.append([cent_x, cent_y]) print(&#39;cluster&#x3D;&#39;, cluster, &#39; ,cent_num &#x3D;&#39;, len(centroid)) print(node[-1]) for i in range(0, len(centroid)-1): # 考虑合并 distance &#x3D; (centroid[i][0]-centroid[-1][0])**2 + (centroid[i][1]-centroid[-1][1])**2 if math.sqrt(distance) &lt;&#x3D; radius: for j in range(0, len(total_set)): node[i][j] +&#x3D; node[-1][j] node &#x3D; node[:-1] x1 &#x3D; centroid[i][0] x2 &#x3D; centroid[-1][0] y1 &#x3D; centroid[i][1] y2 &#x3D; centroid[-1][1] n1 &#x3D; 0 n2 &#x3D; 0 for k in range(0, len(total_set)): if node[i][k] !&#x3D; 0: n1 +&#x3D; 1 if node[-1][k] !&#x3D; 0: n2 +&#x3D; 1 new_centroid &#x3D; [(n1*x1+n2*x2)&#x2F;(n1+n2), (n1*y1+n2*y2)&#x2F;(n1+n2)] centroid[i] &#x3D; new_centroid centroid &#x3D; centroid[:-1] break if empty &#x3D;&#x3D; []: break else: # update default value cluster +&#x3D; 1 temp &#x3D; random.choice(empty) # 每次在未标记点选一个作为当前质心起始点 temp_centroid &#x3D; total_set[temp]print(node)print(&#39;end&#39;)print(&#39;cluster&#x3D;&#39;, cluster)# 这里有两种合并cluster的做法 # 第一种在每次生成新的cluster以后进行合并，本次作业选择第一种# 第二种在全部结束后观察质心间关系，寻找无向图的component 123456789101112131415161718192021222324252627# 以下尝试构建cluster与点集对应关系result &#x3D; []print(node)for i in range(0, len(total_set)): temp &#x3D; -1 max_v &#x3D; -1 for j in range(0, len(node)): if node[j][i] &gt;&#x3D; max_v: max_v &#x3D; node[j][i] temp &#x3D; j result.append(temp)print(centroid)x_axis &#x3D; [[] for i in range(0, len(centroid))]y_axis &#x3D; [[] for i in range(0, len(centroid))]for i in range(0, len(total_set)): x_axis[result[i]].append(total_set[i][0]) y_axis[result[i]].append(total_set[i][1])plt.figure()for i in range(0, len(centroid)): plt.scatter(x&#x3D;x_axis[i], y&#x3D;y_axis[i])plt.show()","categories":[],"tags":[{"name":"CS_Math","slug":"CS-Math","permalink":"https://zqzhao.cn/tags/CS-Math/"}]},{"title":"SVD","slug":"SVD","date":"2020-03-18T10:05:32.000Z","updated":"2020-04-18T05:42:37.735Z","comments":true,"path":"2020/03/18/SVD/","link":"","permalink":"https://zqzhao.cn/2020/03/18/SVD/","excerpt":"","text":"参考资料和笔记SVD（奇异值分解）Python实现 以及我的个人笔记EVD_and_SVD.pdf Code Dataset使用手写数字识别 以下仅保留数学部分实现 123456789101112131415161718192021# 提取data &#x3D;&gt; 130个3, &quot;32*32&quot; &#x3D;&gt; &quot;16*16&quot;# 这里没有做pixel合并raw_data &#x3D; digitals[3][:130]data &#x3D; []for each in raw_data: # 32*32 &#x3D;&gt; 16*16 line &#x3D; [] for i in range(0, 32, 2): for j in range(0, 32, 2):# pixel &#x3D; eval(each[i][j])# pixel +&#x3D; eval(each[i+1][j])# pixel +&#x3D; eval(each[i][j+1])# pixel +&#x3D; eval(each[i+1][j+1]) # 4个pixel合成一个，类似CNN without overlap line.append(each[i][j]) a &#x3D; np.array(line) data.append(a)# print(a.shape)matrix &#x3D; np.array(data, dtype&#x3D;np.float) # 已经完成转置 X(N,p) &#x3D; X(130, 256) 12345# 对matrix做一步均值化处理matrix_mean &#x3D; np.mean(matrix, axis&#x3D;0)matrix &#x3D; matrix - matrix_mean 1234567891011121314151617181920212223242526272829303132333435# 把取前k个奇异值的操作写成函数，算一下MSE# 此处要注意，奇异值里有一个小于0的值（为什么呢？）# 所以在这一步先进行了前k个的筛选再开方，避免了这一问题def sig(k, matrix): # What if 只取前k个奇异值？ # k &#x3D; 4 # 求奇异值矩阵和左右奇异矩阵 # A &#x3D; U(mxm)E(mxn)V^T(nxn ) || AA^T &#x3D; UEE^TU^T sigma, u &#x3D; np.linalg.eigh(matrix.dot(matrix.T)) # 得到E和U sigma_sort_index &#x3D; np.argsort(sigma)[::-1] # 得到降序排列特征值对应index sigma_sort &#x3D; np.sort(sigma)[::-1] # 得到降序排列特征值 sigma_sort_sqrt &#x3D; np.sqrt(sigma_sort[:k]) # 奇异值 &#x3D; sqrt(T*T) u_sort &#x3D; u[:, sigma_sort_index][:, :k] # 得到降序排列特征值对应特征向量 # 在取了前k个奇异值之后，对应特征向量仅保留前4项，由于u原本为列向量所以列上仅保留前4项 # A &#x3D; UE&#39;(mxm)V&#39;(mxn)^T &#x3D;&gt; V&#39;^T &#x3D; (UE&#39;)^(-1)A &#x3D; (E&#39;)^(-1)U^TA sigma_part &#x3D; np.diag(sigma_sort_sqrt) # 对角化# print(sigma_part.shape) # 这里得到的sigma_part仅为130维，相当于mxm的对角阵，但原式中为mxn # 此处为一个降维操作 # 由于上式中sigma！&#x3D;原式sigma，所以此时v并不为A^TA的特征向量 # 而是要通过U和sigma_part确定 v_part_T &#x3D; np.linalg.inv(sigma_part).dot(u_sort.T).dot(matrix) return sigma_part, u_sort, v_part_T# print(v_part_T.shape)# print(u_sort.shape)# print(sigma_part.shape)","categories":[],"tags":[{"name":"CS_Math","slug":"CS-Math","permalink":"https://zqzhao.cn/tags/CS-Math/"}]},{"title":"News Clustering by Title","slug":"news-clustering","date":"2018-03-13T04:13:06.000Z","updated":"2020-04-05T09:14:15.721Z","comments":true,"path":"2018/03/13/news-clustering/","link":"","permalink":"https://zqzhao.cn/2018/03/13/news-clustering/","excerpt":"","text":"0. Thinking0.1 Word List SelectionCustom word list and divid into two layers by category, summed as final eigenvalues, if there are multiple eigenvalues in the same layer then averaged(although this leads to inaccurate classification, eigenvalues tend to be closer). First.txt Used to categorize the main categories, including philosophy, awards and conference activities, research, promotion Each category starts with a whole hundred and the remaining spaces are replaced by “/n” Using the dictionary sequence number *1000000 as an eigenvalue Second.txt Used to classify sub-categories, including faculties, national regions, international regions, international organizations Each category starts with a whole hundred and the remaining spaces are replaced by “/n” Using the dictionary serial number *1000 as an eigenvalue 0.2 Adjustment in K-meansWhen selecting equal spacing selection or random selection, the final result will lead to unevenness in some classes, so select the starting centroid according to a given list, the list has 10 elements, the selected k-value is less than or equal to 10, then selected in the list; the selected k-value is greater than 10, more than 10 parts of the overall medium spacing selection. 1list &#x3D; [50000000, 150000000, 250000000, 350000000, 450000000, 50000, 150000, 250000, 350000, 450000] 0.3 Text Processing Use regular matching to remove punctuation after source text is entered The dictionary is re-ordered according to python’s built-in sort function, because we also need to find a feature word belongs to the original feature word class in reverse, so select the new dictionary, including both the feature word and the original serial number (dictionary’s subscript serial number expresses the current new serial number, the new serial number is easy to find half) 1. Input1.1 CrawlerFirst we crawled 3000+ news headlines on the home page of Zhejiang University. 12345678910111213141516171819202122232425262728293031# -*- coding: utf-8 -*-__author__ &#x3D; &#39;Zhao&#39;from bs4 import BeautifulSoupimport requestssName &#x3D; &quot;new.txt&quot;f &#x3D; open(sName, &#39;w+&#39;)for i in range(1,188): url &#x3D; &quot;http:&#x2F;&#x2F;www.zju.edu.cn&#x2F;xw&#x2F;list&quot; + str(i) + &quot;.htm&quot; headers &#x3D; &#123; &#39;User-Agent&#39;:&quot;Mozilla&#x2F;5.0 (Macintosh; Intel Mac OS X 10_12_5) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;59.0.3071.115 Safari&#x2F;537.36&quot;, &#125; r &#x3D; requests.get(url, headers&#x3D;headers) r.encoding&#x3D;&#39;utf-8&#39; demo &#x3D; r.text soup &#x3D; BeautifulSoup(demo,&#39;html.parser&#39;) # print(&quot;**********************&quot;) for result in soup.find_all(&quot;ul&quot;, &quot;news&quot;): m&#x3D;result.get_text() # print(m) f.write(m) print(url)f.close() 1.2 RegularizationThen regularize to get the title list - this step is relatively simple, just call the re module and leave the code alone here. (Actually, I realized I didn’t save this code…) 1.3 Word ListWhen creating the word list, I chose to double match, that is, first assign a value to each title according to the main keyword, which is larger, and then delete the value according to the secondary keyword. Since the end is abstracted to digital clustering, this works relatively well. (Of course, the results weren’t actually that great.) 2. ClusteringHere I’ve been lazily using the previous participle algorithm… That algorithm is not very accurate. Of course, it has no effect on the small jobs… 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517# -*- coding: utf-8 -*-__author__ &#x3D; &#39;Zhao&#39;# 浙江大学新闻网的list进行相似度计算，并且进行k-means聚类import operatorimport reimport mathfrom decimal import getcontext# import comp_char from cnsortpath &#x3D; &#39;lib&#x2F;&#39;fp &#x3D; open(path + &#39;First.txt&#39;, encoding&#x3D;&#39;utf-8&#39;)ori &#x3D; fp.readlines()# ori is the list with out any operationcopy &#x3D; []new_list &#x3D; []for x in ori: x &#x3D; re.sub(r&#39;\\n&#39;, &#39;&#39;, x) copy.append(x) new_list.append(x)# in this part we change the format in a into standard format and save as copyfp.close()# we close the file, then we can run the list totally in this programcopy.sort()id &#x3D; 0dictionary &#x3D; []for element in copy: if element !&#x3D; &#39;&#39;: dictionary.append([]) dictionary[id].append(element) for ele in new_list: if ele &#x3D;&#x3D; element and len(dictionary[id]) &lt; 2: dictionary[id].append(new_list.index(ele)) id +&#x3D; 1# using new list to substitute original dictionary which contains lots of &#39;&#39; (it&#39;s hard to visualize.)id &#x3D; 0for element in dictionary: print(id, &quot; &quot;, element, end&#x3D;&quot; &#x2F; &quot;) print(&quot; &quot;, copy[id]) id +&#x3D; 1print(&quot;----------&quot;)path &#x3D; &#39;scrapy&#x2F;&#39;f &#x3D; open(path + &#39;ori_news.txt&#39;)ori &#x3D; f.readlines()# ori is the list with out any operationtext &#x3D; []for x in ori: x &#x3D; re.sub(r&#39;\\n&#39;, &#39;&#39;, x) text.append(x)# in this part we change the format in a into standard format and save as copyfp.close()# we close the file, then we can run the list totally in this program# ------------- upper is reading part including wordlist and text -------------index &#x3D; []for x in ori: index.append([])# ------------- upper is append a vacant list prepared to insert index -------------for str_input in text: str_input &#x3D; re.sub(r&#39;,&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;，&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;\\.&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;。&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;——&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;……&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;！&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;!&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;\\?&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;？&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;;&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;；&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39; &#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;&#x2F;&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;、&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;&quot;&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;\\&#39;&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;&lt;&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;&gt;&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;《&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;》&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;\\(&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;\\)&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;（&#39;, &quot;&quot;, str_input) str_input &#x3D; re.sub(r&#39;）&#39;, &quot;&quot;, str_input) # change all the punctuation as blank, however, we may split falsely. # Words get around, the step can also split at wrong place, so, I do not fix this mistake.# ------------- upper is transforming part -------------temp_text &#x3D; -1for str_input in text: temp_text +&#x3D; 1 str_head &#x3D; 0 str_tail &#x3D; len(str_input) ptr &#x3D; 5 temp &#x3D; 0 # 当前处理字段起始位置 # result &#x3D; [] # ch_index &#x3D; [] exact_num &#x3D; 0 # we sort dictionary(the copy) in this program and each word has two characteristic number # using as index to look back on original dictionary while temp &lt; str_tail - 1: flag &#x3D; 0 ptr &#x3D; 5 while flag !&#x3D; 1: in_put &#x3D; str_input[temp:temp + ptr] # 当前处理字段 tail &#x3D; len(dictionary) - 1 head &#x3D; 0 half &#x3D; int((tail + head) &#x2F; 2) while tail !&#x3D; half and head !&#x3D; half: if operator.lt(dictionary[half][0], in_put): # 如果字符组的一半比input小 head &#x3D; half half &#x3D; int((tail + head) &#x2F; 2) elif operator.gt(dictionary[half][0], in_put): # 如果字符组的一半比input大 tail &#x3D; half half &#x3D; int((tail + head) &#x2F; 2) elif operator.eq(dictionary[half][0], in_put): flag &#x3D; 1 temp +&#x3D; len(in_put) if tail !&#x3D; 11 and in_put !&#x3D; &quot;&quot;: try: exact_num &#x3D; dictionary[half][1] except: print(half) # print(&quot;exact_num &#x3D; &quot;,exact_num) index[temp_text].append(exact_num * 1000000) # index[temp_text].append(half) # 这个语句仅用于调试之后的Part A部分 break if ptr &#x3D;&#x3D; 0 and temp &lt;&#x3D; len(str_input) - 1: # print(str_input[temp], end&#x3D;&#39;&#x2F;&#39;) # result.append(str_input[temp]) # ch_index.append(-1) temp +&#x3D; 1 flag &#x3D; 1 if flag &#x3D;&#x3D; 0: ptr -&#x3D; 1 # ------ Part A 仅用于调试变量 具体用于探测特征变量 ------ # print(text[temp_text]) # for element in index[temp_text]: # print(element,end&#x3D;&quot; &quot;) # # print(dictionary[element]) # print(&quot;&quot;) # # print(index[temp_text]) # print(&quot;------------------------------&quot;) # ------ Part A END ------ if len(index[temp_text]) &gt; 1: sum &#x3D; 0 for element in index[temp_text]: sum +&#x3D; element average &#x3D; sum &#x2F; len(index[temp_text]) index[temp_text] &#x3D; [] index[temp_text].append(int(average)) # ------ Part B 仅用于调试变量 具体用于探测特征变量 ------ # print(text[temp_text]) # print(index[temp_text]) # print(&quot;-------------&quot;) # ------ Part B END ------# ------------ Upper is first array for the title (the main class) ------------path &#x3D; &#39;lib&#x2F;&#39;fp &#x3D; open(path + &#39;Second.txt&#39;, encoding&#x3D;&#39;utf-8&#39;)ori &#x3D; fp.readlines()# ori is the list with out any operationcopy &#x3D; []new_list &#x3D; []for x in ori: x &#x3D; re.sub(r&#39;\\n&#39;, &#39;&#39;, x) copy.append(x) new_list.append(x)# in this part we change the format in a into standard format and save as copyfp.close()# we close the file, then we can run the list totally in this programcopy.sort()id &#x3D; 0dictionary &#x3D; []for element in copy: if element !&#x3D; &#39;&#39;: dictionary.append([]) dictionary[id].append(element) for ele in new_list: if ele &#x3D;&#x3D; element and len(dictionary[id]) &lt; 2: dictionary[id].append(new_list.index(ele)) id +&#x3D; 1# using new list to substitute original dictionary which contains lots of &#39;&#39; (it&#39;s hard to visualize.)id &#x3D; 0for element in dictionary: print(id, &quot; &quot;, element, end&#x3D;&quot; &#x2F; &quot;) print(&quot; &quot;, copy[id]) id +&#x3D; 1print(&quot;----------&quot;)# ------------- upper is reading part including the second wordlist -------------temp_text &#x3D; -1for str_input in text: temp_text +&#x3D; 1 # str_head &#x3D; 0 str_tail &#x3D; len(str_input) ptr &#x3D; 5 temp &#x3D; 0 # 当前处理字段起始位置 while temp &lt; str_tail - 1: flag &#x3D; 0 ptr &#x3D; 5 while flag !&#x3D; 1: in_put &#x3D; str_input[temp:temp + ptr] # 当前处理字段 tail &#x3D; len(dictionary) - 1 head &#x3D; 0 half &#x3D; int((tail + head) &#x2F; 2) while tail !&#x3D; half and head !&#x3D; half: if operator.lt(dictionary[half][0], in_put): # 如果字符组的一半比input小 head &#x3D; half half &#x3D; int((tail + head) &#x2F; 2) elif operator.gt(dictionary[half][0], in_put): # 如果字符组的一半比input大 tail &#x3D; half half &#x3D; int((tail + head) &#x2F; 2) elif operator.eq(dictionary[half][0], in_put): flag &#x3D; 1 temp +&#x3D; len(in_put) if tail !&#x3D; 11 and in_put !&#x3D; &quot;&quot;: try: exact_num &#x3D; dictionary[half][1] except: print(half) index[temp_text].append(exact_num * 1000) # index[temp_text].append(half) # 这个语句仅用于调试之后的Part A部分 break if ptr &#x3D;&#x3D; 0 and temp &lt;&#x3D; len(str_input) - 1: temp +&#x3D; 1 flag &#x3D; 1 if flag &#x3D;&#x3D; 0: ptr -&#x3D; 1 # ------ Part A 仅用于调试变量 具体用于探测特征变量 ------ # print(text[temp_text]) # for element in index[temp_text]: # print(element,end&#x3D;&quot; &quot;) # # print(dictionary[element]) # print(&quot;&quot;) # # print(index[temp_text]) # print(&quot;------------------------------&quot;) # ------ Part A END ------ if len(index[temp_text]) &gt; 1: sum &#x3D; 0 for i in range(1, len(index[temp_text])): sum +&#x3D; index[temp_text][i] average &#x3D; sum &#x2F; len(index[temp_text]) average +&#x3D; index[temp_text][0] index[temp_text] &#x3D; [] index[temp_text].append(int(average)) # ------ Part B 仅用于调试变量 具体用于探测特征变量 ------ # print(text[temp_text]) # print(index[temp_text]) # print(&quot;-------------&quot;) # ------ Part B END ------# ------------ Upper is second array for the title (the second class) ------------for element in index: if element &#x3D;&#x3D; []: element.append(0)# ------------ 如果仍然没有结果 那么用0替代这个分组 --------------list &#x3D; [50000000, 150000000, 250000000, 350000000, 450000000, 50000, 150000, 250000, 350000, 450000]# ------------ Start Clustering -------------getcontext().prec &#x3D; 4k &#x3D; int(input(&quot;please input k:\\n&quot;))new_ori_set &#x3D; [float(item[0]) for item in index]centroid &#x3D; []if k &lt;&#x3D; 10: for i in range(0,k-1): centroid.append(list[i])else: for element in list: centroid.append(element) step &#x3D; (len(new_ori_set) - 0) &#x2F; (k-10) # print(new_ori_set) temp &#x3D; 0 while temp &lt; len(new_ori_set): centroid.append(new_ori_set[math.trunc(temp)]) temp +&#x3D; stepprint(&quot;original centroids: &quot;, centroid, &quot;\\n&quot;)class_i &#x3D; [[] for i in range(len(centroid))]class_text &#x3D; [[] for i in range(len(centroid))]# class_i is the null class for k centroidflag &#x3D; 1number &#x3D; 0times &#x3D; 0# sign if k never change or this program runs more than 100 timeswhile flag &#x3D;&#x3D; 1 and times &lt; 100: number +&#x3D; 1 flag &#x3D; 0 times +&#x3D; 1 class_i &#x3D; [[] for i in range(len(centroid))] class_text &#x3D; [[] for i in range(len(centroid))] # class_i is the null class for k centroid for i in range(0, len(new_ori_set)): distance &#x3D; float(&quot;inf&quot;) centroid_in_choose &#x3D; 0 for j in range(0, len(centroid)): if abs(new_ori_set[i] - centroid[j]) &lt; distance: distance &#x3D; abs(new_ori_set[i] - centroid[j]) centroid_in_choose &#x3D; j class_i[centroid_in_choose].append(new_ori_set[i]) class_text[centroid_in_choose].append(i) # sort all the elements into proper class # ------------ 每次 Clustering 之后的结果输出 ------------ # print(&quot;after %sth cluster: &quot; % number, &quot;\\n&quot;) # print(&quot;centroid class&quot;) # for i in range(0, len(class_i)): # print(centroid[i], &#39; &#39;, class_i[i]) # # print(&quot;---------&quot;) # ------------ 每次 Clustering 之后的结果输出 END ------------ for i in range(0, len(class_i)): sum &#x3D; 0 for j in range(0, len(class_i[i])): sum +&#x3D; class_i[i][j] if sum !&#x3D; 0: new_centroid &#x3D; round(sum &#x2F; len(class_i[i]), 3) else: continue if new_centroid !&#x3D; centroid[i]: # print(&quot;change centroid &quot;, centroid[i], &quot;as &quot;, end&#x3D;&quot;&quot;) centroid[i] &#x3D; new_centroid # print(centroid[i]) flag &#x3D; 1 # print(&quot;---------&quot;) # change the wrong centroid# ------------ Clustering 最终结果输出 -----------# print(&quot;THE CONCLUSION IS：&quot;)# print(&quot;centroid class&quot;)# for i in range(0, len(class_i)):# print(centroid[i], &#39; &#39;, [text[element] for element in class_text[i]])# ------------ Clustering 最终结果输出 END -----------# -------------- * UPPER IS CLUSTERING, CLUSTERING IS END.* --------------# ------------ 输出到txt -------------try: path &#x3D; &#39;out&#x2F;&#39; f &#x3D; open(path + &quot;result.txt&quot;, &quot;w+&quot;) f.write(&quot;cat\\ttitle\\n&quot;) for i in range(0, len(class_i)): for element in class_text[i]: f.write(str(i) + &quot;\\t&quot; + text[element] + &quot;\\n&quot;) f.close() print(&quot;Print out %d classes successfully.&quot;%k)except: print(&quot;Print out to txt ERROR.&quot;)# ------------ 输出到txt END -------------","categories":[{"name":"Tech","slug":"Tech","permalink":"https://zqzhao.cn/categories/Tech/"}],"tags":[{"name":"Clustering","slug":"Clustering","permalink":"https://zqzhao.cn/tags/Clustering/"}]},{"title":"Chinese Characters Clustering","slug":"simple-chs-clustering","date":"2018-01-25T08:47:26.000Z","updated":"2020-04-05T02:57:13.105Z","comments":true,"path":"2018/01/25/simple-chs-clustering/","link":"","permalink":"https://zqzhao.cn/2018/01/25/simple-chs-clustering/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304# -*- coding: utf-8 -*-__author__ &#x3D; &#39;Zhao&#39;import reimport operatorblank &#x3D; [chr(183)]tabs &#x3D; [&#39;&#39;]def tree(lst): l &#x3D; len(lst) if l &#x3D;&#x3D; 0: print(&#39;─&#39; * 3) else: for i, j in enumerate(lst): if i !&#x3D; 0: print(tabs[0], end&#x3D;&#39;&#39;) if l &#x3D;&#x3D; 1: s &#x3D; &#39;─&#39; * 3 elif i &#x3D;&#x3D; 0: s &#x3D; &#39;┬&#39; + &#39;─&#39; * 2 elif i + 1 &#x3D;&#x3D; l: s &#x3D; &#39;└&#39; + &#39;─&#39; * 2 else: s &#x3D; &#39;├&#39; + &#39;─&#39; * 2 print(s, end&#x3D;&#39;&#39;) if isinstance(j, list) or isinstance(j, tuple): if i + 1 &#x3D;&#x3D; l: tabs[0] +&#x3D; blank[0] * 3 else: tabs[0] +&#x3D; &#39;│&#39; + blank[0] * 2 tree(j) else: print(&quot; &quot;, j) tabs[0] &#x3D; tabs[0][:-3]def judge_element_delete(list_input, centroid, group, match_num): for list_element in list_input: if isinstance(list_element, list): for element in list_element: if element &#x3D;&#x3D; match_num: del centroid[list_input.index(list_element)] del group[list_input.index(list_element)] else: if list_element &#x3D;&#x3D; match_num: del centroid[list_input.index(list_element)] del group[list_input.index(list_element)]# --------------- in this part we save the list as list ---------------path &#x3D; &#39;&#x2F;Users&#x2F;apple&#x2F;desktop&#x2F;&#39;fp &#x3D; open(path + &#39;list.txt&#39;)ori &#x3D; fp.readlines()# ori is the list with out any operationcopy &#x3D; []for x in ori: x &#x3D; re.sub(r&#39;\\n&#39;, &#39;&#39;, x) copy.append(x)# in this part we change the format in a into standard format and save as copyfp.close()# we close the file, then we can run the list totally in this programcopy.sort()# --------------- this part end ---------------# in this part we know the average length in this list is 2, thus we set step as 5.# In that case, we can contain at least one word.# totally, there are 56064 words in this list and only 56 is longer than 5.# In that case, 5 can be a reasonable step for this program.# sum &#x3D; 0# num &#x3D; 0# for x in copy:# sum +&#x3D; len(x)# num +&#x3D; 1# average &#x3D; (int)(sum&#x2F;num)# print(average, &#39; &#39;, num);# max_lenth &#x3D; 0# for x in copy:# if max_lenth &lt; len(x):# max_lenth &#x3D; len(x)## print(max_lenth)# number &#x3D; 0# for x in copy:# if len(x) &gt; 5:# number +&#x3D; 1## print(number)# --------------- the upper is the calculation in the preparation ---------------str_input &#x3D; input(&quot;请输入一个段落：\\n&quot;)str_input &#x3D; re.sub(r&#39;,&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39;，&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39;\\.&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39;。&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39;——&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39;……&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39;！&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39;!&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39;\\?&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39;？&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39;;&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39;；&#39;, &quot;&quot;, str_input)str_input &#x3D; re.sub(r&#39; &#39;, &quot;&quot;, str_input)# change all the punctuation as blank, however, we may split falsely.# Words get around, the step can also split at wrong place, so, I do not fix this mistake.str_head &#x3D; 0str_tail &#x3D; len(str_input)ptr &#x3D; 5temp &#x3D; 0step &#x3D; 5result &#x3D; []ch_index &#x3D; []while temp &lt; str_tail-1: flag &#x3D; 0 ptr &#x3D; 5 while flag !&#x3D; 1: in_put &#x3D; str_input[temp:temp + ptr] tail &#x3D; len(copy) head &#x3D; 0 half &#x3D; int((tail + head) &#x2F; 2) while tail !&#x3D; half and head !&#x3D; half: if operator.lt(copy[half], in_put): # 如果字符组的一半比input小 head &#x3D; half half &#x3D; int((tail + head) &#x2F; 2) elif operator.gt(copy[half], in_put): # 如果字符组的一半比input大 tail &#x3D; half half &#x3D; int((tail + head) &#x2F; 2) else: # print(in_put, end&#x3D;&#39;&#x2F;&#39;) result.append(in_put) ch_index.append(half) flag &#x3D; 1 temp +&#x3D; len(in_put) break if ptr &#x3D;&#x3D; 0 and temp &lt;&#x3D; len(str_input)-1: # print(str_input[temp], end&#x3D;&#39;&#x2F;&#39;) result.append(str_input[temp]) ch_index.append(-1) temp +&#x3D; 1 flag &#x3D; 1 if flag &#x3D;&#x3D; 0: ptr -&#x3D; 1group &#x3D; resultcentroid &#x3D; ch_index# group &#x3D; input(&quot;Please input some numbers spit as blank:\\n&quot;).split(&quot; &quot;)# group_num &#x3D; len(group)# for element in group:# centroid.append(int(element))precision &#x3D; 0for element in group: precision &#x3D; len(element) if len(element) &gt; precision else precisiongroup_num &#x3D; len(group)while group_num !&#x3D; 2: # print(&quot;the numbers of groups now is &quot;, group_num, &quot;\\n&quot;) matrix &#x3D; [[] for i in range(group_num)] for i in range(group_num): for j in range(group_num): distance &#x3D; abs(int(centroid[i]) - int(centroid[j])) matrix[i].append(distance) # --------------- matrix --------------- # print(&quot;distance matrix :&quot;) # for i in range(group_num): # print(matrix[i]) # matrix contains the distance between every two elements # print(&quot;------------&quot;) max_in_matrix &#x3D; 0 for i in range(group_num): for j in range(group_num): max_in_matrix &#x3D; max_in_matrix if max_in_matrix &gt; matrix[i][j] else matrix[i][j] # print(max_in_matrix) # if max_in_matrix &#x3D;&#x3D; 0: # break for i in range(group_num): for j in range(group_num): matrix[i][j] &#x2F;&#x3D; max_in_matrix matrix[i][j] &#x3D; round(1 - matrix[i][j], precision) if round(1 - matrix[i][j], precision) !&#x3D; 1 else 0 # print(&quot;standard matrix :&quot;) # for i in range(group_num): # print(matrix[i]) # print(&quot;------------&quot;) # standard the matrix similarity &#x3D; 0 for i in range(group_num): for j in range(group_num): similarity &#x3D; similarity if similarity &gt; matrix[i][j] else matrix[i][j] # print(&quot;max similarity in the matrix: &quot;, max_in_matrix, &quot;\\n&quot;) # --------------- matrix --------------- # find the max similarity in this matrix temp_class &#x3D; [] index &#x3D; [] flag &#x3D; 0 for i in range(group_num): for j in range(group_num): if matrix[i][j] &#x3D;&#x3D; similarity: index.append(i) index.append(j) flag &#x3D; 1 temp_class.append(group[i]) temp_class.append(group[j]) if flag &#x3D;&#x3D; 1: break if flag &#x3D;&#x3D; 1: break # find the first center index of new group group_num &#x3D; len(group) for i in range(group_num): if matrix[index[0]][i] &#x3D;&#x3D; similarity and i !&#x3D; index[1]: temp_class.append(group[i]) index.append(i) for i in range(group_num): if matrix[index[1]][i] &#x3D;&#x3D; similarity and i !&#x3D; index[0]: temp_class.append(group[i]) index.append(i) new_centroid &#x3D; 0 for element in index: new_centroid +&#x3D; centroid[element] new_centroid &#x2F;&#x3D; len(index) for element in index: group[element] &#x3D; &#39;substitute&#39; centroid[element] &#x3D; &#39;substitute&#39; lenth &#x3D; len(group) temp_flag &#x3D; 0 while temp_flag !&#x3D; 1: temp_flag &#x3D; 1 for i in range(0, lenth): if group[i] &#x3D;&#x3D; &#39;substitute&#39;: del group[i] lenth &#x3D; len(group) temp_flag &#x3D; 0 break lenth &#x3D; len(centroid) temp_flag &#x3D; 0 while temp_flag !&#x3D; 1: temp_flag &#x3D; 1 for i in range(0, lenth): if centroid[i] &#x3D;&#x3D; &#39;substitute&#39;: del centroid[i] lenth &#x3D; len(centroid) temp_flag &#x3D; 0 break group.append(temp_class) centroid.append(new_centroid) group_num &#x3D; len(group)print(group)tree(group)","categories":[{"name":"Tech","slug":"Tech","permalink":"https://zqzhao.cn/categories/Tech/"}],"tags":[{"name":"Clustering","slug":"Clustering","permalink":"https://zqzhao.cn/tags/Clustering/"}]},{"title":"Python 3.5 Set-Up","slug":"python-setting","date":"2017-11-16T08:13:09.000Z","updated":"2020-04-05T04:10:19.867Z","comments":true,"path":"2017/11/16/python-setting/","link":"","permalink":"https://zqzhao.cn/2017/11/16/python-setting/","excerpt":"","text":"install Homebrew1&#x2F;usr&#x2F;bin&#x2F;ruby -e &quot;$(curl -fsSL https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Homebrew&#x2F;install&#x2F;master&#x2F;install)&quot; Jump if already installed. It’s necessary to update your homebrew to the latest version. 2020-04-05 Update: If you get blocked, try to fix the problem by this. Use Homebrew install Python3 &amp; pip3 (pip is a package management tool for Python), automatically latest version, you may choose another version. 1$ brew install python3 We use pip3 because we want to use Python 3.x.x. If you need pip simply, try1$ sudo easy_install pip install pip need administrator role Check the version 1234$python --version$python3 --version$pip --version$pip3 --version Install [PyCharm](https://www.jetbrains.com/pycharm/). I recommend community edition. If you want the professional edition, there is a Free JetBrains Products License Server. Install additional packages: For example, bs4 (BeautifulSoup 4): PyCharm offer you an inner package management tool: Preferences —&gt; Project —&gt; Project Interpreter Click “+” to install packages you need. Usually there are some errors, follow its introduction and try again. At most cases, error occurs when you revoke the administrator role. So… sudoplease Another way is to install in the terminal: $ pip3 install bs4 if any problems, follow the introduction and try again. Usually you need to upgrade your “pip” “homebrew” “python” or other relative package.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://zqzhao.cn/categories/Tech/"}],"tags":[]},{"title":"Hierarchical Clustering","slug":"hierarchical-clustering","date":"2017-11-14T10:28:27.000Z","updated":"2020-04-18T05:55:07.958Z","comments":true,"path":"2017/11/14/hierarchical-clustering/","link":"","permalink":"https://zqzhao.cn/2017/11/14/hierarchical-clustering/","excerpt":"","text":"周志华《机器学习》中的层次聚类算法太简单了，这个算法里考虑到了多个子类聚成同一个父类的情况。但是时间精力有限，没有办法实现完美的树状输出，Bonus中我会改进。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151# -*- coding: utf-8 -*-__author__ &#x3D; &#39;Zhao&#39;import mathimport numpy as npdef judge_element_append(list_input): if isinstance(list_input, list): for element in list_input: temp_class.append(element) else: temp_class.append(list_input)def judge_element_delete(list_input, aim_list, match_num): for list_element in list_input: if isinstance(list_element, list): for element in list_element: if element &#x3D;&#x3D; match_num: del aim_list[list_input.index(list_element)] else: if list_element &#x3D;&#x3D; match_num: del aim_list[list_input.index(list_element)]group &#x3D; []group &#x3D; input(&quot;Please input some numbers spit as blank:\\n&quot;).split(&quot; &quot;)group_num &#x3D; len(group)centroid &#x3D; []for i in range(group_num): centroid.append(group[i])print(&quot;centroid is &quot;, centroid, &quot;\\n&quot;)times &#x3D; 0# auto-incrementwhile group_num !&#x3D; 1: group_num &#x3D; len(group) print(&quot;the numbers of groups now is &quot;, group_num, &quot;\\n&quot;) matrix &#x3D; [[] for i in range(group_num)] for i in range(group_num): for j in range(group_num): distance &#x3D; abs(int(centroid[i]) - int(centroid[j])) matrix[i].append(distance) print(&quot;distance matrix :&quot;) for i in range(group_num): print(matrix[i]) # matrix contains the distance between every two elements print(&quot;------------&quot;) max_in_matrix &#x3D; 0 for i in range(group_num): for j in range(group_num): max_in_matrix &#x3D; max_in_matrix if max_in_matrix &gt; matrix[i][j] else matrix[i][j] # print(max_in_matrix) for i in range(group_num): for j in range(group_num): matrix[i][j] &#x2F;&#x3D; max_in_matrix matrix[i][j] &#x3D; round(1 - matrix[i][j], 3) if round(1 - matrix[i][j], 3) !&#x3D; 1 else 0 print(&quot;standard matrix :&quot;) for i in range(group_num): print(matrix[i]) print(&quot;------------&quot;) # standard the matrix max_in_matrix &#x3D; 0 for i in range(group_num): for j in range(group_num): max_in_matrix &#x3D; max_in_matrix if max_in_matrix &gt; matrix[i][j] else matrix[i][j] print(&quot;max similarity in the matrix: &quot;, max_in_matrix, &quot;\\n&quot;) # find the max similarity in this matrix if max_in_matrix &#x3D;&#x3D; 0: temp_class &#x3D; [] for i in range(group_num): judge_element_append(group[i]) # print(&quot;last temp_group &#x3D; &quot;, temp_class) for i in range(len(temp_class)): judge_element_delete(group, centroid, temp_class[i]) judge_element_delete(group, group, temp_class[i]) group.append(temp_class) print(&quot;[CONCLUSION]: &quot;, group) break temp_class &#x3D; [] index1 &#x3D; 0 index2 &#x3D; 0 flag &#x3D; 0 for i in range(group_num): for j in range(group_num): if matrix[i][j] &#x3D;&#x3D; max_in_matrix: index1 &#x3D; i index2 &#x3D; j flag &#x3D; 1 judge_element_append(group[i]) judge_element_append(group[j]) if flag &#x3D;&#x3D; 1: break # find the first center index of new group group_num &#x3D; len(group) # print(group_num) for i in range(group_num): if matrix[index1][i] &#x3D;&#x3D; max_in_matrix and i !&#x3D; index2: judge_element_append(group[i]) # group_num &#x3D; len(group) for i in range(group_num): if matrix[index2][i] &#x3D;&#x3D; max_in_matrix and i !&#x3D; index1: judge_element_append(group[i]) times +&#x3D; 1 print(&quot;after %dth clustering: &quot; % times) # print(&quot;temp_group &#x3D; &quot;, temp_class) for i in range(len(temp_class)): judge_element_delete(group, centroid, temp_class[i]) judge_element_delete(group, group, temp_class[i]) group.append(temp_class) print(&quot;the new group is &quot;, group) sum &#x3D; 0 for i in range(len(temp_class)): sum +&#x3D; int(temp_class[i]) centroid.append(sum &#x2F; len(temp_class)) print(&quot;the new centroid is &quot;, centroid, &quot;\\n&quot;) print(&quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;EHD OF ONE CLUSTERING&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\\n&quot;)","categories":[{"name":"Tech","slug":"Tech","permalink":"https://zqzhao.cn/categories/Tech/"}],"tags":[{"name":"Clustering","slug":"Clustering","permalink":"https://zqzhao.cn/tags/Clustering/"}]},{"title":"Naive K-Means","slug":"k-means","date":"2017-11-02T10:54:03.000Z","updated":"2020-04-18T05:46:11.337Z","comments":true,"path":"2017/11/02/k-means/","link":"","permalink":"https://zqzhao.cn/2017/11/02/k-means/","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576# -*- coding: utf-8 -*-__author__ &#x3D; &#39;Zhao&#39;import mathfrom decimal import getcontextgetcontext().prec &#x3D; 4origin_set &#x3D; []origin_set &#x3D; input(&quot;please input a set which is consist of numbers:\\n&quot;).split(&quot; &quot;)k &#x3D; int(input(&quot;please input k:\\n&quot;))origin_set &#x3D; [float(item) for item in origin_set]step &#x3D; (len(origin_set) - 0) &#x2F; kcentroid &#x3D; []temp &#x3D; 0while temp &lt; len(origin_set): centroid.append(origin_set[math.trunc(temp)]) temp &#x3D; temp + stepprint(&quot;original centroids: &quot;, centroid, &quot;\\n&quot;)class_i &#x3D; [[] for i in range(len(centroid))]# class_i is the null class for k centroidflag &#x3D; 1number &#x3D; 0# sign if k never changewhile flag &#x3D;&#x3D; 1: number +&#x3D; 1 flag &#x3D; 0 class_i &#x3D; [[] for i in range(len(centroid))] # class_i is the null class for k centroid for i in range(0, len(origin_set)): distance &#x3D; float(&quot;inf&quot;) centroid_in_choose &#x3D; 0 for j in range(0, len(centroid)): if abs(origin_set[i] - centroid[j]) &lt; distance: distance &#x3D; abs(origin_set[i] - centroid[j]) centroid_in_choose &#x3D; j class_i[centroid_in_choose].append(origin_set[i]) # sort all the elements into proper class print(&quot;after %sth cluster: &quot; % number, &quot;\\n&quot;) print(&quot;centroid class&quot;) for i in range(0, len(class_i)): print(centroid[i], &#39; &#39;, class_i[i]) print(&quot;---------&quot;) for i in range(0, len(class_i)): sum &#x3D; 0 for j in range(0, len(class_i[i])): sum +&#x3D; class_i[i][j] if sum !&#x3D; 0: new_centroid &#x3D; round(sum &#x2F; len(class_i[i]), 3) else: continue if new_centroid !&#x3D; centroid[i]: print(&quot;change centroid &quot;, centroid[i], &quot;as &quot;, end&#x3D;&quot;&quot;) centroid[i] &#x3D; new_centroid print(centroid[i]) flag &#x3D; 1 print(&quot;---------&quot;) # change the wrong centroidprint(&quot;THE CONCLUSION IS：&quot;)print(&quot;centroid class&quot;)for i in range(0, len(class_i)): print(centroid[i], &#39; &#39;, [int(element) for element in class_i[i]])","categories":[{"name":"Tech","slug":"Tech","permalink":"https://zqzhao.cn/categories/Tech/"}],"tags":[{"name":"Clustering","slug":"Clustering","permalink":"https://zqzhao.cn/tags/Clustering/"}]},{"title":"3 Hours Review of OOP","slug":"3hoursOOP","date":"2017-02-04T04:33:38.000Z","updated":"2020-04-18T06:18:02.201Z","comments":true,"path":"2017/02/04/3hoursOOP/","link":"","permalink":"https://zqzhao.cn/2017/02/04/3hoursOOP/","excerpt":"","text":"基于《Thinking in C++》 1. 静态成员变量 静态成员变量用static修饰，它只属于类而不是对象，因此所有这个类的对象享用同一个静态变量值。 静态成员变量必须要在类外初始化 type class::name = value; 初始化的时候不用带static但需要有类型，protected，privated，public都可以被这样初始化 静态成员变量的调用 //通过类类访问 static 成员变量 Student::m_total = 10; //通过对象来访问 static 成员变量 Student stu(&quot;小明&quot;, 15, 92.5f); stu.m_total = 20; //通过对象指针来访问 static 成员变量 Student *pstu = new Student(&quot;李华&quot;, 16, 96); pstu -&gt; m_total = 20; static 成员变量不占用对象的内存，而是在所有对象之外开辟内存，即使不创建对象也可以访问。 一个类中可以有一个或多个静态成员变量，所有的对象都共享这些静态成员变量，都可以引用它。 static 成员变量和普通 static 变量一样，都在内存分区中的全局数据区分配内存，到程序结束时才释放。这就意味着，static 成员变量不随对象的创建而分配内存，也不随对象的销毁而释放内存。而普通成员变量在对象创建时分配内存，在对象销毁时释放内存。 静态成员变量初始化时可以赋初值，也可以不赋值。如果不赋值，那么会被默认初始化为 0。全局数据区的变量都有默认的初始值 0，而动态数据区（堆区、栈区）变量的默认值是不确定的，一般认为是垃圾值。 静态成员变量既可以通过对象名访问，也可以通过类名访问，但要遵循 private、protected 和 public 关键字的访问权限限制。当通过对象名访问时，对于不同的对象，访问的是同一份内存。 静态成员变量可以成为派生类和基类共同使用的数值，也可以成为成员函数的可选参数。 静态成员变量可以是所属类的类型，普通数据成员只能成为该类的指针或引用。 2. 静态成员函数 静态成员函数的地址可以用普通函数指针调用 class A{ public: static fun(){}; int fun1(){}; } int (*pf1)()=&amp;base::fun; int (base::*pf2)()=&amp;case::fun1; 静态成员函数不可以调用类的非静态成员，因为这个静态成员函数并不带有this指针。 静态成员函数不可以同时声明为 virtual const volatile函数。 静态成员函数不需要对象名即可调用。 非静态成员函数可以自由调用静态成员函数和静态成员变量。 3. 引用和地址 引用类似于某个变量的别名，完全享用同一片地址。 引用必须在定义的时候初始化。 引用对象已经初始化不能重新引用另外的变量。 4. 拷贝构造函数 CExample(const CExample&amp; C) 就是我们自定义的拷贝构造函数。可见，拷贝构造函数是一种特殊的构造函数，函数的名称必须和类名称一致，它必须的一个参数是本类型的一个引用变量。 调用时机 类作为一个参数整体传入一个函数的时候，需要调用这个类的拷贝构造函数，进行形参和实参的复制 类作为一个结果返回的时候，先产生一个临时变量，调用拷贝构造函数将返回值拷贝到临时变量，析构返回的变量，再析构临时变量 需要通过另一个变量初始化的时候 class mode{...} mode A(10); mode B = A; 拷贝构造函数分为浅拷贝和深拷贝。 默认拷贝构造函数是浅拷贝的一种 默认拷贝构造函数无法处理静态成员变量只是简单复制 需要自己写浅拷贝构造函数进行静态成员变量的复制 如果被拷贝对象中包含指针，进行逐位拷贝后新旧两个指针将指向同一个空间，并且将被重复释放 深拷贝用于需要动态创建新空间时 Rect(const Rect&amp; r) { width = r.width; height = r.height; p = new int; // 为新对象重新动态分配空间 *p = *(r.p); } 可以创建一个private的拷贝构造函数声明来解决默认值拷贝。？？？ 5. const 修饰指针变量时： 只有一个const，如果const位于*左侧，表示指针所指数据是常量，不能通过解引用修改该数据；指针本身是变量，可以指向其他的内存单元。 只有一个const，如果const位于*右侧，表示指针本身是常量，不能指向其他内存地址；指针所指的数据可以通过解引用修改。 两个const，*左右各一个，表示指针和指针所指数据都不能修改。 修饰函数参数时: 不能改变该参数的值。 修饰函数时： 该函数不能改变调用的参数值，同样地，该函数也不能调用任何非const函数。 修饰返回值时： 指针返回时：只能赋值给同样用const修饰的左值 值传递时：const并没有什么意义 6. 对象初始化和析构 空初始化：即无参数无括号形式 如int i，new int,new int[10].当在所有函数之外时，初始化为0；当在某一函数中时，没初始化。 值初始化：即无参数有括号形式，且括号只能在类型名后，而不能在变量名之后，即只能创无名对象，对象被值初始化为0. 如：int() //创建了一个无名对象，其被值初始化为0.一般将该无名对象初始化化或赋值给某有名对象，或直接作为无名对象使用 显式初始化：即有参数有括号形式，且当为有名对象时括号在对象名之后，为无名对象时括号在类类型名之后。 如：int i（5）； new int(5); 以下四种必须使用初始化列表： 初始化一个引用成员变量 初始化一个const变量 当我们在初始化一个子类对象的时候，而这个子类对象的父类有一个显示的带有参数的构造函数 当调用一个类类型成员的构造函数，而它拥有一组参数的时候 析构函数通常使用默认析构函数，但是在之前进行空间改变（指针移位等）的时候一定要自己写析构函数。 析构数组或类组： class A { A(){m_a=new int[10];} ~A(){delete [] m_a;} int * m_a; } 强制类型转换支持但并不推荐，推荐使用以下较温和的方法： pd = static_cast&lt;double*&gt;(pv); 初始化列表不管怎么写，初始化的顺序也只是按照原类内声明的顺序进行。 7. 重载函数和默认参数 重载函数的调用匹配 精确匹配：参数匹配而不做转换，或者只是做微不足道的转换，如数组名到指针、函数名到指向函数的指针、T到const T； 提升匹配：即整数提升（如bool 到 int、char到int、short 到int），float到double 使用标准转换匹配：如int 到double、double到int、double到long double、Derived*到Base*、T*到void*、int到unsigned int； 使用用户自定义匹配； 使用省略号匹配：类似printf中省略号参数 同一作用域中有相同函数名但是有不同参数列表的可见函数构成重载关系。 内层作用域的函数会隐藏外层的同名函数，同样的派生类的成员函数会隐藏基类的同名函数。 如果要在函数内部调用重名的全局变量则要以“:: va”这样的形式调用。 在编译器中，编译器看到的函数名为“类型+名称+从左往右的参数列表”，但事实上在调用重载函数时，仅仅有返回类型不同是不能成立的，因为编译器无法判断你调用的是哪个函数，具有二义性。 8. 运算符重载 两种重载方式的比较： 一般情况下，单目运算符最好重载为类的成员函数；双目运算符则最好重载为类的友元函数。以下一些双目运算符不能重载为类的友元函数：=、()、[]、-&gt;。 类型转换函数只能定义为一个类的成员函数而不能定义为类的友元函数。 C++提供4个类型转换函数：reinterpret_cast（在编译期间实现转换）、const_cast（在编译期间实现转换）、stactic_cast（在编译期间实现转换）、dynamic_cast（在运行期间实现转换，并可以返回转换成功与否的标志）。 若一个运算符的操作需要修改对象的状态，选择重载为成员函数较好。 若运算符所需的操作数（尤其是第一个操作数）希望有隐式类型转换，则只能选用友元函数。当运算符函数是一个成员函数时，最左边的操作数（或者只有最左边的操作数）必须是运算符类的一个类对象（或者是对该类对象的引用）。如果左边的操作数必须是一个不同类的对象，或者是一个内部 类型的对象，该运算符函数必须作为一个友元函数来实现。 当需要重载运算符具有可交换性时，选择重载为友元函数。 注意事项： 除了类属关系运算符”.“、成员指针运算符”.*“、作用域运算符”::“、sizeof运算符和三目运算符”?:“以外，C++中的所有运算符都可以重载。 重载运算符限制在C++语言中已有的运算符范围内的允许重载的运算符之中，不能创建新的运算符。运算符重载实质上是函数重载，因此编译程序对运算符重载的选择，遵循函数重载的选择原则。 重载之后的运算符不能改变运算符的优先级和结合性，也不能改变运算符操作数的个数及语法结构。 运算符重载不能改变该运算符用于内部类型对象的含义。它只能和用户自定义类型的对象一起使用，或者用于用户自定义类型的对象和内部类型的对象混合使用时。 运算符重载是针对新类型数据的实际需要对原有运算符进行的适当的改造，重载的功能应当与原有功能相类似，避免没有目的地使用重载运算符。 9. 继承和组合 kind of关系下用继承，part of关系下用组合。 继承 class Human { … }; class Man : public Human { … }; class Boy : public Man { … }; 组合 class Eye { public: void Look(void); }; class Nose { public: void Smell(void); }; class Mouth { public: void Eat(void); }; class Ear { public： void Listen(void); }; class Head { public: void Look(void) { m_eye.Look(); } void Smell(void) { m_nose.Smell(); } void Eat(void) { m_mouth.Eat(); } void Listen(void) { m_ear.Listen(); } private: Eye m_eye; Nose m_nose; Mouth m_mouth; Ear m_ear; }; 继承的关系不同对这个派生类并无影响，而是对该派生类的派生类产生影响。例如private Base（10），则对于该派生类的派生类来说，Base不可见。 10. inline &amp; extern 关键字inline 必须与函数定义体放在一起才能使函数成为内联，仅将inline 放在函数声明前面不起任何作用。 定义在类声明之中的成员函数将自动地成为内联函数。 宏替换是单纯地代码替换，inline函数真正具有函数的特征。 extern 表示该声明已经定义在别的文件中了。 11. virtual函数与纯虚函数 虚函数：类Base中加了Virtual关键字的函数就是虚拟函数（例如函数print），于是在Base的派生类Derived中就可以通过重写虚拟函数来实现对基类虚拟函数的覆盖。当基类Base的指针point指向派生类Derived的对象时，对point的print函数的调用实际上是调用了Derived的print函数而不是Base的print函数。 我们只需在把基类的成员函数设为virtual，其派生类的相应的函数也会自动变为虚函数。也就是说，virtual函数被继承后可以自动动态绑定当前对象。 纯虚函数：只声明，无定义，包含纯虚函数的类称为抽象类，无实际作用，只作为基类。 class &lt;类名&gt; { virtual &lt;类型&gt;&lt;函数名&gt;(&lt;参数表&gt;)=0; … }; 重载和覆盖的区别 重载的几个函数必须在同一个类中；覆盖的函数必须在有继承关系的不同的类中 覆盖的几个函数必须函数名、参数、返回值都相同；重载的函数必须函数名相同，参数不同。 覆盖的函数前必须加关键字Virtual；重载和Virtual没有任何瓜葛，加不加都不影响重载的运作。 关于C++的隐藏规则： 如果派生类的函数与基类的函数同名，但是参数不同。此时，不论有无virtual关键字，基类的函数将被隐藏（注意别与重载混淆）。 如果派生类的函数与基类的函数同名，并且参数也相同，但是基类函数没有virtual关键字。此时，基类的函数被隐藏（注意别与覆盖混淆）。 重写 重载 重定义 重写(override):父类与子类之间的多态性。子类重新定义父类中有相同名称和参数的虚函数。 1) 被重写的函数不能是 static 的。必须是 virtual 的 ( 即函数在最原始的基类中被声明为 virtual ) 。 2) 重写函数必须有相同的类型，名称和参数列表 (即相同的函数原型) 3) 重写函数的访问修饰符可以不同。尽管 virtual 是 private 的，派生类中重写改写为 public,protected 也是可以的 重载 (overload):指函数名相同，但是它的参数表列个数或顺序，类型不同。但是不能靠返回类型来判断。 重定义 (redefining):子类重新定义父类中有相同名称的非虚函数 ( 参数列表可以不同 ) 。 重写与重载的区别 (override) PK (overload) 方法的重写是子类和父类之间的关系，是垂直关系；方法的重载是同一个类中方法之间的关 系，是水平关系。 重写要求参数列表相同；重载要求参数列表不同。 重写关系中，调用那个方法体，是根据对象的类型（对象对应存储空间类型）来决定；重载关系，是根据调用时的实参表与形参表来选择方法体的。 12. binding 对象的静态类型：对象在声明时采用的类型。是在编译期确定的。 对象的动态类型：目前所指对象的类型。是在运行期决定的。对象的动态类型可以更改，但是静态类型无法更改。 D* pD = new D(); //pD的静态类型是它声明的类型D*，动态类型也是D* B* pB = pD; //pB的静态类型是它声明的类型B*，动态类型是pB所指向的对象pD的类型D* C* pC = new C(); pB = pC; //pB的动态类型是可以更改的，现在它的动态类型是C* 静态绑定：绑定的是对象的静态类型，某特性（比如函数）依赖于对象的静态类型，发生在编译期。 动态绑定：绑定的是对象的动态类型，某特性（比如函数）依赖于对象的动态类型，发生在运行期。 只有虚函数是动态绑定，其余函数都是静态绑定。动态绑定的函数调用的函数体看实际上的对象类型，静态绑定的函数调用的函数体看声明的对象类型。 虚函数是动态绑定的，但是为了执行效率，缺省参数是静态绑定的。 13. upcasting、downcasting与类指针 将基类引用转换为派生类引用称为upcasting，因为在继承图上式上升的。 对于一个使用了虚函数的基类来说： Base b = d;//直接赋值（产生切割） b.Test(); Base&amp; b2 = d;//使用引用赋值（不产生切割） b2.Test(); Base* b3 = &amp;d;//使用指针赋值（不产生切割） b3-&gt;Test(); //覆盖方法和子类数据丢失的现象生成切割(slice) 14. 模板 模板的一般形式： Template &lt;class或者也可以用typename T&gt; 返回类型 函数名（形参表） {//函数定义体 } //template是一个声明模板的关键字，表示声明一个模板关键字class不能省略，如果类型形参多余一个 ，每个形参前都要加class &lt;类型 形参表&gt;可以包含基本数据类型可以包含类类型. template &lt;class T&gt; inline T square(T x) { T result; result = x * x; return result; }; 15. 异常探查http://www.cnblogs.com/ggjucheng/archive/2011/12/18/2292089.html 16. explicitTest1 t1=12;//隐式调用其构造函数,成功 Test2 t2=12;//编译错误,不能隐式调用其构造函数 Test2 t2(12);//显式调用成功 explicit可以避免隐式调用构造函数。 17. 友元函数class A{ friend int print(); //友元函数不可被继承 } int print(){}; //可以定义在类内或者类外 int main{ A obj; print(); //可以直接调用友元函数 }","categories":[],"tags":[{"name":"OOP","slug":"OOP","permalink":"https://zqzhao.cn/tags/OOP/"}]}],"categories":[{"name":"Theory","slug":"Theory","permalink":"https://zqzhao.cn/categories/Theory/"},{"name":"Tech","slug":"Tech","permalink":"https://zqzhao.cn/categories/Tech/"}],"tags":[{"name":"Article_Template_MIS","slug":"Article-Template-MIS","permalink":"https://zqzhao.cn/tags/Article-Template-MIS/"},{"name":"Theorical_Basis","slug":"Theorical-Basis","permalink":"https://zqzhao.cn/tags/Theorical-Basis/"},{"name":"MIS_thinking","slug":"MIS-thinking","permalink":"https://zqzhao.cn/tags/MIS-thinking/"},{"name":"CS_Math","slug":"CS-Math","permalink":"https://zqzhao.cn/tags/CS-Math/"},{"name":"Clustering","slug":"Clustering","permalink":"https://zqzhao.cn/tags/Clustering/"},{"name":"OOP","slug":"OOP","permalink":"https://zqzhao.cn/tags/OOP/"}]}